[
{
    "issue_url": "https://github.com/dmlc/gluon-cv/issues/598",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "yuanCnD",
            "datetime": "Jan 30, 2019",
            "body": "hi,here is training log:\nloading annotations into memory...\nDone (t=16.61s)\ncreating index...\nindex created!\nloading annotations into memory...\nDone (t=0.46s)\ncreating index...\nindex created!\nINFO:root:Namespace(batch_size=64, data_shape=416, dataset='coco', epochs=280, gpus='0,1,2,3,4,5,6,7', label_smooth=True, log_interval=100, lr=0.001, lr_decay=0.1, lr_decay_epoch='220,250', lr_decay_period=0, lr_mode='step', mixup=True, momentum=0.9, network='darknet53', no_mixup_epochs=20, no_random_shape=False, no_wd=True, num_samples=117266, num_workers=32, resume='', save_interval=10, save_prefix='yolo3_darknet53_coco', seed=233, start_epoch=0, syncbn=True, val_interval=1, warmup_epochs=2, warmup_lr=0.0, wd=0.0005)\nINFO:root:Start training from [Epoch 0]\nINFO:root:[Epoch 0][Batch 99], LR: 2.70E-05, Speed: 33.324 samples/sec, ObjLoss=878.333, BoxCenterLoss=17.802, BoxScaleLoss=14.941, ClassLoss=339.257\nINFO:root:[Epoch 0][Batch 199], LR: 5.43E-05, Speed: 27.818 samples/sec, ObjLoss=464.404, BoxCenterLoss=17.508, BoxScaleLoss=13.389, ClassLoss=237.332\nINFO:root:[Epoch 0][Batch 299], LR: 8.16E-05, Speed: 56.125 samples/sec, ObjLoss=321.394, BoxCenterLoss=16.973, BoxScaleLoss=11.971, ClassLoss=174.369\nINFO:root:[Epoch 0][Batch 399], LR: 1.09E-04, Speed: 30.589 samples/sec, ObjLoss=249.321, BoxCenterLoss=16.702, BoxScaleLoss=11.015, ClassLoss=140.578\nINFO:root:[Epoch 0][Batch 499], LR: 1.36E-04, Speed: 38.707 samples/sec, ObjLoss=205.859, BoxCenterLoss=16.567, BoxScaleLoss=10.342, ClassLoss=119.724\nINFO:root:[Epoch 0][Batch 599], LR: 1.63E-04, Speed: 37.456 samples/sec, ObjLoss=176.808, BoxCenterLoss=16.499, BoxScaleLoss=9.844, ClassLoss=105.734\nINFO:root:[Epoch 0][Batch 699], LR: 1.91E-04, Speed: 34.759 samples/sec, ObjLoss=155.749, BoxCenterLoss=16.326, BoxScaleLoss=9.392, ClassLoss=95.448\nINFO:root:[Epoch 0][Batch 799], LR: 2.18E-04, Speed: 34.887 samples/sec, ObjLoss=140.052, BoxCenterLoss=16.265, BoxScaleLoss=9.074, ClassLoss=87.846\nINFO:root:[Epoch 0][Batch 899], LR: 2.45E-04, Speed: 21.149 samples/sec, ObjLoss=127.875, BoxCenterLoss=16.238, BoxScaleLoss=8.806, ClassLoss=81.887\nINFO:root:[Epoch 0][Batch 999], LR: 2.73E-04, Speed: 39.372 samples/sec, ObjLoss=117.959, BoxCenterLoss=16.182, BoxScaleLoss=8.577, ClassLoss=77.059\nINFO:root:[Epoch 0][Batch 1099], LR: 3.00E-04, Speed: 23.731 samples/sec, ObjLoss=109.935, BoxCenterLoss=16.154, BoxScaleLoss=8.364, ClassLoss=73.143\nINFO:root:[Epoch 0][Batch 1199], LR: 3.27E-04, Speed: 32.060 samples/sec, ObjLoss=103.141, BoxCenterLoss=16.092, BoxScaleLoss=8.195, ClassLoss=69.817\nINFO:root:[Epoch 0][Batch 1299], LR: 3.55E-04, Speed: 55.695 samples/sec, ObjLoss=97.359, BoxCenterLoss=16.040, BoxScaleLoss=8.067, ClassLoss=67.010\nINFO:root:[Epoch 0][Batch 1399], LR: 3.82E-04, Speed: 29.831 samples/sec, ObjLoss=92.345, BoxCenterLoss=15.977, BoxScaleLoss=7.947, ClassLoss=64.564\nINFO:root:[Epoch 0][Batch 1499], LR: 4.09E-04, Speed: 47.742 samples/sec, ObjLoss=87.972, BoxCenterLoss=15.919, BoxScaleLoss=7.830, ClassLoss=62.440\nINFO:root:[Epoch 0][Batch 1599], LR: 4.36E-04, Speed: 34.914 samples/sec, ObjLoss=84.214, BoxCenterLoss=15.883, BoxScaleLoss=7.729, ClassLoss=60.608\nINFO:root:[Epoch 0][Batch 1699], LR: 4.64E-04, Speed: 36.860 samples/sec, ObjLoss=80.848, BoxCenterLoss=15.821, BoxScaleLoss=7.624, ClassLoss=58.938\nINFO:root:[Epoch 0][Batch 1799], LR: 4.91E-04, Speed: 46.941 samples/sec, ObjLoss=77.929, BoxCenterLoss=15.795, BoxScaleLoss=7.533, ClassLoss=57.506\nINFO:root:[Epoch 0] Training cost: 4479.540, ObjLoss=77.019, BoxCenterLoss=15.767, BoxScaleLoss=7.509, ClassLoss=57.045\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type \nDONE (t=21.98s).\nAccumulating evaluation results...\nDONE (t=1.79s).\nINFO:root:[Epoch 0] Validation:",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "zhreshold",
            "datetime": "Feb 7, 2019",
            "body": "Are you following the same arguments as in the model zoo script?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "xupengcoding",
            "datetime": "Mar 28, 2019",
            "body": "I also met this problem. When I was training, the validation mAP is always zero. My script is \"python3 -u train_yolo3.py --network darknet53 --dataset coco --lr 0.0005 --gpus 4,5,6,7 --batch-size 32 -j 32 --log-interval 100 --lr-decay-epoch 220,250 --epochs 280 --syncbn --warmup-epochs 2 --mixup --no-mixup-epochs 20 --label-smooth --no-wd 1>train_yolo_dark53.log\".  , Could you please help me!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "zhreshold",
            "datetime": "Mar 28, 2019",
            "body": "  try this first to make sure you have all set up correctly:If this still doesn't work, then there might be some dataset problem",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "xupengcoding",
            "datetime": "Mar 29, 2019",
            "body": "I found the ans. The score_thresh in COCODetectionMetric is 0.5, but the predict scores always less than 0.5 in several starting epochs. I think this does not matter, and the issue can be closed.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "yuzhms",
            "datetime": "Apr 25, 2019",
            "body": "I meet this problem when I use scripts likeLosses seemed ok, dropped about 30x. I check and found the score is all below 0.5 even after training 150 epochs.\nBut, when I turn off label smoothing, mixup and no-wd, It work fine, I can get none zero map after 2 epochs.\nIs this normal?\nWhat should I do if I want to use label smoothing, mixup and no-wd?\n",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "zhreshold",
            "datetime": "Apr 25, 2019",
            "body": "please update to master, there has been a small bug causing smooth to be incorrect",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "zhreshold",
            "datetime": "Mar 29, 2019",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/voxel51/fiftyone/issues/1196",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "brimoor",
            "datetime": "Aug 16, 2021",
            "body": "It would be helpful to see confidence thresholds (if possible, see below) in the tooltips of PR/ROC curves plotable viaIn the first two,  and  are used to compute the curves and they return thresholds, so it'll be trivial to get the data.For detection evaluation, there are some nuances. See  for details.In terms of adding the threshold data to the plot tooltips, you can see in  how to customize the tooltip. A similar thing should be possible to add for the other PR/ROC curve plotting methods for the  backend.Tooltips aren't supported by the  backend, so this would be a feature only supported by the  backend. But that's okay, there is already precedent for backend-specific arguments to plotting functions, e.g., . Also, we would like to remove the  backend altogether in the future.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "pradkrish",
            "datetime": "Sep 30, 2021",
            "body": "Hello, a newcomer to this project looking for good first issues. is someone working on this? Otherwise, I can give it a go.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "brimoor",
            "datetime": "Sep 30, 2021",
            "body": "Hi   No one is working on this yet so please do give it a go! Happy to assist if needed",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "pradkrish",
            "datetime": "Oct 1, 2021",
            "body": "I looked briefly at the implementation and also looked around for any available tests in the directory that uses  and  and found none, to my surprise. do you think it's a good idea to test those functions and if yes, can we make it part of this issue?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "brimoor",
            "datetime": "Oct 1, 2021",
            "body": "Yeah we don't have good test coverage for graphical things like plots or the App (difficult to ensure plots are rendering as expected). Though I would certainly be onboard with adding basic unit tests to ensure the code runs without error (excluding ).In terms of testing you work, the primary existing way is just to verify that the examples in the docs in places like the following work as expected: ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "pradkrish",
            "datetime": "Oct 1, 2021",
            "body": "Will it be equivalent to making sure all the tests in  pass after changes?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "brimoor",
            "datetime": "Oct 1, 2021",
            "body": "yes, good point. I forgot about those because the tests in  are not automatically included in our CI workflow. But, yes, running those tests manually (and adding new ones as necessary) is a good way to verify plotting-related functionality is working as expected",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "pradkrish",
            "datetime": "Oct 2, 2021",
            "body": "I have never worked with Plotly before and I have a basic question. This task is about adding a tooltip, does it mean  when I move the mouse cursor over the PR or ROC curve, I should be able to see a box with values for precision, recall and the corresponding threshold? In that case, it looks like I need to create a dataframe with columns for precision, recall and threshold and pass it into plot function. is that the right approach? Thanks.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "brimoor",
            "datetime": "Oct 2, 2021",
            "body": "yes exactly. The plotly functions have something called  that you can use to store extra data (confidences, in this case) that you can use to define a custom tooltip that shows the confidence value when you hover over a point.This snippet shows an example of doing that elsewhere in our codebase:\nIf you get stuck, forget about FiftyOne for a second and just try to make a plotly plot directly that does what you want. Then you can get it integrated into the FiftyOne codebase.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "brimoor",
            "datetime": "Aug 16, 2021",
            "body": [],
            "type": "issue",
            "related_issue": null
        },
        {
            "user_name": "brimoor",
            "datetime": "Dec 27, 2021",
            "body": [],
            "type": "pull",
            "related_issue": "#1490"
        },
        {
            "user_name": "brimoor",
            "datetime": "Dec 30, 2021",
            "body": [],
            "type": "pull",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/voxel51/fiftyone/issues/891",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "brimoor",
            "datetime": "Feb 25, 2021",
            "body": "The  view stage supports creating a view that only contains certain objects, and, as shown in the example code in the docs, it works very naturally with , which provides the necessary info automatically from a user's mouse clicks.However, it also may be useful for a user to select objects using only their , without having to worry about what field or sample the object is in. One way to accomplish this is via the pattern below:The following ideas come to mind:\n(a) add optional support for passing a simple list of IDs to , in which case the stage will internally use the pattern above to construct the view\n(b) deprecate the more expressive but clunky current syntax and  support the above\n(c) add a new stage that allows for selection via the above syntaxPerhaps (a) is the best best for now?An important observation is that the pattern shown above will be quite slow for datasets with many  fields.Usage of the existing  stage:",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "brimoor",
            "datetime": "Feb 25, 2021",
            "body": "Another option could be to add a  method that uses the above construction to locate the objects and return information about them in the format expected by . The benefit here would be that you run  (slow) only once, and then use  (fast) in your subsequent operations",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "benjaminpkane",
            "datetime": "Feb 25, 2021",
            "body": "(a) would probably be an improvement, especially now that it seems like ids being used by other parts of FiftyOne.I also think it would be nice to simplify our approach to , , and s for users so they never have to think about it...",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ehofesmann",
            "datetime": "Feb 25, 2021",
            "body": "I agree with Ben, I think  should support both the current input and just a list of object ids. It should probably support different versions of the current input as well, for example, a dict with just object ids and associated label fields, or just sample ids and object ids without label fields. The more information you add the faster the method becomes.Though most importantly, I really we should get rid of the need to use . Just doing this through  on the  of objects was the most natural/first thing that I wanted to do.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "brimoor",
            "datetime": "Feb 25, 2021",
            "body": [],
            "type": "added",
            "related_issue": null
        },
        {
            "user_name": "brimoor",
            "datetime": "Feb 26, 2021",
            "body": [],
            "type": "pull",
            "related_issue": "#892"
        },
        {
            "user_name": "brimoor",
            "datetime": "Mar 5, 2021",
            "body": [],
            "type": "pull",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/voxel51/fiftyone/issues/980",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "brimoor",
            "datetime": "Apr 24, 2021",
            "body": "It would be natural if clicking on an already-opened graphs tab would collapse the graphs section. This would present a more convenient alternative to mousing way over to the righthand side to click hide.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "brimoor",
            "datetime": "Apr 24, 2021",
            "body": [],
            "type": "issue",
            "related_issue": null
        },
        {
            "user_name": "benjaminpkane",
            "datetime": "May 7, 2021",
            "body": [],
            "type": "pull",
            "related_issue": "#1005"
        },
        {
            "user_name": "benjaminpkane",
            "datetime": "May 10, 2021",
            "body": [],
            "type": "pull",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/voxel51/fiftyone/issues/390",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "brimoor",
            "datetime": "Aug 13, 2020",
            "body": "It would be extremely useful to be able to zoom in/out and pan around the viewer in expanded sample mode. Typical use case is to inspect specific regions of large and/or complicated imagesIn terms of implementation, the obvious best practice is to follow the Google Maps-style interface:",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "brimoor",
            "datetime": "Aug 13, 2020",
            "body": [],
            "type": "added",
            "related_issue": null
        },
        {
            "user_name": "benjaminpkane",
            "datetime": "Nov 16, 2020",
            "body": [],
            "type": "issue",
            "related_issue": "#135"
        },
        {
            "user_name": "benjaminpkane",
            "datetime": "Nov 16, 2020",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "brimoor",
            "datetime": "Apr 28, 2021",
            "body": [],
            "type": "issue",
            "related_issue": "#991"
        },
        {
            "user_name": "benjaminpkane",
            "datetime": "May 18, 2021",
            "body": [],
            "type": "pull",
            "related_issue": "#1041"
        },
        {
            "user_name": "benjaminpkane",
            "datetime": "Aug 9, 2021",
            "body": [],
            "type": "pull",
            "related_issue": null
        },
        {
            "user_name": null,
            "datetime": "Aug 9, 2021",
            "body": [],
            "type": "moved this from",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/4173",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "dvkruchinin",
            "datetime": "Jan 14, 2022",
            "body": "An error occurs when the movement of the mouse cursor after removing the shape during its movement.The error does not occur.The error occurs in the Firefox browser when interacting with shapes that can be moved (rectangle, points, ellipse, cuboid).Fix a bug.You may  channel for community support.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dvkruchinin",
            "datetime": "Jan 14, 2022",
            "body": [],
            "type": "changed the title",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Jan 14, 2022",
            "body": [],
            "type": "pull",
            "related_issue": "#4175"
        },
        {
            "user_name": "bsekachev",
            "datetime": "Jan 14, 2022",
            "body": [],
            "type": "pull",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/4341",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "yaoguang97",
            "datetime": "Feb 14, 2022",
            "body": "Environment：ubuntu20.04，nuctl1.5.16\n\n",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Feb 15, 2022",
            "body": " , thanks for the report. I can reproduce the issue on our side. I will try to fix before 2.0.0 release.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "yaoguang97",
            "datetime": "Feb 17, 2022",
            "body": ", I pulled the latest code, rebuilt the YOLOv5 model, and the same error occurred.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Feb 17, 2022",
            "body": " , could you please send logs for the function? ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "yaoguang97",
            "datetime": "Feb 18, 2022",
            "body": " ，Hello, this is the log about the container.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Feb 21, 2022",
            "body": " ,From your logs I see that  leads to an exception. It tries to download the model locally and cannot. Please check your network settings.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "maecky",
            "datetime": "Jun 25, 2022",
            "body": "Any progress on this? For me, it fails as well.  Network connection is OK.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Feb 15, 2022",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Feb 15, 2022",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Feb 15, 2022",
            "body": [],
            "type": "pull",
            "related_issue": "#4344"
        },
        {
            "user_name": "nmanovic",
            "datetime": "Feb 15, 2022",
            "body": [],
            "type": "pull",
            "related_issue": null
        },
        {
            "user_name": null,
            "datetime": "Feb 15, 2022",
            "body": [],
            "type": "moved this from",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/4503",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "admer7",
            "datetime": "Mar 23, 2022",
            "body": "We are using the \"Standard\" Workspace and a handful of labels and one tag with attributes for our annotation jobs. We often need to switch between placing a tag and placing a label.Current workaround is to select by mouse another label/tag from the side-bar, place it, delete it again and create the original label.No errors or warnings gets printed.Same problem with , CVAT v2.0.0-alpha and v2.0.0 release version.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Mar 23, 2022",
            "body": "Thank you for the report, it is a bug.P.S. For tags I would recommend to look at \"Tag annotation\" mode. If you do not have lots of classes it probably would be more effective.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "admer7",
            "datetime": "Mar 24, 2022",
            "body": "Thanks for the quick response!We have it the other way round. A lot of classes and usually only one or two tags. I assume for this scenario the \"Standard\" mode is the logical one.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Mar 25, 2022",
            "body": "Hi Could you please check if the fix above works for you?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "admer7",
            "datetime": "Mar 27, 2022",
            "body": "Problem still remains. After pressing \"n\", the rectangle button in the side-bar is locked.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Mar 27, 2022",
            "body": "Are u sure you updated CVAT? What steps did you do to update? I tried this patch and actually looks like it works.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "admer7",
            "datetime": "Mar 28, 2022",
            "body": "Ok, it is fixed after fresh cloning and building from source :)But we are using 2.0.0 release and only coping  is not enough to fix this bug... Any suggestions?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Mar 28, 2022",
            "body": "Maybe because you fetched server release from docker hub instead of buidling from source first?  file must be included when build.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "admer7",
            "datetime": "Mar 28, 2022",
            "body": "I used the git repo with the , added the modified  file and build via .",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Mar 23, 2022",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Mar 23, 2022",
            "body": [],
            "type": "self-assigned this",
            "related_issue": null
        },
        {
            "user_name": "klakhov",
            "datetime": "Mar 25, 2022",
            "body": [],
            "type": "pull",
            "related_issue": "#4517"
        },
        {
            "user_name": "bsekachev",
            "datetime": "Mar 25, 2022",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Mar 25, 2022",
            "body": [],
            "type": "pull",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/4785",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "mandharsh38",
            "datetime": "Aug 1, 2022",
            "body": "Read/searched \nSearched Should annotate automaticallyServer Error\nError: Request failed with status code 500. \"500 Server Error: Internal Server Error for url: \".1 run ./serverless/deploy_cpu.sh ./serverless/pytorch/ultralytics/yolov5/\n2 Create a task and try to auto-annotate using the detector yolo-v5Wanted to automatic annotate my custom dataset using yolov5 detectorYou may  channel for community support.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dschoerk",
            "datetime": "Aug 3, 2022",
            "body": "looks like the body of the http request isn't delivering the image correctly. are you using google chrome? the docs state that it's the only supported browser.i just tried with the develop branch on  and spun up an instance within WSL with the CPU version of YOLOv5 ... and it worked fine.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dschoerk",
            "datetime": "Aug 3, 2022",
            "body": "logs for comparisoni'm not getting \"[W NNPACK.cpp:51] Could not initialize NNPACK! Reason: Unsupported hardware.\" although that seems to be just a warning.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Aug 4, 2022",
            "body": " , thanks for sharing. We did a number of fixes for serverless functions in  repo. Don't hestitate to update the nuclio version: . It was updated as well.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "mandharsh38",
            "datetime": "Aug 13, 2022",
            "body": "Works now..updated nuctl and running: docker bridge fixed it. Thanks for the help..  ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "matiassalriv1998",
            "datetime": "Sep 6, 2022",
            "body": "Hello  , I'm having problems to auto annotate my own model with Yolo and the tutorial only shows detectron, could you explain about the changes you made at the function.yaml (the default one, to adapt at your own model) also main.py. I'm having problems with that.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "mandharsh38",
            "datetime": "Aug 13, 2022",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/3652",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "kgloveyou",
            "datetime": "Sep 7, 2021",
            "body": "the annotation page can interact correctlyyou can zoom, but you cannot select the bouding box and change to next picture1.Click on the bouding box without releasing the mouse\n2.press delete key\n3.the annotation page will be stuck(you can zoom, but you cannot select the bouding box and change to next picture)You may  channel for community support.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Sep 23, 2021",
            "body": "Hi Thank you for the report.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": null,
            "datetime": [],
            "body": [],
            "type": "",
            "related_issue": "hixio-mh/cvat#77"
        },
        {
            "user_name": "bsekachev",
            "datetime": "Sep 23, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Sep 23, 2021",
            "body": [],
            "type": "self-assigned this",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Nov 20, 2021",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Jan 12, 2022",
            "body": [],
            "type": "pull",
            "related_issue": "#4151"
        },
        {
            "user_name": "bsekachev",
            "datetime": "Jan 13, 2022",
            "body": [],
            "type": "pull",
            "related_issue": null
        },
        {
            "user_name": null,
            "datetime": "Jan 13, 2022",
            "body": [],
            "type": "moved this from",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/3582",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "TOsmanov",
            "datetime": "Aug 23, 2021",
            "body": "Related You can change the restrictive threshold without triggers the block.When you change the limiting threshold intelligent scissors () the block is also triggered.You may  channel for community support.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Aug 23, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Sep 23, 2021",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "klakhov",
            "datetime": "Oct 25, 2021",
            "body": [],
            "type": "pull",
            "related_issue": "#3825"
        },
        {
            "user_name": "bsekachev",
            "datetime": "Oct 26, 2021",
            "body": [],
            "type": "pull",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/2991",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "nstolyarov",
            "datetime": "Mar 22, 2021",
            "body": "You can copy and paste polygons in CVAT. This helps us in cases when we mark one place with different classes. We need to be able to paste the copied polygon in exactly the same place. But when you insert a polygon, it snaps to the mouse cursor and moves away from its original position.After pressing ctrl-v, the polygon is inserted exactly in the same place as the original.After pressing ctrl-v, the polygon snaps to the mouse cursor and moves.Insert a polygon in exactly the same place by default, if necessary, drag it with the mouse from its original position.When working with complex regions of segmentation, it can be useful to duplicate the polygon at the same place.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Mar 22, 2021",
            "body": "Hi, What is usecase when you need the same polygon in exactly the same place?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nstolyarov",
            "datetime": "Mar 22, 2021",
            "body": "Hi, Here is the example below\n",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Apr 15, 2021",
            "body": " , As far as I know the automatic border solved the issue. Could you please confirm and close the issue in the case?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nstolyarov",
            "datetime": "Apr 15, 2021",
            "body": "Hi, !You are right, the automatic bordering solved this issue. Thank you.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Mar 22, 2021",
            "body": [],
            "type": "added",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Mar 22, 2021",
            "body": [],
            "type": "self-assigned this",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Apr 15, 2021",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Apr 15, 2021",
            "body": [],
            "type": "added this to the",
            "related_issue": null
        },
        {
            "user_name": "nstolyarov",
            "datetime": "Apr 15, 2021",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        },
        {
            "user_name": null,
            "datetime": "Apr 15, 2021",
            "body": [],
            "type": "moved this from",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/2899",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "bsekachev",
            "datetime": "Mar 3, 2021",
            "body": "If two issue tags created at the same place it was impossible to access on of them ().\nTo fix the behavior we've added the feature of scrolling these tags by mouse wheel () as shown on the gif below.\nNeed to hover cursor under an issue and use wheel your mouse. We should add a piece of information about it to our user guide",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Nov 24, 2021",
            "body": " , could you please check that it is covered by our documentation? If it is not, please add corresponding information. I will close the issue.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Mar 3, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Mar 3, 2021",
            "body": [],
            "type": "added this to the",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Mar 8, 2021",
            "body": [],
            "type": "modified the milestones:",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Nov 24, 2021",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Nov 24, 2021",
            "body": [],
            "type": "removed this from the",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Nov 24, 2021",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "TOsmanov",
            "datetime": "Nov 24, 2021",
            "body": [],
            "type": "pull",
            "related_issue": "#3944"
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/2807",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "bsekachev",
            "datetime": "Feb 15, 2021",
            "body": "",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Feb 15, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": null,
            "datetime": [],
            "body": [],
            "type": "",
            "related_issue": "#2712"
        },
        {
            "user_name": "bsekachev",
            "datetime": "Feb 15, 2021",
            "body": [],
            "type": "self-assigned this",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Feb 15, 2021",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Feb 15, 2021",
            "body": [],
            "type": "added this to the",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Feb 18, 2021",
            "body": [],
            "type": "pull",
            "related_issue": null
        },
        {
            "user_name": null,
            "datetime": "Feb 18, 2021",
            "body": [],
            "type": "moved this from",
            "related_issue": null
        },
        {
            "user_name": "dvkruchinin",
            "datetime": "Feb 19, 2021",
            "body": [],
            "type": "pull",
            "related_issue": "#2833"
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/3361",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "davodogster",
            "datetime": "Jun 23, 2021",
            "body": "Hi Guys,I successfully updated CVAT and deployed IOG on my ubuntu machine (not windows anymore), remote server IP address, but it still gives the same error from months ago:\n\n\nI also tried adding port 32001 (from the below issue) to the yaml and it gives the same error.\nAre you able to help?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "azhavoro",
            "datetime": "Jun 24, 2021",
            "body": "Hi, please attach logs from cvat and nuclio containers:  ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "davodogster",
            "datetime": "Jun 24, 2021",
            "body": "Hi :2021-06-23 23:00:10,912 DEBG 'rqworker_low' stderr output:\nINFO - 2021-06-23 23:00:10,912 - worker - Cleaning registries for queue: low2021-06-23 23:01:06,754 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:01:06.753887 2021] [wsgi:error] [pid 438:tid 140564144842496] [remote 172.21.0.7:57528] [2021-06-23 23:01:06,753] WARNING django.request: Not Found: /analytics/app/kibana2021-06-23 23:01:06,754 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:01:06.753975 2021] [wsgi:error] [pid 438:tid 140564144842496] [remote 172.21.0.7:57528] WARNING - 2021-06-23 23:01:06,753 - log - Not Found: /analytics/app/kibana2021-06-23 23:01:21,081 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:01:21.081261 2021] [wsgi:error] [pid 438:tid 140564153235200] [remote 172.21.0.7:57592] ERROR - 2021-06-23 23:01:21,081 - views - {\"system\":\"Windows 10\",\"client\":\"chrome\",\"time\":\"2021-06-23T23:01:20.991000Z\",\"client_id\":266469,\"message\":\"Cannot read property 'toString' of undefined\",\"filename\":\": Cannot read property 'toString' of undefined\\n    at Vl.renderParameters (    at Vl.render (    at $i (    at qi (    at Ss (    at ml (    at fl (    at ol (    at     at t.unstable_runWithPriority ( exception\"}2021-06-23 23:01:25,784 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:01:25.784606 2021] [wsgi:error] [pid 438:tid 140564153235200] [remote 172.21.0.7:57658] [2021-06-23 23:01:25,784] INFO cvat.server.task_140: get repository request\n[Wed Jun 23 23:01:25.784673 2021] [wsgi:error] [pid 438:tid 140564153235200] [remote 172.21.0.7:57658] INFO - 2021-06-23 23:01:25,784 - views - get repository request2021-06-23 23:01:55,521 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:01:55.521658 2021] [wsgi:error] [pid 438:tid 140564161627904] [remote 172.21.0.7:57742] [2021-06-23 23:01:55,521] WARNING django.request: Unauthorized: /api/v1/users/self2021-06-23 23:01:55,521 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:01:55.521748 2021] [wsgi:error] [pid 438:tid 140564161627904] [remote 172.21.0.7:57742] WARNING - 2021-06-23 23:01:55,521 - log - Unauthorized: /api/v1/users/self2021-06-23 23:01:55,604 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:01:55.604343 2021] [wsgi:error] [pid 438:tid 140564153235200] [remote 172.21.0.7:57746] [2021-06-23 23:01:55,604] WARNING django.request: Unauthorized: /api/v1/auth/password/change2021-06-23 23:01:55,604 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:01:55.604691 2021] [wsgi:error] [pid 438:tid 140564153235200] [remote 172.21.0.7:57746] WARNING - 2021-06-23 23:01:55,604 - log - Unauthorized: /api/v1/auth/password/change2021-06-23 23:01:57,865 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:01:57.865350 2021] [wsgi:error] [pid 438:tid 140564144842496] [remote 172.21.0.7:57760] [2021-06-23 23:01:57,865] WARNING django.request: Unauthorized: /api/v1/users/self2021-06-23 23:01:57,865 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:01:57.865659 2021] [wsgi:error] [pid 438:tid 140564144842496] [remote 172.21.0.7:57760] WARNING - 2021-06-23 23:01:57,865 - log - Unauthorized: /api/v1/users/self2021-06-23 23:01:57,948 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:01:57.948715 2021] [wsgi:error] [pid 438:tid 140564161627904] [remote 172.21.0.7:57764] [2021-06-23 23:01:57,948] WARNING django.request: Unauthorized: /api/v1/auth/password/change2021-06-23 23:01:57,949 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:01:57.948856 2021] [wsgi:error] [pid 438:tid 140564161627904] [remote 172.21.0.7:57764] WARNING - 2021-06-23 23:01:57,948 - log - Unauthorized: /api/v1/auth/password/change2021-06-23 23:01:59,964 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:01:59.964480 2021] [wsgi:error] [pid 438:tid 140564153235200] [remote 172.21.0.7:57778] [2021-06-23 23:01:59,964] WARNING django.request: Unauthorized: /api/v1/users/self2021-06-23 23:01:59,965 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:01:59.964785 2021] [wsgi:error] [pid 438:tid 140564153235200] [remote 172.21.0.7:57778] WARNING - 2021-06-23 23:01:59,964 - log - Unauthorized: /api/v1/users/self2021-06-23 23:02:00,048 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:02:00.048532 2021] [wsgi:error] [pid 438:tid 140564144842496] [remote 172.21.0.7:57782] [2021-06-23 23:02:00,048] WARNING django.request: Unauthorized: /api/v1/auth/password/change2021-06-23 23:02:00,049 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:02:00.048830 2021] [wsgi:error] [pid 438:tid 140564144842496] [remote 172.21.0.7:57782] WARNING - 2021-06-23 23:02:00,048 - log - Unauthorized: /api/v1/auth/password/change2021-06-23 23:02:02,940 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:02:02.940565 2021] [wsgi:error] [pid 438:tid 140564161627904] [remote 172.21.0.7:57798] [2021-06-23 23:02:02,940] WARNING django.request: Unauthorized: /api/v1/users/self2021-06-23 23:02:02,941 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:02:02.940898 2021] [wsgi:error] [pid 438:tid 140564161627904] [remote 172.21.0.7:57798] WARNING - 2021-06-23 23:02:02,940 - log - Unauthorized: /api/v1/users/self2021-06-23 23:02:03,051 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:02:03.051685 2021] [wsgi:error] [pid 438:tid 140564153235200] [remote 172.21.0.7:57802] [2021-06-23 23:02:03,051] WARNING django.request: Unauthorized: /api/v1/auth/password/change2021-06-23 23:02:03,052 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:02:03.052022 2021] [wsgi:error] [pid 438:tid 140564153235200] [remote 172.21.0.7:57802] WARNING - 2021-06-23 23:02:03,051 - log - Unauthorized: /api/v1/auth/password/change2021-06-23 23:05:09,275 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:05:09.275347 2021] [wsgi:error] [pid 438:tid 140564144842496] [remote 172.21.0.7:58184] [2021-06-23 23:05:09,275] INFO cvat.server.task_133: get repository request2021-06-23 23:05:09,276 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:05:09.275828 2021] [wsgi:error] [pid 438:tid 140564144842496] [remote 172.21.0.7:58184] INFO - 2021-06-23 23:05:09,275 - views - get repository request2021-06-23 23:05:16,937 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:05:16.937629 2021] [wsgi:error] [pid 438:tid 140564170020608] [remote 172.21.0.7:58228] [2021-06-23 23:05:16,937] INFO cvat.server.task_125: get repository request2021-06-23 23:05:16,937 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:05:16.937723 2021] [wsgi:error] [pid 438:tid 140564170020608] [remote 172.21.0.7:58228] INFO - 2021-06-23 23:05:16,937 - views - get repository request2021-06-23 23:05:18,449 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:05:18.448989 2021] [wsgi:error] [pid 438:tid 140564144842496] [remote 172.21.0.7:58246] INFO - 2021-06-23 23:05:18,448 - views - {\"client_id\":284839,\"name\":\"Send user activity\",\"time\":\"2021-06-23T23:05:18.408000Z\",\"payload\":{\"working_time\":131387},\"is_active\":true,\"username\":\"Davidsoscvat\"}2021-06-23 23:05:29,689 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:05:29.689166 2021] [wsgi:error] [pid 438:tid 140564161627904] [remote 172.21.0.7:58288] [2021-06-23 23:05:29,689] ERROR django.request: Internal Server Error: /api/v1/lambda/functions/pth.shiyinzhang.iog2021-06-23 23:05:29,689 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:05:29.689242 2021] [wsgi:error] [pid 438:tid 140564161627904] [remote 172.21.0.7:58288] ERROR - 2021-06-23 23:05:29,689 - log - Internal Server Error: /api/v1/lambda/functions/pth.shiyinzhang.iog2021-06-23 23:05:32,074 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:05:32.074364 2021] [wsgi:error] [pid 438:tid 140564170020608] [remote 172.21.0.7:58308] [2021-06-23 23:05:32,074] ERROR django.request: Internal Server Error: /api/v1/lambda/functions/pth.shiyinzhang.iog2021-06-23 23:05:32,074 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:05:32.074441 2021] [wsgi:error] [pid 438:tid 140564170020608] [remote 172.21.0.7:58308] ERROR - 2021-06-23 23:05:32,074 - log - Internal Server Error: /api/v1/lambda/functions/pth.shiyinzhang.iog2021-06-23 23:05:35,326 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:05:35.326429 2021] [wsgi:error] [pid 438:tid 140564161627904] [remote 172.21.0.7:58328] [2021-06-23 23:05:35,326] ERROR django.request: Internal Server Error: /api/v1/lambda/functions/pth.shiyinzhang.iog2021-06-23 23:05:35,327 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:05:35.326745 2021] [wsgi:error] [pid 438:tid 140564161627904] [remote 172.21.0.7:58328] ERROR - 2021-06-23 23:05:35,326 - log - Internal Server Error: /api/v1/lambda/functions/pth.shiyinzhang.iog2021-06-23 23:05:36,439 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:05:36.439051 2021] [wsgi:error] [pid 438:tid 140564170020608] [remote 172.21.0.7:58344] [2021-06-23 23:05:36,438] ERROR django.request: Internal Server Error: /api/v1/lambda/functions/pth.shiyinzhang.iog2021-06-23 23:05:36,439 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:05:36.439206 2021] [wsgi:error] [pid 438:tid 140564170020608] [remote 172.21.0.7:58344] ERROR - 2021-06-23 23:05:36,438 - log - Internal Server Error: /api/v1/lambda/functions/pth.shiyinzhang.iog2021-06-23 23:05:43,975 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:05:43.975792 2021] [wsgi:error] [pid 438:tid 140564161627904] [remote 172.21.0.7:58372] INFO - 2021-06-23 23:05:43,971 - views - {\"job_id\":108,\"task_id\":125,\"client_id\":284839,\"name\":\"Load job\",\"time\":\"2021-06-23T23:05:18.408000Z\",\"payload\":{\"duration\":1969,\"frame count\":129,\"track count\":814,\"object count\":814,\"box count\":814,\"polygon count\":0,\"polyline count\":0,\"points count\":0,\"cuboids count\":0,\"tag count\":0},\"is_active\":true,\"username\":\"Davidsoscvat\"}2021-06-23 23:05:43,976 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:05:43.975913 2021] [wsgi:error] [pid 438:tid 140564161627904] [remote 172.21.0.7:58372] INFO - 2021-06-23 23:05:43,975 - views - {\"job_id\":108,\"task_id\":125,\"client_id\":284839,\"name\":\"Fit image\",\"time\":\"2021-06-23T23:05:20.415000Z\",\"payload\":{},\"is_active\":true,\"username\":\"Davidsoscvat\"}\n[Wed Jun 23 23:05:43.976001 2021] [wsgi:error] [pid 438:tid 140564161627904] [remote 172.21.0.7:58372] INFO - 2021-06-23 23:05:43,975 - views - {\"job_id\":108,\"task_id\":125,\"client_id\":284839,\"name\":\"Zoom image\",\"time\":\"2021-06-23T23:05:22.104000Z\",\"payload\":{},\"is_active\":true,\"username\":\"Davidsoscvat\"}2021-06-23 23:05:43,976 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:05:43.976101 2021] [wsgi:error] [pid 438:tid 140564161627904] [remote 172.21.0.7:58372] INFO - 2021-06-23 23:05:43,976 - views - {\"client_id\":284839,\"name\":\"Send user activity\",\"time\":\"2021-06-23T23:05:43.923000Z\",\"payload\":{\"working_time\":20732},\"is_active\":true,\"username\":\"Davidsoscvat\"}2021-06-23 23:06:55,957 DEBG 'rqworker_default_0' stderr output:\nDEBUG - 2021-06-23 23:06:55,956 - worker - Sent heartbeat to prevent worker timeout. Next one should arrive within 480 seconds.2021-06-23 23:06:55,957 DEBG 'rqworker_low' stderr output:\nDEBUG - 2021-06-23 23:06:55,956 - worker - Sent heartbeat to prevent worker timeout. Next one should arrive within 480 seconds.2021-06-23 23:06:56,057 DEBG 'rqworker_default_1' stderr output:\nDEBUG - 2021-06-23 23:06:56,057 - worker - Sent heartbeat to prevent worker timeout. Next one should arrive within 480 seconds.2021-06-23 23:13:40,979 DEBG 'rqworker_default_0' stderr output:\nDEBUG - 2021-06-23 23:13:40,979 - worker - Sent heartbeat to prevent worker timeout. Next one should arrive within 480 seconds.2021-06-23 23:13:40,979 DEBG 'rqworker_low' stderr output:\nDEBUG - 2021-06-23 23:13:40,979 - worker - Sent heartbeat to prevent worker timeout. Next one should arrive within 480 seconds.2021-06-23 23:13:41,080 DEBG 'rqworker_default_1' stderr output:\nDEBUG - 2021-06-23 23:13:41,079 - worker - Sent heartbeat to prevent worker timeout. Next one should arrive within 480 seconds.2021-06-23 23:20:26,073 DEBG 'rqworker_low' stderr output:\nDEBUG - 2021-06-23 23:20:26,072 - worker - Sent heartbeat to prevent worker timeout. Next one should arrive within 480 seconds.2021-06-23 23:20:26,073 DEBG 'rqworker_default_0' stderr output:\nDEBUG - 2021-06-23 23:20:26,072 - worker - Sent heartbeat to prevent worker timeout. Next one should arrive within 480 seconds.2021-06-23 23:20:26,173 DEBG 'rqworker_default_1' stderr output:\nDEBUG - 2021-06-23 23:20:26,173 - worker - Sent heartbeat to prevent worker timeout. Next one should arrive within 480 seconds.2021-06-23 23:23:39,786 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:23:39.785984 2021] [wsgi:error] [pid 438:tid 140564144842496] [remote 172.21.0.7:60306] [2021-06-23 23:23:39,784] INFO cvat.server.task_140: get repository request2021-06-23 23:23:39,786 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:23:39.786141 2021] [wsgi:error] [pid 438:tid 140564144842496] [remote 172.21.0.7:60306] INFO - 2021-06-23 23:23:39,784 - views - get repository request2021-06-23 23:23:40,883 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:23:40.883380 2021] [wsgi:error] [pid 438:tid 140564161627904] [remote 172.21.0.7:60324] INFO - 2021-06-23 23:23:40,883 - views - {\"client_id\":284839,\"name\":\"Send user activity\",\"time\":\"2021-06-23T23:23:40.837000Z\",\"payload\":{\"working_time\":0},\"is_active\":true,\"username\":\"Davidsoscvat\"}2021-06-23 23:23:58,897 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:23:58.897616 2021] [wsgi:error] [pid 438:tid 140564144842496] [remote 172.21.0.7:60364] [2021-06-23 23:23:58,897] ERROR django.request: Internal Server Error: /api/v1/lambda/functions/pth.shiyinzhang.iog2021-06-23 23:23:58,897 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:23:58.897730 2021] [wsgi:error] [pid 438:tid 140564144842496] [remote 172.21.0.7:60364] ERROR - 2021-06-23 23:23:58,897 - log - Internal Server Error: /api/v1/lambda/functions/pth.shiyinzhang.iog2021-06-23 23:24:06,962 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:24:06.962204 2021] [wsgi:error] [pid 438:tid 140564170020608] [remote 172.21.0.7:60394] [2021-06-23 23:24:06,962] ERROR django.request: Internal Server Error: /api/v1/lambda/functions/pth.shiyinzhang.iog2021-06-23 23:24:06,962 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:24:06.962288 2021] [wsgi:error] [pid 438:tid 140564170020608] [remote 172.21.0.7:60394] ERROR - 2021-06-23 23:24:06,962 - log - Internal Server Error: /api/v1/lambda/functions/pth.shiyinzhang.iog2021-06-23 23:24:12,237 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:24:12.237653 2021] [wsgi:error] [pid 438:tid 140564144842496] [remote 172.21.0.7:60428] INFO - 2021-06-23 23:24:12,237 - views - {\"job_id\":119,\"task_id\":140,\"client_id\":284839,\"name\":\"Load job\",\"time\":\"2021-06-23T23:23:40.837000Z\",\"payload\":{\"duration\":2762,\"frame count\":2,\"track count\":5,\"object count\":5,\"box count\":0,\"polygon count\":5,\"polyline count\":0,\"points count\":0,\"cuboids count\":0,\"tag count\":0},\"is_active\":true,\"username\":\"Davidsoscvat\"}2021-06-23 23:24:12,237 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:24:12.237737 2021] [wsgi:error] [pid 438:tid 140564144842496] [remote 172.21.0.7:60428] INFO - 2021-06-23 23:24:12,237 - views - {\"job_id\":119,\"task_id\":140,\"client_id\":284839,\"name\":\"Fit image\",\"time\":\"2021-06-23T23:23:44.447000Z\",\"payload\":{},\"is_active\":true,\"username\":\"Davidsoscvat\"}\n[Wed Jun 23 23:24:12.237796 2021] [wsgi:error] [pid 438:tid 140564144842496] [remote 172.21.0.7:60428] INFO - 2021-06-23 23:24:12,237 - views - {\"client_id\":284839,\"name\":\"Send user activity\",\"time\":\"2021-06-23T23:24:12.188000Z\",\"payload\":{\"working_time\":11814},\"is_active\":true,\"username\":\"Davidsoscvat\"}2021-06-23 23:27:11,142 DEBG 'rqworker_default_0' stderr output:\nDEBUG - 2021-06-23 23:27:11,140 - worker - Sent heartbeat to prevent worker timeout. Next one should arrive within 480 seconds.2021-06-23 23:27:11,142 DEBG 'rqworker_low' stderr output:\nDEBUG - 2021-06-23 23:27:11,140 - worker - Sent heartbeat to prevent worker timeout. Next one should arrive within 480 seconds.\nINFO - 2021-06-23 23:27:11,141 - worker - Cleaning registries for queue: low2021-06-23 23:27:11,143 DEBG 'rqworker_default_0' stderr output:\nINFO - 2021-06-23 23:27:11,141 - worker - Cleaning registries for queue: default2021-06-23 23:27:11,240 DEBG 'rqworker_default_1' stderr output:\nDEBUG - 2021-06-23 23:27:11,240 - worker - Sent heartbeat to prevent worker timeout. Next one should arrive within 480 seconds.2021-06-23 23:33:56,241 DEBG 'rqworker_default_0' stderr output:\nDEBUG - 2021-06-23 23:33:56,240 - worker - Sent heartbeat to prevent worker timeout. Next one should arrive within 480 seconds.2021-06-23 23:33:56,241 DEBG 'rqworker_low' stderr output:\nDEBUG - 2021-06-23 23:33:56,240 - worker - Sent heartbeat to prevent worker timeout. Next one should arrive within 480 seconds.2021-06-23 23:33:56,339 DEBG 'rqworker_default_1' stderr output:\nDEBUG - 2021-06-23 23:33:56,338 - worker - Sent heartbeat to prevent worker timeout. Next one should arrive within 480 seconds.2021-06-23 23:34:08,087 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:34:08.087036 2021] [wsgi:error] [pid 438:tid 140564161627904] [remote 172.21.0.7:34074] [2021-06-23 23:34:08,086] INFO cvat.server.task_133: get repository request2021-06-23 23:34:08,092 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:34:08.092674 2021] [wsgi:error] [pid 438:tid 140564161627904] [remote 172.21.0.7:34074] INFO - 2021-06-23 23:34:08,086 - views - get repository request2021-06-23 23:34:09,336 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:34:09.336107 2021] [wsgi:error] [pid 438:tid 140564144842496] [remote 172.21.0.7:34094] INFO - 2021-06-23 23:34:09,335 - views - {\"client_id\":284839,\"name\":\"Send user activity\",\"time\":\"2021-06-23T23:34:09.264000Z\",\"payload\":{\"working_time\":0},\"is_active\":true,\"username\":\"Davidsoscvat\"}2021-06-23 23:34:30,213 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:34:30.213556 2021] [wsgi:error] [pid 438:tid 140564170020608] [remote 172.21.0.7:34186] [2021-06-23 23:34:30,213] ERROR django.request: Internal Server Error: /api/v1/lambda/functions/pth.shiyinzhang.iog2021-06-23 23:34:30,214 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:34:30.213875 2021] [wsgi:error] [pid 438:tid 140564170020608] [remote 172.21.0.7:34186] ERROR - 2021-06-23 23:34:30,213 - log - Internal Server Error: /api/v1/lambda/functions/pth.shiyinzhang.iog2021-06-23 23:34:32,006 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:34:32.005893 2021] [wsgi:error] [pid 438:tid 140564161627904] [remote 172.21.0.7:34210] [2021-06-23 23:34:32,005] ERROR django.request: Internal Server Error: /api/v1/lambda/functions/pth.shiyinzhang.iog2021-06-23 23:34:32,006 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:34:32.006247 2021] [wsgi:error] [pid 438:tid 140564161627904] [remote 172.21.0.7:34210] ERROR - 2021-06-23 23:34:32,005 - log - Internal Server Error: /api/v1/lambda/functions/pth.shiyinzhang.iog2021-06-23 23:34:33,437 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:34:33.437583 2021] [wsgi:error] [pid 438:tid 140564170020608] [remote 172.21.0.7:34232] [2021-06-23 23:34:33,437] ERROR django.request: Internal Server Error: /api/v1/lambda/functions/pth.shiyinzhang.iog2021-06-23 23:34:33,438 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:34:33.437708 2021] [wsgi:error] [pid 438:tid 140564170020608] [remote 172.21.0.7:34232] ERROR - 2021-06-23 23:34:33,437 - log - Internal Server Error: /api/v1/lambda/functions/pth.shiyinzhang.iog2021-06-23 23:34:36,137 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:34:36.137761 2021] [wsgi:error] [pid 438:tid 140564161627904] [remote 172.21.0.7:34260] INFO - 2021-06-23 23:34:36,137 - views - {\"job_id\":116,\"task_id\":133,\"client_id\":284839,\"name\":\"Load job\",\"time\":\"2021-06-23T23:34:09.264000Z\",\"payload\":{\"duration\":833,\"frame count\":12,\"track count\":105,\"object count\":105,\"box count\":0,\"polygon count\":105,\"polyline count\":0,\"points count\":0,\"cuboids count\":0,\"tag count\":0},\"is_active\":true,\"username\":\"Davidsoscvat\"}2021-06-23 23:34:36,138 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:34:36.137843 2021] [wsgi:error] [pid 438:tid 140564161627904] [remote 172.21.0.7:34260] INFO - 2021-06-23 23:34:36,137 - views - {\"job_id\":116,\"task_id\":133,\"client_id\":284839,\"name\":\"Fit image\",\"time\":\"2021-06-23T23:34:10.139000Z\",\"payload\":{},\"is_active\":true,\"username\":\"Davidsoscvat\"}\n[Wed Jun 23 23:34:36.137901 2021] [wsgi:error] [pid 438:tid 140564161627904] [remote 172.21.0.7:34260] INFO - 2021-06-23 23:34:36,137 - views - {\"client_id\":284839,\"name\":\"Send user activity\",\"time\":\"2021-06-23T23:34:36.086000Z\",\"payload\":{\"working_time\":23713},\"is_active\":true,\"username\":\"Davidsoscvat\"}2021-06-23 23:34:44,396 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:34:44.396496 2021] [wsgi:error] [pid 438:tid 140564170020608] [remote 172.21.0.7:34322] [2021-06-23 23:34:44,396] WARNING django.request: Not Found: /analytics/app/kibana2021-06-23 23:34:44,397 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:34:44.396831 2021] [wsgi:error] [pid 438:tid 140564170020608] [remote 172.21.0.7:34322] WARNING - 2021-06-23 23:34:44,396 - log - Not Found: /analytics/app/kibana2021-06-23 23:34:48,860 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:34:48.860028 2021] [wsgi:error] [pid 438:tid 140564170020608] [remote 172.21.0.7:34364] ERROR - 2021-06-23 23:34:48,859 - views - {\"system\":\"Windows 10\",\"client\":\"chrome\",\"time\":\"2021-06-23T23:34:48.808000Z\",\"client_id\":284091,\"message\":\"Cannot read property 'toString' of undefined\",\"filename\":\": Cannot read property 'toString' of undefined\\n    at Vl.renderParameters (    at Vl.render (    at $i (    at qi (    at Ss (    at ml (    at fl (    at ol (    at     at t.unstable_runWithPriority ( exception\"}2021-06-23 23:34:57,363 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:34:57.363221 2021] [wsgi:error] [pid 438:tid 140564144842496] [remote 172.21.0.7:34452] [2021-06-23 23:34:57,362] INFO cvat.server.task_130: get repository request2021-06-23 23:34:57,364 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:34:57.363686 2021] [wsgi:error] [pid 438:tid 140564144842496] [remote 172.21.0.7:34452] INFO - 2021-06-23 23:34:57,362 - views - get repository request2021-06-23 23:34:59,443 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:34:59.443628 2021] [wsgi:error] [pid 438:tid 140564170020608] [remote 172.21.0.7:34474] INFO - 2021-06-23 23:34:59,443 - views - {\"client_id\":294787,\"name\":\"Send user activity\",\"time\":\"2021-06-23T23:34:59.387000Z\",\"payload\":{\"working_time\":2496},\"is_active\":true,\"username\":\"Davidsoscvat\"}2021-06-23 23:35:08,814 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:35:08.814735 2021] [wsgi:error] [pid 438:tid 140564144842496] [remote 172.21.0.7:34532] [2021-06-23 23:35:08,814] ERROR django.request: Internal Server Error: /api/v1/lambda/functions/pth.shiyinzhang.iog2021-06-23 23:35:08,815 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:35:08.814857 2021] [wsgi:error] [pid 438:tid 140564144842496] [remote 172.21.0.7:34532] ERROR - 2021-06-23 23:35:08,814 - log - Internal Server Error: /api/v1/lambda/functions/pth.shiyinzhang.iog2021-06-23 23:35:10,055 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:35:10.055407 2021] [wsgi:error] [pid 438:tid 140564153235200] [remote 172.21.0.7:34552] [2021-06-23 23:35:10,055] ERROR django.request: Internal Server Error: /api/v1/lambda/functions/pth.shiyinzhang.iog2021-06-23 23:35:10,056 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:35:10.055704 2021] [wsgi:error] [pid 438:tid 140564153235200] [remote 172.21.0.7:34552] ERROR - 2021-06-23 23:35:10,055 - log - Internal Server Error: /api/v1/lambda/functions/pth.shiyinzhang.iog2021-06-23 23:35:13,050 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:35:13.050817 2021] [wsgi:error] [pid 438:tid 140564144842496] [remote 172.21.0.7:34572] [2021-06-23 23:35:13,050] ERROR django.request: Internal Server Error: /api/v1/lambda/functions/pth.shiyinzhang.iog2021-06-23 23:35:13,051 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:35:13.050897 2021] [wsgi:error] [pid 438:tid 140564144842496] [remote 172.21.0.7:34572] ERROR - 2021-06-23 23:35:13,050 - log - Internal Server Error: /api/v1/lambda/functions/pth.shiyinzhang.iog2021-06-23 23:37:05,001 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:37:05.001058 2021] [wsgi:error] [pid 438:tid 140564153235200] [remote 172.21.0.7:35000] INFO - 2021-06-23 23:37:05,000 - views - {\"job_id\":113,\"task_id\":130,\"client_id\":294787,\"name\":\"Load job\",\"time\":\"2021-06-23T23:34:59.387000Z\",\"payload\":{\"duration\":1648,\"frame count\":14,\"track count\":359,\"object count\":359,\"box count\":0,\"polygon count\":359,\"polyline count\":0,\"points count\":0,\"cuboids count\":0,\"tag count\":0},\"is_active\":true,\"username\":\"Davidsoscvat\"}2021-06-23 23:37:05,001 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:37:05.001187 2021] [wsgi:error] [pid 438:tid 140564153235200] [remote 172.21.0.7:35000] INFO - 2021-06-23 23:37:05,001 - views - {\"job_id\":113,\"task_id\":130,\"client_id\":294787,\"name\":\"Fit image\",\"time\":\"2021-06-23T23:35:01.062000Z\",\"payload\":{},\"is_active\":true,\"username\":\"Davidsoscvat\"}\n[Wed Jun 23 23:37:05.001285 2021] [wsgi:error] [pid 438:tid 140564153235200] [remote 172.21.0.7:35000] INFO - 2021-06-23 23:37:05,001 - views - {\"job_id\":113,\"task_id\":130,\"client_id\":294787,\"name\":\"Zoom image\",\"time\":\"2021-06-23T23:35:02.638000Z\",\"payload\":{},\"is_active\":true,\"username\":\"Davidsoscvat\"}2021-06-23 23:37:05,001 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:37:05.001362 2021] [wsgi:error] [pid 438:tid 140564153235200] [remote 172.21.0.7:35000] INFO - 2021-06-23 23:37:05,001 - views - {\"client_id\":294787,\"name\":\"Send user activity\",\"time\":\"2021-06-23T23:37:04.922000Z\",\"payload\":{\"working_time\":10304},\"is_active\":true,\"username\":\"Davidsoscvat\"}2021-06-23 23:40:41,283 DEBG 'rqworker_default_0' stderr output:\nDEBUG - 2021-06-23 23:40:41,282 - worker - Sent heartbeat to prevent worker timeout. Next one should arrive within 480 seconds.2021-06-23 23:40:41,283 DEBG 'rqworker_low' stderr output:\nDEBUG - 2021-06-23 23:40:41,282 - worker - Sent heartbeat to prevent worker timeout. Next one should arrive within 480 seconds.2021-06-23 23:40:41,383 DEBG 'rqworker_default_1' stderr output:\nDEBUG - 2021-06-23 23:40:41,382 - worker - Sent heartbeat to prevent worker timeout. Next one should arrive within 480 seconds.2021-06-23 23:47:26,315 DEBG 'rqworker_default_0' stderr output:\nDEBUG - 2021-06-23 23:47:26,315 - worker - Sent heartbeat to prevent worker timeout. Next one should arrive within 480 seconds.2021-06-23 23:47:26,315 DEBG 'rqworker_low' stderr output:\nDEBUG - 2021-06-23 23:47:26,315 - worker - Sent heartbeat to prevent worker timeout. Next one should arrive within 480 seconds.2021-06-23 23:47:26,416 DEBG 'rqworker_default_1' stderr output:\nDEBUG - 2021-06-23 23:47:26,415 - worker - Sent heartbeat to prevent worker timeout. Next one should arrive within 480 seconds.2021-06-23 23:47:41,570 DEBG 'runserver' stderr output:\n[Wed Jun 23 23:47:41.570027 2021] [wsgi:error] [pid 438:tid 140564136449792] [remote 172.21.0.7:37268] [2021-06-23 23:47:41,569] INFO cvat.server.task_133: get repository request",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "davodogster",
            "datetime": "Jun 25, 2021",
            "body": " the Nuclio.log is 800MB of letters",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "azhavoro",
            "datetime": "Jun 29, 2021",
            "body": " thanks, I'll try to reproduce",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Jul 6, 2021",
            "body": " , IOG function has non-intuitive interface for now. In the future you should draw a bounding box + a point inside. For now, AI tools doesn't allow to specify a bounding box for  serverless functions. Thus you have to specify two negative points using right mouse click and one positive using left mouse click.Also I have found a problem, that the function doesn't support 4 channel images for now. , could you please improve  interfaces? The function has  in function.yaml. For such functions we need to draw a bounding box at the beginning of the annotation process.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Jul 7, 2021",
            "body": " Sure.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "davodogster",
            "datetime": "Jul 9, 2021",
            "body": " great so all along it has been working, but we didn't know how to use it properly.\nIt's working for me now that I draw the box first - but that is super slow to chop and change from box to interactor for every single instance..Thanks ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Jul 12, 2021",
            "body": "Could you please explain in details? What do you mean?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "davodogster",
            "datetime": "Jul 12, 2021",
            "body": "",
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Jul 12, 2021",
            "body": "Why do you need both segmentation and bounding box? You can get bounding boxes from segmentation masks easily.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "davodogster",
            "datetime": "Jul 12, 2021",
            "body": "",
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Jul 12, 2021",
            "body": " , you need to put 2 negative points which are top left and bottom right corners of the bounding box + a point inside the object.In the future when you use IOTG it will ask you to draw a bounding box first + a point inside the object. It will be the interface of the function.Now IOG doesn't look at the bounding box at all. It uses only several negative points and a positive point which you provide.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "davodogster",
            "datetime": "Jul 12, 2021",
            "body": "Ok currently IOG is working for me but the only way is to draw a bbox first and then click the points. The point I'm trying to make is that annotation speed is slow and it's inefficient to change between bbox and points for every single instance ?? Because that is the only way the tool works ?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Jul 13, 2021",
            "body": " , it looks like there is a problem with your CVAT instance. It should work without the bounding box. I have checked that on my side and if set 2 negative points + 1 positive point, IOG works as expected.\nCould you please record a small video clip to demonstrate the problem if you don't draw a bounding box?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Jul 14, 2021",
            "body": "Now it works this way. The PR will be opened soon.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "davodogster",
            "datetime": "Jul 14, 2021",
            "body": "",
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Jul 15, 2021",
            "body": "No, there is not suchthe feature, but you can submit an issue",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Jul 6, 2021",
            "body": [],
            "type": "self-assigned this",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Jul 6, 2021",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Jul 6, 2021",
            "body": [],
            "type": "changed the title",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Jul 6, 2021",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Jul 14, 2021",
            "body": [],
            "type": "pull",
            "related_issue": "#3417"
        },
        {
            "user_name": "snyk-bot",
            "datetime": "Jul 14, 2021",
            "body": [],
            "type": "pull",
            "related_issue": "hixio-mh/cvat#42"
        },
        {
            "user_name": "nmanovic",
            "datetime": "Jul 20, 2021",
            "body": [],
            "type": "pull",
            "related_issue": null
        },
        {
            "user_name": null,
            "datetime": "Jul 20, 2021",
            "body": [],
            "type": "moved this from",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/2776",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "xs818818",
            "datetime": "Feb 6, 2021",
            "body": "metadata:\nname: darknet-yolov4\nnamespace: cvat\nannotations:\nname: yolov4\ntype: detector\nspec: |\n[\n{ \"id\": 1, \"name\": \"person\" },\n{ \"id\": 2, \"name\": \"bicycle\" },\n{ \"id\": 3, \"name\": \"car\" },\n{ \"id\": 4, \"name\": \"motorbike\" },\n{ \"id\": 5, \"name\": \"aeroplane\" },\n{ \"id\": 6, \"name\": \"bus\" },\n{ \"id\": 8, \"name\": \"train\" },\n{ \"id\": 9, \"name\": \"truck\" },\n{ \"id\": 10, \"name\": \"boat\" },\n{ \"id\": 11, \"name\": \"traffic light\" },\n{ \"id\": 12, \"name\": \"fire hydrant\" },\n{ \"id\": 13, \"name\": \"stop sign\" },\n{ \"id\": 14, \"name\": \"parking meter\" },\n{ \"id\": 15, \"name\": \"bird\" },\n{ \"id\": 16, \"name\": \"cat\" },\n{ \"id\": 17, \"name\": \"dog\" },\n{ \"id\": 18, \"name\": \"horse\" },\n{ \"id\": 19, \"name\": \"sheep\" },\n{ \"id\": 20, \"name\": \"cow\" },\n{ \"id\": 21, \"name\": \"elephant\" },\n{ \"id\": 22, \"name\": \"bear\" },\n{ \"id\": 23, \"name\": \"zebra\" },\n{ \"id\": 24, \"name\": \"giraffe\" },\n{ \"id\": 25, \"name\": \"backpack\" },\n{ \"id\": 26, \"name\": \"umbrella\" },\n{ \"id\": 27, \"name\": \"handbag\" },\n{ \"id\": 28, \"name\": \"tie\" },\n{ \"id\": 29, \"name\": \"suitcase\" },\n{ \"id\": 30, \"name\": \"frisbee\" },\n{ \"id\": 31, \"name\": \"skis\" },\n{ \"id\": 32, \"name\": \"snowboard\" },\n{ \"id\": 33, \"name\": \"sports ball\" },\n{ \"id\": 34, \"name\": \"kite\" },\n{ \"id\": 35, \"name\": \"baseball bat\" },\n{ \"id\": 36, \"name\": \"baseball glove\" },\n{ \"id\": 37, \"name\": \"skateboard\" },\n{ \"id\": 38, \"name\": \"surfboard\" },\n{ \"id\": 39, \"name\": \"tennis racket\" },\n{ \"id\": 40, \"name\": \"bottle\" },\n{ \"id\": 41, \"name\": \"wine glass\" },\n{ \"id\": 42, \"name\": \"cup\" },\n{ \"id\": 43, \"name\": \"fork\" },\n{ \"id\": 44, \"name\": \"knife\" },\n{ \"id\": 45, \"name\": \"spoon\" },\n{ \"id\": 46, \"name\": \"bowl\" },\n{ \"id\": 47, \"name\": \"banana\" },\n{ \"id\": 48, \"name\": \"apple\" },\n{ \"id\": 49, \"name\": \"sandwich\" },\n{ \"id\": 50, \"name\": \"orange\" },\n{ \"id\": 51, \"name\": \"broccoli\" },\n{ \"id\": 52, \"name\": \"carrot\" },\n{ \"id\": 53, \"name\": \"hot dog\" },\n{ \"id\": 54, \"name\": \"pizza\" },\n{ \"id\": 55, \"name\": \"donut\" },\n{ \"id\": 56, \"name\": \"cake\" },\n{ \"id\": 57, \"name\": \"chair\" },\n{ \"id\": 58, \"name\": \"sofa\" },\n{ \"id\": 59, \"name\": \"pottedplant\" },\n{ \"id\": 60, \"name\": \"bed\" },\n{ \"id\": 61, \"name\": \"diningtable\" },\n{ \"id\": 62, \"name\": \"toilet\" },\n{ \"id\": 63, \"name\": \"tvmonitor\" },\n{ \"id\": 64, \"name\": \"laptop\" },\n{ \"id\": 65, \"name\": \"mouse\" },\n{ \"id\": 66, \"name\": \"remote\" },\n{ \"id\": 67, \"name\": \"keyboard\" },\n{ \"id\": 68, \"name\": \"cell phone\" },\n{ \"id\": 69, \"name\": \"microwave\" },\n{ \"id\": 70, \"name\": \"oven\" },\n{ \"id\": 71, \"name\": \"toaster\" },\n{ \"id\": 72, \"name\": \"sink\" },\n{ \"id\": 73, \"name\": \"refrigerator\" },\n{ \"id\": 74, \"name\": \"book\" },\n{ \"id\": 75, \"name\": \"clock\" },\n{ \"id\": 76, \"name\": \"vase\" },\n{ \"id\": 77, \"name\": \"scissors\" },\n{ \"id\": 78, \"name\": \"teddy bear\" },\n{ \"id\": 79, \"name\": \"hair drier\" },\n{ \"id\": 80, \"name\": \"toothbrush\" },\n]\nframework: darknetspec:\ndescription: yolov4 from darknet Object Detection API\nruntime: 'python:3.6'\nhandler: main:handler\neventTimeout: 30sbuild:\nimage: cvat/darknet.yolov4\nbaseImage: baoxin/darknettriggers:\nmyHttpTrigger:\nmaxWorkers: 2\nkind: 'http'\nworkerAvailabilityTimeoutMilliseconds: 10000\nattributes:\nmaxRequestBodySize: 33554432 # 32MBplatform:\nattributes:\nrestartPolicy:\nname: always\nmaximumRetryCount: 3\nThis is my function.yaml\nnuclio :8070/projects/cvat/functions is running\nbut cvat Could not get models from the server\nOpen the Browser Console to get details",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "xs818818",
            "datetime": "Feb 6, 2021",
            "body": "If i only use siammask i will success",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "spatra007",
            "datetime": "May 11, 2021",
            "body": "Hi  , were you able to run this? I am stuck with this in my project and I want to deploy my custom yolov4 darknet model in Nuclio for CVAT auto annotations. Can you share the function and yaml file or atleast a way so that I can refer how to make it work?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "May 11, 2021",
            "body": " , please start to read the tutorial. I hope it can help you. ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "gautami-yara",
            "datetime": "Sep 15, 2021",
            "body": " Hi, the tutorial at  is not very helpful as it does tell us how we can change the function.yaml file to upload our own custom Yolov3 models from local machine. Can you please help us?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Sep 15, 2021",
            "body": " , could you please describe your issue? The tutorial describes how to create a serverless function from scratch. Thus it should answer how to update function.yaml file. I will be happy to answer on a specific question.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "gautami-yara",
            "datetime": "Sep 15, 2021",
            "body": " Thank you for replying so promptly. I have built a custom YoloV3 model in my local machine. I am not sure what parameters are supposed to be added in the 'Directives' section in function.yaml file to deploy the model on nuclio. Currently, the tutorial (specifically retinanet) only tells how to use opensource models from model zoos.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Sep 15, 2021",
            "body": " section should contain steps to re-create your local environment inside a docker container. For example, locally you can have  script to run inference of your model. The script depends on a number of python packages. Thus you have to install them. The script can rely on Python3. Thus it has to be available inside the docker container.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "gautami-yara",
            "datetime": "Sep 16, 2021",
            "body": " I understand now. Does this also mean that we can deploy models in every format (.h5, .onnx, .pb, etc) as long as we install the correct python packages? Thank you!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Sep 16, 2021",
            "body": " , basically you can do that ever you want as soon as your serverless function will accept and return expected json sctructures.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "xs818818",
            "datetime": "Feb 6, 2021",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/2713",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "valeriyvan",
            "datetime": "Jan 24, 2021",
            "body": "Currently if label selected in dropdown is inside of bounds of popup, popup stays open allowing annotator to choose labelling method pressing [Shape] or [Track] buttons:But if selected label is beyond bounds of popup, it hides. Annotator has to open popup once again to choose labelling method by pressing [Shape] or [Track] buttons.:In both cases popup should not hide allowing annotator press [Shape] or [Track] buttons.Popup hides unexpectedly. Annotator has to open popup again.Possible solution: if selected labels is inside bounds of popup, behaviour stays the same - popup hides. If selected label is beyond bounds of popup, it stays open until user presses [Shape] or [Track] buttons or until user moves mouse so that mouse pointer goes beyond right edge of popup (mouse y coordinate become greater then popup's greatest y coordinate).Look gifs attached.n/a",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Jan 25, 2021",
            "body": " ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "valeriyvan",
            "datetime": "Jan 25, 2021",
            "body": "Yes, but  is about different popups.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "valeriyvan",
            "datetime": "Jan 25, 2021",
            "body": "Any plans to fix?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Jan 26, 2021",
            "body": "Yes, we have plans to fix it.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "valeriyvan",
            "datetime": "Jan 26, 2021",
            "body": "Create! Does it fit next release?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Jan 26, 2021",
            "body": "We will try to implement it earlier than in next release. It will be available in develop branch",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Jan 25, 2021",
            "body": [],
            "type": "marked this as    a duplicate of",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Jan 26, 2021",
            "body": [],
            "type": "added this to the",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Jan 26, 2021",
            "body": [],
            "type": "self-assigned this",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Jan 26, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Feb 15, 2021",
            "body": [],
            "type": "pull",
            "related_issue": "#2809"
        },
        {
            "user_name": "bsekachev",
            "datetime": "Feb 20, 2021",
            "body": [],
            "type": "pull",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/2820",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "miseonkang",
            "datetime": "Feb 17, 2021",
            "body": "I am currently testing the work on the CVAT site(cvat.org), and I tried to find cars and people using the automatic detector function using Yolov3 of AI TOOL.\nHowever, the following message appears.Is there no workaround?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Feb 17, 2021",
            "body": "Hi,Try to re-deploy the model.\nProbably related ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "miseonkang",
            "datetime": "Feb 18, 2021",
            "body": "my problem is not related . i am testing the work on the CVAT site(cvat.org). not localhost:8080 site.  I haven't installed cvat on my machine. Only logging into the site and testing.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Feb 18, 2021",
            "body": " ,We have fixed the issue on CVAT.org. Could you please specify a task where it doesn't work? I will double check.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "miseonkang",
            "datetime": "Feb 18, 2021",
            "body": "When I run it on the site now, the auto anotation function is running. Thanks for fixing it.May I ask you one more question,I am installing cvat on local. While installing the semi-automation function, the nuctl-linux-1.5.16 version file in git bash is not installed due to the following problems.chmod +x nuctl-linux-1.5.16Command does not apply. How can this be solved?./nuctl-1.5.16-linux-amd64File properties are not changed to executable files. The windows version file is executed, but the semi-automation function cannot be installed because this file cannot be executed.And, among the semi-automation functions in cvat, there is a video that automatically performs segmentation by spotting it. Is this using ai tool or which tool is used?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Feb 18, 2021",
            "body": "I see you try to add executable flag and run different files",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "miseonkang",
            "datetime": "Feb 22, 2021",
            "body": "Is there any different file??\nI downloaded it from the site here()\nAre there any other download sites?my OS : Windows 10, docker, git-bash window...",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Feb 22, 2021",
            "body": "You apply  to file \"nuctl-linux-1.5.16\". Then you try to run \"nuctl-1.5.16-linux-amd64\". They have different names, don't they?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "miseonkang",
            "datetime": "Feb 22, 2021",
            "body": "i tried to chmod +x nuctl-linux-1.5.16.. that doesn't work.chmod: cannot access 'nuctl-linux-1.5.16': No such file or directory",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "miseonkang",
            "datetime": "Feb 23, 2021",
            "body": "so i install ubuntu 16.04  cvat..\nsuccess install nuctl..but i have error message like this  (when install   =>   nuctl deploy --project-name cvat \n--path serverless/openvino/dextr/nuclio \n--volume /serverless/openvino/common:/opt/nuclio/common \n--platform local)21.02.23 07:54:17.485 cessor.healthcheck.server (I) Listening {\"listenAddress\": \":8082\"}\n21.02.23 07:54:17.485            processor.http (D) Creating worker pool {\"num\": 2}\n21.02.23 07:54:17.485 sor.http.w1.python.logger (D) Creating listener socket {\"path\": \"/tmp/nuclio-rpc-c0qb9aflufhca7t2blug.sock\"}\n21.02.23 07:54:17.485 sor.http.w0.python.logger (D) Creating listener socket {\"path\": \"/tmp/nuclio-rpc-c0qb9aflufhca7t2blv0.sock\"}\n21.02.23 07:54:17.485 sor.http.w1.python.logger (D) Using Python wrapper script path {\"path\": \"/opt/nuclio/_nuclio_wrapper.py\"}\n21.02.23 07:54:17.485 sor.http.w1.python.logger (D) Using Python handler {\"handler\": \"main:handler\"}\n21.02.23 07:54:17.486 sor.http.w1.python.logger (E) Can't find Python exe {\"error\": \"exec: \"/opt/nuclio/common/openvino/python3\": stat /opt/nuclio/common/openvino/python3: no such file or directory\"}\n21.02.23 07:54:17.486 sor.http.w0.python.logger (D) Using Python wrapper script path {\"path\": \"/opt/nuclio/_nuclio_wrapper.py\"}\n21.02.23 07:54:17.486 sor.http.w0.python.logger (D) Using Python handler {\"handler\": \"main:handler\"}\n21.02.23 07:54:17.486 sor.http.w0.python.logger (E) Can't find Python exe {\"error\": \"exec: \"/opt/nuclio/common/openvino/python3\": stat /opt/nuclio/common/openvino/python3: no such file or directory\"}Error - exec: \"/opt/nuclio/common/openvino/python3\": stat /opt/nuclio/common/openvino/python3: no such file or directory\n...//nuclio/pkg/processor/runtime/rpc/abstract.go:231how can i solve???",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "AlexandrMoruk",
            "datetime": "Feb 23, 2021",
            "body": "I have version 1.5.16 but still the problemMaybe I didn't write the correct path?\nVersion:",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "miseonkang",
            "datetime": "Feb 24, 2021",
            "body": "So, what version can be installed to use the Semi-automatic and Automatic Annotation tool?Can I install a lower version?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Feb 24, 2021",
            "body": " ,",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "AlexandrMoruk",
            "datetime": "Feb 24, 2021",
            "body": "Then a very long log output. The end of the output looks like this:",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Feb 24, 2021",
            "body": "If you find the command in documentation, need to update it. The path to the volume wasn't correct. Please use the command below:Also it is better to use scripts inside serverless directory. They should work out of the box: ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "AlexandrMoruk",
            "datetime": "Feb 24, 2021",
            "body": "Thank you very much, i did as you said above and it worked",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "miseonkang",
            "datetime": "Feb 25, 2021",
            "body": "i run nuctl version`user01@kmsDeepServer01:~/cvat/serverless$ ./deploy_cpu.sh openvino/dextr/\nDeploying openvino/dextr function...\n21.02.25 09:02:14.011                     nuctl (I) Deploying function {\"name\": \"\"}\n21.02.25 09:02:14.011                     nuctl (I) Building {\"versionInfo\": \"Label: 1.5.16, Git commit: ae4                                                                      3a6a560c2bec42d7ccfdf6e8e11a1e3cc3774, OS: linux, Arch: amd64, Go version: go1.14.3\", \"name\": \"\"}\n21.02.25 09:02:14.353                     nuctl (I) Cleaning up before deployment {\"functionName\": \"openvino                                                                      -dextr\"}\n21.02.25 09:02:14.447                     nuctl (I) Function already exists, deleting function containers {\"                                                                      functionName\": \"openvino-dextr\"}\n21.02.25 09:02:14.569                     nuctl (I) Staging files and preparing base images\n21.02.25 09:02:14.570                     nuctl (I) Building processor image {\"imageName\": \"cvat/openvino.de                                                                      xtr:latest\"}\n21.02.25 09:02:14.570     nuctl.platform.docker (I) Pulling image {\"imageName\": \"quay.io/nuclio/handler-buil                                                                      der-python-onbuild:1.5.16-amd64\"}\n21.02.25 09:02:18.798     nuctl.platform.docker (I) Pulling image {\"imageName\": \"quay.io/nuclio/uhttpc:0.0.1                                                                      -amd64\"}\n21.02.25 09:02:24.332            nuctl.platform (I) Building docker image {\"image\": \"cvat/openvino.dextr:lat                                                                      est\"}\n21.02.25 09:02:24.655            nuctl.platform (I) Pushing docker image into registry {\"image\": \"cvat/openv                                                                      ino.dextr:latest\", \"registry\": \"\"}\n21.02.25 09:02:24.655            nuctl.platform (I) Docker image was successfully built and pushed into dock                                                                      er registry {\"image\": \"cvat/openvino.dextr:latest\"}\n21.02.25 09:02:24.655                     nuctl (I) Build complete {\"result\": {\"Image\":\"cvat/openvino.dextr:                                                                      latest\",\"UpdatedFunctionConfig\":{\"metadata\":{\"name\":\"openvino-dextr\",\"namespace\":\"nuclio\",\"labels\":{\"nuclio.                                                                      io/project-name\":\"cvat\"},\"annotations\":{\"framework\":\"openvino\",\"min_pos_points\":\"4\",\"name\":\"DEXTR\",\"spec\":\"\"                                                                      ,\"type\":\"interactor\"}},\"spec\":{\"description\":\"Deep Extreme Cut\",\"handler\":\"main:handler\",\"runtime\":\"python:3                                                                      .6\",\"env\":[{\"name\":\"NUCLIO_PYTHON_EXE_PATH\",\"value\":\"/opt/nuclio/common/openvino/python3\"}],\"resources\":{},\"                                                                      image\":\"cvat/openvino.dextr:latest\",\"targetCPU\":75,\"triggers\":{\"myHttpTrigger\":{\"class\":\"\",\"kind\":\"http\",\"na                                                                      me\":\"myHttpTrigger\",\"maxWorkers\":2,\"workerAvailabilityTimeoutMilliseconds\":10000,\"attributes\":{\"maxRequestBo                                                                      dySize\":33554432}}},\"volumes\":[{\"volume\":{\"name\":\"volume-1\",\"hostPath\":{\"path\":\"/home/user01/cvat/serverless                                                                      /common\"}},\"volumeMount\":{\"name\":\"volume-1\",\"mountPath\":\"/opt/nuclio/common\"}}],\"build\":{\"image\":\"cvat/openv                                                                      ino.dextr\",\"baseImage\":\"openvino/ubuntu18_runtime:2020.2\",\"directives\":{\"postCopy\":[{\"kind\":\"RUN\",\"value\":\"c                                                                      url -O https://download.01.org/openvinotoolkit/models_contrib/cvat/dextr_model_v1.zip\"},{\"kind\":\"RUN\",\"value                                                                      \":\"unzip dextr_model_v1.zip\"},{\"kind\":\"RUN\",\"value\":\"pip3 install Pillow\"}],\"preCopy\":[{\"kind\":\"USER\",\"value                                                                      \":\"root\"},{\"kind\":\"WORKDIR\",\"value\":\"/opt/nuclio\"},{\"kind\":\"RUN\",\"value\":\"ln -s /usr/bin/pip3 /usr/bin/pip\"}                                                                      ]},\"codeEntryType\":\"image\"},\"platform\":{\"attributes\":{\"mountMode\":\"volume\",\"restartPolicy\":{\"maximumRetryCou                                                                      nt\":3,\"name\":\"always\"}}},\"readinessTimeoutSeconds\":60,\"securityContext\":{},\"eventTimeout\":\"30s\"}}}}\n21.02.25 09:02:26.239            nuctl.platform (I) Waiting for function to be ready {\"timeout\": 60}\n21.02.25 09:02:27.542                     nuctl (I) Function deploy complete {\"functionName\": \"openvino-dext                                                                      r\", \"httpPort\": 53441}\nNAMESPACE |              NAME              | PROJECT |  STATE   | NODE PORT | REPLICAS\nnuclio    | openvino-dextr                 | cvat    | ready    |     53441 | 1/1\nnuclio    | openvino-omz-public-yolo-v3-tf | cvat    | building |         0 | 1/1wow!! thank you!!!!\nopenvino-dextr  state ready!!!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "miseonkang",
            "datetime": "Feb 25, 2021",
            "body": "Installation was successful.However, if you do DEXTR in task task at localhost:8080, the following message appears.How to fix this error? ??",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "AlexandrMoruk",
            "datetime": "Feb 25, 2021",
            "body": "I have same problem. I think the difference is in the requests tnat the CVAT send.\nOn CVAT.org request for fbrs looks like:\nBut on localhost it is different:\n\nand i get 500 error\nWhy does the CVAT send requests with another fields?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Feb 25, 2021",
            "body": "Looks like your localhost wasn't updated.\nSend us a version: user dropdown at top right corner -> About",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Feb 25, 2021",
            "body": "You can also try to update page with enabled checkbox \"Disable cache\". JS page you use, theoretically might be cached by a browser (with old version)",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "AlexandrMoruk",
            "datetime": "Feb 25, 2021",
            "body": "like the latest version\n\"Disable cache\" doesn't work too",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "AlexandrMoruk",
            "datetime": "Feb 25, 2021",
            "body": "Yesterday the fbrs on cvat.org also did not work, maybe something was fixed there?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "azhavoro",
            "datetime": "Feb 25, 2021",
            "body": " If you use develop branch you should build images with  command. Only release images v1.2.0 are available on the Dockerhub that dont yet support this unreleased functionality.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Mar 8, 2021",
            "body": " ,  , I will close the issue. Please don't hesitate to reopen it, if you still can reproduce it on the latest develop branch.P.S. I have checked and FBRS works on CVAT.org now.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Ashish-25-11",
            "datetime": "Jul 11, 2022",
            "body": "nuctl deploy --project-name cvat \n--path serverless/openvino/dextr/nuclio \n--volume /serverless/common:/opt/nuclio/common \n--platform local\nI am running the above command and getting the error which is shown belowError - exec: \"/opt/nuclio/common/openvino/python3\": stat /opt/nuclio/common/openvino/python3: no such file or directory\n...//nuclio/pkg/processor/runtime/rpc/abstract.go:239Any soltuion",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Feb 25, 2021",
            "body": [],
            "type": "issue",
            "related_issue": "#2844"
        },
        {
            "user_name": "nmanovic",
            "datetime": "Mar 8, 2021",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/2692",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "Smirkey",
            "datetime": "Jan 20, 2021",
            "body": "Hi :)When I try to use the split function on a polygon/boundingbox nothing appens. My cursors changes and when I drag the mouse over a bbx/poly the object becomes blue, but when I click nothing appens. Am i missing something here?My goal is to be able to cut a polygon in two by drawing a cutting line.Thanks !",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Jan 20, 2021",
            "body": "Hi The function of split doesn't cut a polygon into several polygons by cutting line (CVAT doesn't have such a function like you described).\nPlease, refer to user guide.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Jan 21, 2021",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/2650",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "Smirkey",
            "datetime": "Jan 8, 2021",
            "body": "Hello, when I draw a boundingBox (2 points) in track mode it's totally possible to drag it on the image. But sadly when I try the same thing with a polygon the whole image moves instead of moving the polygon on the image.I couldn't find anything in the docs or in previous issues related to this problem.Thanks in advance for your response :)Best",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "azhavoro",
            "datetime": "Jan 13, 2021",
            "body": " could you please take a look?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Jan 14, 2021",
            "body": "Hi, thanks for your concern.\nPolygons are default \"pinned\" and cannot be moved (in the most of task you do not need to move an entire polygon).\nTo do them \"unpinned\" press the icon button (shown on the screenshot below)\n",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Smirkey",
            "datetime": "Jan 14, 2021",
            "body": "Thank you :) !",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "mohammadreza-sheykhmousa",
            "datetime": "Dec 7, 2021",
            "body": "Hi  there actually are many instances that suffer from mismatching thus it is crucial to move ans also sometimes to rotate multiple polygons at once. I know about the unpinning, however I was wondering is there any other convenient way of moving (single or multiple at once) polygons? How about rotating? if not is there any plan to add such capabilities -- which seems crucial to many geospatial data labeling-- to CVAT? I appreciate the help and thank you :)",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Dec 8, 2021",
            "body": "Hi We do not have these features in our current road map. Since our team has limited resources we can't satisfy all the community requests. But CVAT is an open source tool which everyone can contribute into, and we would like to review community PRs, provide feedbacks, and give advice if necessary",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "azhavoro",
            "datetime": "Jan 13, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Jan 14, 2021",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/2587",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "ITBOX-ITBOY",
            "datetime": "Dec 17, 2020",
            "body": "Model deployment statement：nuctl deploy --project-name cvat \n--path $SCRIPT_DIR/tensorflow/faster_rcnn_inception_v2_coco/nuclio \n--platform localThe configuration file is as follows：\nfunctions.yamlmetadata:\nname: tf-faster-rcnn-inception-v2-coco\nnamespace: cvat\nannotations:\nname: Faster RCNN via Tensorflow\ntype: detector\nframework: tensorflow\nspec: |\n[\n{ \"id\": 1, \"name\": \"person\" },\n{ \"id\": 2, \"name\": \"bicycle\" },\n{ \"id\": 3, \"name\": \"car\" },\n{ \"id\": 4, \"name\": \"motorcycle\" },\n{ \"id\": 5, \"name\": \"airplane\" },\n{ \"id\": 6, \"name\": \"bus\" },\n{ \"id\": 7, \"name\": \"train\" },\n{ \"id\": 8, \"name\": \"truck\" },\n{ \"id\": 9, \"name\": \"boat\" },\n{ \"id\":10, \"name\": \"traffic_light\" },\n{ \"id\":11, \"name\": \"fire_hydrant\" },\n{ \"id\":13, \"name\": \"stop_sign\" },\n{ \"id\":14, \"name\": \"parking_meter\" },\n{ \"id\":15, \"name\": \"bench\" },\n{ \"id\":16, \"name\": \"bird\" },\n{ \"id\":17, \"name\": \"cat\" },\n{ \"id\":18, \"name\": \"dog\" },\n{ \"id\":19, \"name\": \"horse\" },\n{ \"id\":20, \"name\": \"sheep\" },\n{ \"id\":21, \"name\": \"cow\" },\n{ \"id\":22, \"name\": \"elephant\" },\n{ \"id\":23, \"name\": \"bear\" },\n{ \"id\":24, \"name\": \"zebra\" },\n{ \"id\":25, \"name\": \"giraffe\" },\n{ \"id\":27, \"name\": \"backpack\" },\n{ \"id\":28, \"name\": \"umbrella\" },\n{ \"id\":31, \"name\": \"handbag\" },\n{ \"id\":32, \"name\": \"tie\" },\n{ \"id\":33, \"name\": \"suitcase\" },\n{ \"id\":34, \"name\": \"frisbee\" },\n{ \"id\":35, \"name\": \"skis\" },\n{ \"id\":36, \"name\": \"snowboard\" },\n{ \"id\":37, \"name\": \"sports_ball\" },\n{ \"id\":38, \"name\": \"kite\" },\n{ \"id\":39, \"name\": \"baseball_bat\" },\n{ \"id\":40, \"name\": \"baseball_glove\" },\n{ \"id\":41, \"name\": \"skateboard\" },\n{ \"id\":42, \"name\": \"surfboard\" },\n{ \"id\":43, \"name\": \"tennis_racket\" },\n{ \"id\":44, \"name\": \"bottle\" },\n{ \"id\":46, \"name\": \"wine_glass\" },\n{ \"id\":47, \"name\": \"cup\" },\n{ \"id\":48, \"name\": \"fork\" },\n{ \"id\":49, \"name\": \"knife\" },\n{ \"id\":50, \"name\": \"spoon\" },\n{ \"id\":51, \"name\": \"bowl\" },\n{ \"id\":52, \"name\": \"banana\" },\n{ \"id\":53, \"name\": \"apple\" },\n{ \"id\":54, \"name\": \"sandwich\" },\n{ \"id\":55, \"name\": \"orange\" },\n{ \"id\":56, \"name\": \"broccoli\" },\n{ \"id\":57, \"name\": \"carrot\" },\n{ \"id\":58, \"name\": \"hot_dog\" },\n{ \"id\":59, \"name\": \"pizza\" },\n{ \"id\":60, \"name\": \"donut\" },\n{ \"id\":61, \"name\": \"cake\" },\n{ \"id\":62, \"name\": \"chair\" },\n{ \"id\":63, \"name\": \"couch\" },\n{ \"id\":64, \"name\": \"potted_plant\" },\n{ \"id\":65, \"name\": \"bed\" },\n{ \"id\":67, \"name\": \"dining_table\" },\n{ \"id\":70, \"name\": \"toilet\" },\n{ \"id\":72, \"name\": \"tv\" },\n{ \"id\":73, \"name\": \"laptop\" },\n{ \"id\":74, \"name\": \"mouse\" },\n{ \"id\":75, \"name\": \"remote\" },\n{ \"id\":76, \"name\": \"keyboard\" },\n{ \"id\":77, \"name\": \"cell_phone\" },\n{ \"id\":78, \"name\": \"microwave\" },\n{ \"id\":79, \"name\": \"oven\" },\n{ \"id\":80, \"name\": \"toaster\" },\n{ \"id\":81, \"name\": \"sink\" },\n{ \"id\":83, \"name\": \"refrigerator\" },\n{ \"id\":84, \"name\": \"book\" },\n{ \"id\":85, \"name\": \"clock\" },\n{ \"id\":86, \"name\": \"vase\" },\n{ \"id\":87, \"name\": \"scissors\" },\n{ \"id\":88, \"name\": \"teddy_bear\" },\n{ \"id\":89, \"name\": \"hair_drier\" },\n{ \"id\":90, \"name\": \"toothbrush\" }\n]spec:\ndescription: Faster RCNN from Tensorflow Object Detection API\nruntime: \"python:3.6\"\nhandler: main:handler\neventTimeout: 30s\nimage: 47.104.169.133:8888/cvat/tf.faster_rcnn_inception_v2_coco:latest\nimagePullPolicy: Never\nserviceType: NodePort\nminReplicas: 1\nmaxReplicas: 3\ntriggers:\nmyHttpTrigger:\nmaxWorkers: 2\nkind: \"http\"\nworkerAvailabilityTimeoutMilliseconds: 10000\nattributes:\nmaxRequestBodySize: 33554432 # 32MBplatform:\nattributes:\nrestartPolicy:\nname: always\nmaximumRetryCount: 3Partial logs after execution：[root@master serverless]# nuctl deploy --project-name cvat --path $SCRIPT_DIR/tensorflow/faster_rcnn_inception_v2_coco/nuclio --namespace nuclio --kubeconfig /etc/kubernetes/admin.conf --platform kube\n20.12.18 10:17:38.202                     nuctl (I) Deploying function {\"name\": \"\"}\n20.12.18 10:17:38.203                     nuctl (I) Building {\"versionInfo\": \"Label: 1.5.8, Git commit: c12022750a6003a309d4f20c72a98addacd3e95d, OS: linux, Arch: amd64, Go version: go1.14.3\", \"name\": \"\"}\n20.12.18 10:17:38.284                     nuctl (I) Staging files and preparing base images\n20.12.18 10:17:38.284                     nuctl (I) Building processor image {\"imageName\": \"nuclio/processor-tf-faster-rcnn-inception-v2-coco:latest\"}\n20.12.18 10:17:38.284     nuctl.platform.docker (I) Pulling image {\"imageName\": \"quay.io/nuclio/handler-builder-python-onbuild:1.5.8-amd64\"}Spec. image I have specified my own custom image, why not use a custom image instead of nuclio/ processor-TF-faster - rCNN-inception -v2-coco:latestAfter I execute the following command, image uses custom：nuctl deploy --project-name cvat \n--path $SCRIPT_DIR/tensorflow/faster_rcnn_inception_v2_coco/nuclio \n--image 47.104.169.133:8888/cvat/tf.faster_rcnn_inception_v2_coco:latest\n--platform localPartial logs after execution：\n[root@master serverless]# nuctl deploy --project-name cvat --path $SCRIPT_DIR/tensorflow/faster_rcnn_inception_v2_coco/nuclio --namespace nuclio --kubeconfig /etc/kubernetes/admin.conf --platform kube\n20.12.18 10:17:38.202                     nuctl (I) Deploying function {\"name\": \"\"}\n20.12.18 10:17:38.203                     nuctl (I) Building {\"versionInfo\": \"Label: 1.5.8, Git commit: c12022750a6003a309d4f20c72a98addacd3e95d, OS: linux, Arch: amd64, Go version: go1.14.3\", \"name\": \"\"}\n20.12.18 10:17:38.284                     nuctl (I) Staging files and preparing base images\n20.12.18 10:17:38.284                     nuctl (I) Building processor image {\"imageName\": \"47.104.169.133:8888/cvat/tf.faster_rcnn_inception_v2_coco:latest\"}\n20.12.18 10:17:38.284     nuctl.platform.docker (I) Pulling image {\"imageName\": \"quay.io/nuclio/handler-builder-python-onbuild:1.5.8-amd64\"}Is there any difference between using image in functions.YAMl definition and using image in nuctl execution command",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "azhavoro",
            "datetime": "Dec 24, 2020",
            "body": " Please ask this question nuclio developers",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "azhavoro",
            "datetime": "Dec 24, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Dec 28, 2020",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/2329",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "arasharchor",
            "datetime": "Oct 17, 2020",
            "body": "If a point is selected and mouse gets away from it, its size shall not change similar to the early versions.When a point is select and mouse gets away from it, it becomes significantly bigger which hinders to see the area near that point.\n\n\n\n\n\nReverting back to the previous settings?!It does not allow fine annotation because it blocks to see area near that point.Origin/develop branch - 19th October 2020\nLinux",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Oct 18, 2020",
            "body": "Please, provide exact version (not ) and git hash.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Oct 18, 2020",
            "body": "I would say we have fixed similar issue in ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "arasharchor",
            "datetime": "Oct 20, 2020",
            "body": "Oops!\n\nI used the \"origin/develop\" branch which has the commit dating until October 9th. 2020. I did not use any specific git tags as I wanted to clone the latest develop version.\nI see the commit below as the latest commit by calling \"git log\"commit \nAuthor: tdowgiel \nDate:   Fri Oct 9 21:13:47 2020 +0200Thanks. I see issue in  dates back to 8 days ago. I will pull the merge and try again. I will update this issue afterwards.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "arasharchor",
            "datetime": "Oct 20, 2020",
            "body": "I just pulled the repo by \"git pull\" and compiled it again\n\"docker-compose -f docker-compose.yml -f components/serverless/docker-compose.serverless.yml -f components/analytics/docker-compose.analytics.yml  up -d\"\nStill points appear to be bigger when selected and released.Is there any way to define the point size when released?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Oct 20, 2020",
            "body": " doesn't rebuild image.\nYou need to use ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "arasharchor",
            "datetime": "Oct 21, 2020",
            "body": "\nOh I missed it. Now it is being built, but it takes long to finish.\nIn this way, even by a tiny modification in the code, the whole repo has to be built again.\nI am wondering whether there is any alternatives to compile the code faster and see the changes.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Oct 21, 2020",
            "body": "@smajidaInternally we use docker deployment only for production. For development & debugging we install the whole system on a host operating system. The process is described in CONTRIBUTING.md",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "arasharchor",
            "datetime": "Oct 22, 2020",
            "body": "\nThanks for the explanation.\nI can confirm that the issue has been solved. I will then close the issue.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "arasharchor",
            "datetime": "Oct 17, 2020",
            "body": [],
            "type": "changed the title",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Oct 21, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "arasharchor",
            "datetime": "Oct 22, 2020",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/2317",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "cpudney",
            "datetime": "Oct 13, 2020",
            "body": "It would be useful if keyboard shortcuts existed for the labels used during an annotation task.During the annotation process it is often necessary to change to a different label from the current one. This involves using the mouse to select the label in the annotation widgets on the left-hand side of the GUI. Providing this action via a shortcut would make annotation more facile and quicker.The shortcuts could be keys: 0 ... 9 and would correspond to the (first 10) labels (e.g. alphabetically ordered).",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Oct 13, 2020",
            "body": "Hi,One question here. Where a label should be changed? In all drawing popups? Or on the latest used? Or only for N shortcut? How do you see the feature?Additionally I can say that 0 ... 9 isn't the best choice, because these keys used in attribute annotation mode. We can use them only with an additional modifier (like ctrl or shift). In long term view these shortcuts could be setup by a user.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "cpudney",
            "datetime": "Oct 14, 2020",
            "body": "Thanks, Boris for your quick response.Ideally, apply to all drawing popups but if that's not feasible, the current drawing mode (N shortcut). So for exampleUnderstood - I think Ctrl+ (or Alt?) might be better as Shift+ produces different characters on various keyboard layouts.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "xyc2690",
            "datetime": "Dec 14, 2020",
            "body": "Any update? How could I help to do it?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Dec 28, 2020",
            "body": "Hi, The core team isn't working on the feature. If somebody from the community could propose a PR, it would be great",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "xyc2690",
            "datetime": "Dec 28, 2020",
            "body": "Thanks for your kind notification.\nI am willing to work on the feature, however, I am not familiar with TS.\nDoes there any examples or similar functions which I can take them as references?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Dec 28, 2020",
            "body": "TS is just a superset of JS, nothing really difficult if you familiar with JS. You can look how other shortcuts are implemented I suppose. I would suggest to make a search using key  in the project. We use the library  to maintain shortcuts.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "xyc2690",
            "datetime": "Dec 28, 2020",
            "body": "Thanks a lot, I will try to make it！",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lisc199",
            "datetime": "Feb 2, 2021",
            "body": " Hi~ I have the same requirement. Have you achieved this function?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "JimEverest",
            "datetime": "Mar 11, 2021",
            "body": "Same requirement. It's a very useful shortcut for improving work efficiency.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Serakov",
            "datetime": "Mar 11, 2021",
            "body": "Same requirement. It's a very useful shortcut.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Oct 13, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Oct 13, 2020",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Oct 13, 2020",
            "body": [],
            "type": "added this to the",
            "related_issue": null
        },
        {
            "user_name": "vnishukov",
            "datetime": "Jan 18, 2021",
            "body": [],
            "type": "self-assigned this",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Mar 11, 2021",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Apr 6, 2021",
            "body": [],
            "type": "pull",
            "related_issue": "#3070"
        },
        {
            "user_name": "bsekachev",
            "datetime": "Apr 7, 2021",
            "body": [],
            "type": "pull",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/1585",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "LukeAI",
            "datetime": "May 22, 2020",
            "body": "Feature Request:\nAn Appearance tick box that shows all labels on an image.Motivation:\nWhen reviewing annotations and checking for errors I can see this:\nI cannot easily, at a glance, assert that every annotation is of the correct class, I have to hover the mouse over each annotation in turn.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "May 22, 2020",
            "body": "Hi, please look here:\n",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "May 22, 2020",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        },
        {
            "user_name": "snyk-bot",
            "datetime": "Oct 9, 2020",
            "body": [],
            "type": "pull",
            "related_issue": "#2287"
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/1540",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "mkostiv",
            "datetime": "May 14, 2020",
            "body": "Steps to reproduce:TypeError\nCannot read property 'removeClass' of undefinedTypeError: Cannot read property 'removeClass' of undefined\nat Mu.deactivateShape ()\nat Mu.deactivate ()\nat Mu.activate ()\nat Mu.notify ()\nat Cc.notify ()\nat Cc.activate ()\nat Lu.activate ()\nat od.componentDidUpdate ()\nat yl ()\nat t.unstable_runWithPriority ()\n",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "mkostiv",
            "datetime": "May 14, 2020",
            "body": " 0.2.0-706-g6566e4a",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "May 14, 2020",
            "body": "Also found the issue. It is enough just to deactivate a tag. could you please look into this?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ActiveChooN",
            "datetime": "May 14, 2020",
            "body": ", maybe it's good idea to add activated shape id checking in cvat-canvas in activation method, is it?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "mkostiv",
            "datetime": "May 14, 2020",
            "body": [],
            "type": "changed the title",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "May 14, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "May 14, 2020",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "May 14, 2020",
            "body": [],
            "type": "added this to the",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "May 14, 2020",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "ActiveChooN",
            "datetime": "May 14, 2020",
            "body": [],
            "type": "pull",
            "related_issue": "#1541"
        },
        {
            "user_name": "bsekachev",
            "datetime": "May 15, 2020",
            "body": [],
            "type": "pull",
            "related_issue": null
        },
        {
            "user_name": null,
            "datetime": "May 15, 2020",
            "body": [],
            "type": "moved this from",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "May 15, 2020",
            "body": [],
            "type": "issue",
            "related_issue": "#1546"
        },
        {
            "user_name": "dvkruchinin",
            "datetime": "Aug 28, 2020",
            "body": [],
            "type": "pull",
            "related_issue": "#2096"
        }
    ]
},
{
    "issue_url": "https://github.com/mozilla-extensions/firefox-voice/issues/1505",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "alexandra-martin",
            "datetime": "Apr 8, 2020",
            "body": "Mic permissions are enabled.\n\"Allow\" or \"Don't Allow\" button from “Allow Firefox Voice to Collect Voice Transcriptions” pop-up is clicked.\n\"A privacy reminder from Google\" is reviewed and agreed and the yellow language pop-up is closed. (if applicable)Doorhanger doesn't have display issues.There is a scrollbar present that shows a partial white border of the black background.Reproduced on Mac 10.14 with Firefox Nightly 77.0a1 (2020-04-08).",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "vandnakapoor19",
            "datetime": "Apr 8, 2020",
            "body": "  I'd like to work on this.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "awallin",
            "datetime": "Apr 8, 2020",
            "body": "Go for it ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "vandnakapoor19",
            "datetime": "Apr 8, 2020",
            "body": "  I've made some CSS changes and tested on Local Machine.\nPlease have a look and confirm.\n\nOS: Windows 10x64\nFirefox Nightly: Version 75.0a1\nNode: v12.16.1",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "vandnakapoor19",
            "datetime": "Apr 25, 2020",
            "body": "  If everything is working fine then please close this issue. Let me know in case I've to make any other changes?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "awallin",
            "datetime": "Apr 27, 2020",
            "body": "Looks good. Closing.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "alexandra-martin",
            "datetime": "May 5, 2020",
            "body": "Verified on Mac 10.14 and Windows 10x64 with Firefox Nightly 78.0a1 (2020-05-04).",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "alexandra-martin",
            "datetime": "Apr 8, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "awallin",
            "datetime": "Apr 8, 2020",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "vandnakapoor19",
            "datetime": "Apr 8, 2020",
            "body": [],
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "vandnakapoor19",
            "datetime": "Apr 8, 2020",
            "body": [],
            "type": "pull",
            "related_issue": "#1513"
        },
        {
            "user_name": "awallin",
            "datetime": "Apr 27, 2020",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        },
        {
            "user_name": "alexandra-martin",
            "datetime": "May 5, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/2176",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "Mylszd",
            "datetime": "Sep 15, 2020",
            "body": "nuctl deploydocker-compose up on the yml in master branchYou may  channel for community support.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Mylszd",
            "datetime": "Sep 15, 2020",
            "body": "Use nuctl-1.4.17-linux-amd64 instead of the latest nuctl-1.1.37-linux-amd64.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Mylszd",
            "datetime": "Sep 15, 2020",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/1825",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "nmanovic",
            "datetime": "Jun 30, 2020",
            "body": "A tooltip should be hidden after mouse is out of an element which generates the tooltip.Even I move the mouse cursor out of an element, the tooltip is still visible. It is really annoying problem which doesn't allow in come cases modify/press other UI elements.I have the problem each time when I try to demonstrate CVAT to internal/external customers. It is a really critical usability issue.You may  channel for community support.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Jun 30, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Jun 30, 2020",
            "body": [],
            "type": "added this to the",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Jun 30, 2020",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Jun 30, 2020",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "ActiveChooN",
            "datetime": "Jul 28, 2020",
            "body": [],
            "type": "pull",
            "related_issue": "#1955"
        },
        {
            "user_name": "bsekachev",
            "datetime": "Jul 29, 2020",
            "body": [],
            "type": "pull",
            "related_issue": null
        },
        {
            "user_name": null,
            "datetime": "Jul 29, 2020",
            "body": [],
            "type": "moved this from",
            "related_issue": null
        },
        {
            "user_name": "dvkruchinin",
            "datetime": "Sep 3, 2020",
            "body": [],
            "type": "pull",
            "related_issue": "#2124"
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/1886",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "miso-ramen",
            "datetime": "Jul 12, 2020",
            "body": "This makes labeling polygons in my videos very difficult and frustrating. Sometimes very jagged points are added to my polygons, which takes a lot of time to correct.\n",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Jul 12, 2020",
            "body": "Looks like you have several points with the same coordinates and move one of them. Could you please check it?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "miso-ramen",
            "datetime": "Jul 13, 2020",
            "body": "Thank you, bsekachev. In the instances above, the polygons are only 4 pointed. As soon as a point is touched to move it, a new point seems to be created.If I think I'm creating a 4-pointed polygon, but somehow the program is creating additional points, how would I go about checking that? Would I need to do an annotation dump and view the annotation file for that frame?I specifically added only a 4-point polygon, and confirmed that only 4 points were used. So long as the directional arrow is located  points, the editing of points moves as expected. However, for some unknown reason, the directional arrow will locate itself  a point. When this happens (the arrow on top of a point), trying to move a point only results in creating new points. It's almost like it goes a little wild. You can see in the videos above this behavior in action. Note the directional arrow is on a point in both videos, and note how at that time, a new point is generated instead of being moved.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Jul 13, 2020",
            "body": "Actually code of dragging points even doesn't assume ability to create new points. Issue is probably in something else.By the way, speaking about orientation arrow. It always directed from the latest point to the first point, so if you see this arrow between two points, everything is alright. If you see it over a point, it means, that the latest point and the first point have the same coordinates, as I wrote in the first message.I believe, need to understand why some points are duplicated for you. Maybe every click of your mouse is double? At least I am unable to reproduce the issue from provided steps",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Jul 13, 2020",
            "body": "By the way, git says that hash you provided  is not in the working tree of our  branch.\nAre you sure it is correct?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "miso-ramen",
            "datetime": "Jul 13, 2020",
            "body": "Thank you for your time on this. The hash is correct. I had installed probably the master branch. Would this hash match up? Then, a few days ago, there was a bug in annotation.py that you all fixed (problem with dumping annotations). I (perhaps incorrectly) changed the files affected, then rebuilt cvat. Should I clone the development branch and rebuild instead? I'm sorry if I did this incorrectly.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "miso-ramen",
            "datetime": "Jul 13, 2020",
            "body": "I was able to screen capture labeling a new polygon from the beginning (a brand new task that hadn't yet been labeled) that shows all steps, when things are working as expected, then when things go awry. I hope this helps you in recreating the problem. Thank you.\nI start at frame 80, add a 4 pointed polygon (with track). I create a 4 pointed polygon, jump ahead by 10 frames at a time, unpin object, then move points, jump 10 frames, move points, move entire polygon; this is just as expected. Note: the orientation arrow in these frames is between points.Then I jump backward to beginning frame (sorry...mistake), then move forward back to where polygon was created. Note: the orientation arrow is now on a point. Now, if I try to move a point, an additional point is created. If try to move the point at the location of the orientation arrow, the entire image moves. This is unexpected behavior.This is reproducible by me each time. I'm hoping that by repeating these events on your system, you'll also be able to recreate them. Again, thank you.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Jul 13, 2020",
            "body": "I suspicious that it is related with \nAnyway let's assign  label, I will look into this issue",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "miso-ramen",
            "datetime": "Jul 13, 2020",
            "body": "Much appreciated. Thank you.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Jul 13, 2020",
            "body": "Please, check if  resolves the issue. Let me know if it does not",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "miso-ramen",
            "datetime": "Jul 13, 2020",
            "body": "I built the development branch and made the changes you outlined, then built it again. I tried to recreate the issue like I did from scratch in the video above. I was unable to. However, I imported the task my labeler was working on and asked them to see if the issue was gone. The issue still exists in the imported task.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Jul 13, 2020",
            "body": "Actually it is expected because wrong annotation is probably have been saved for some frames (with duplicated points).",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "miso-ramen",
            "datetime": "Jul 13, 2020",
            "body": "I'll keep you posted on this. I had my labeler only create new polygons, and  continue edited existing polygons. I'm told that on the new polygons, things seem to be working well. We'll continue with only new polygons from this point forward. If we see problems again, we'll let you know. Many thanks to you for your time and work on this!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Jul 13, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Jul 13, 2020",
            "body": [],
            "type": "self-assigned this",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Jul 13, 2020",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Jul 13, 2020",
            "body": [],
            "type": "added this to the",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Jul 13, 2020",
            "body": [],
            "type": "pull",
            "related_issue": "#1892"
        },
        {
            "user_name": "bsekachev",
            "datetime": "Jul 15, 2020",
            "body": [],
            "type": "pull",
            "related_issue": null
        },
        {
            "user_name": null,
            "datetime": "Jul 15, 2020",
            "body": [],
            "type": "moved this from",
            "related_issue": null
        },
        {
            "user_name": "dvkruchinin",
            "datetime": "Aug 24, 2020",
            "body": [],
            "type": "pull",
            "related_issue": "#2075"
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/2127",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "cognitiveRobot",
            "datetime": "Sep 4, 2020",
            "body": "I was expecting to see a model that is currently running.After deploying the TensorFlow model, when I go to  I see the error message as below.Still searching.Please help me to find a solution. :)",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Sep 4, 2020",
            "body": " , could you please attach server logs? ().\nAlso please attach logs from the serverless function ()",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "cognitiveRobot",
            "datetime": "Sep 4, 2020",
            "body": "Thank  . Here they are.\ndocker logs cvat:docker logs nuclio-nuclio-tf.faster_rcnn_inception_v2_coco",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "cognitiveRobot",
            "datetime": "Sep 7, 2020",
            "body": ", any update on this? Thanks.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "cognitiveRobot",
            "datetime": "Sep 8, 2020",
            "body": "To resolve this, I installed a fresh ubuntu 18.04. Now, I am running into a new problem. I can't deploy the model.\nEnv:When I run the deploying commad:But looks like docker image has been created.\n$ docker imagesBut no container:\n$docker psAny help would be highly appreciated.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "cognitiveRobot",
            "datetime": "Sep 8, 2020",
            "body": "Working with the latest release of nuclio.\n",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "varchanaiyer",
            "datetime": "Sep 8, 2020",
            "body": "Hello,I am also facing a similar issue. I am using the 1.4.17 version of nuclio, but when I try to perform automatic sengmentation using the openvino yolo model, then I get an error message:Here are the logs:Thank you",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "WeiChihChern",
            "datetime": "Sep 9, 2020",
            "body": "\nSame issue, and fixed by using latest nuclio suggested by .  Please update the link for nuclio in the guide, that one is an older version which will cause problems for serverless functions.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "veer5551",
            "datetime": "Sep 12, 2020",
            "body": "Hello,I am getting these errors while executing the first command itself  .\nTried multiple versions and got different errors.Error on nuctl version -  1.4.17Error on nuctl version -  1.3.17 and 1.1.37Running on Windows 10.\nLet me know If I am missing something here!Thanks a lot!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "cognitiveRobot",
            "datetime": "Sep 12, 2020",
            "body": ", after trying to perform automatic segmentation, immediately check  (make sure the image name is correct in this command) and see what's the error message. Hope you will find the solution. If not then share your docker logs share, we will try.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "cognitiveRobot",
            "datetime": "Sep 12, 2020",
            "body": ", go to the location where you downloaded  and check the filename. In my case, it's , so I run .",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "veer5551",
            "datetime": "Sep 13, 2020",
            "body": "Hello ,I renamed the downloaded files and ran accordingly. Still getting the same Errors.Thanks!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "cognitiveRobot",
            "datetime": "Sep 13, 2020",
            "body": "well,  means there is something wrong in your execution. It could be either you are not going to the directory where the  is or you are not executing the command properly. Hope these give you some directions.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "veer5551",
            "datetime": "Sep 13, 2020",
            "body": "Followed the same procedure on a Linux system and everything was smooth. Models are deployed correctly and I am able to use them as well.Need to check if this is an issue of Nuclio + WSL in Windows 10 combination problem.\nMaybe I'll report the issue there.\nIf anyone here has got it working, please share the procedure/guide.Alternatively, is it possible to deploy the models via the Nuclio UI Dashboard by loading the appropriate YAML and model handler? Tried doing it but got some function invocation error.Thanks a lot!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Sep 14, 2020",
            "body": " , could you please check if basic examples from nuclio are working on your Windows machine and report problems to nuclio github if it doesn't work?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "veer5551",
            "datetime": "Sep 14, 2020",
            "body": "Reported the Issue on Nuclio github:\nReference Link: Thanks!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "beep-love",
            "datetime": "Dec 4, 2020",
            "body": "I was having an error while executing:\n\npwd\nError - Container wasn't healthy in time\n.../nuclio/nuclio/pkg/dockerclient/shell.go:395Call stack:\nContainer wasn't healthy in time\n.../nuclio/nuclio/pkg/dockerclient/shell.go:395\nFunction wasn't ready in time. Logs:`20.12.04 08:40:45.720 sor.http.w0.python.logger (E) Unexpected termination of child process {\"error\": null, \"status\": \"exit status 1\"}\npanic: Wrapper process for worker 0 exited unexpectedly with: exit status 1goroutine 22 [running]:\ngithub.com/nuclio/nuclio/pkg/processor/runtime/rpc.(*AbstractRuntime).watchWrapperProcess(0xc4205160b0)\n/go/src/github.com/nuclio/nuclio/pkg/processor/runtime/rpc/abstract.go:453 +0x5bb\ncreated by github.com/nuclio/nuclio/pkg/processor/runtime/rpc.(*AbstractRuntime).startWrapper\n/go/src/github.com/nuclio/nuclio/pkg/processor/runtime/rpc/abstract.go:232 +0x1c8Failed to deploy function\n.../nuclio/pkg/platform/abstract/platform.go:172\n`\nI checked the GitHub repo and found that the URL does not exist but the file is rather with URL  instead of github.com/nuclio/nuclio/pkg/ ......Can you please help on this issue   ?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "cognitiveRobot",
            "datetime": "Dec 9, 2020",
            "body": " looks like you are trying to use an older version of nuclio. I did the same mistake, then when I used  this, it worked.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "beep-love",
            "datetime": "Dec 9, 2020",
            "body": "Yeah. It was the same issue. Mine worked with v 1.5.7.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "cognitiveRobot",
            "datetime": "Sep 8, 2020",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        },
        {
            "user_name": "veer5551",
            "datetime": "Sep 14, 2020",
            "body": [],
            "type": "issue",
            "related_issue": "nuclio/nuclio#1821"
        },
        {
            "user_name": "Loc-Vo",
            "datetime": "Oct 7, 2020",
            "body": [],
            "type": "issue",
            "related_issue": "#2259"
        },
        {
            "user_name": "veer5551",
            "datetime": "Oct 9, 2020",
            "body": [],
            "type": "issue",
            "related_issue": "nuclio/nuclio#1850"
        }
    ]
},
{
    "issue_url": "https://github.com/mozilla-extensions/firefox-voice/issues/1329",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "alexandra-martin",
            "datetime": "Mar 18, 2020",
            "body": "Mic permissions are enabled.\n\"Allow\" or \"Don't Allow\" button from “Allow Firefox Voice to Collect Voice Transcriptions” pop-up needs to be clicked.\nThe \"Preferences\" page is opened, by using the shortcut or clicking on the mic icon from the browser toolbar and selecting the \"Settings\" icon from the bottom left side of the doorhanger.\"Routines\" page doesn't have discrepancies compared to the mock-up from .There are some discrepancies between the mock-up and the actual display.Reproduced on Mac 10.14 and Win10x64 with Firefox Nightly 76.0a1 (2020-03-16).\nThe discrepancies between the mock-up and the actual display are as followed:Some of these can change, depending on the desired user experience. One example is the position of the \"+ New Routine\" button.Mock-up:\n",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Shulammite-Aso",
            "datetime": "Mar 18, 2020",
            "body": "Hi  I think Issue    Is a part of this,  or are they different?\nIf they are the same and you intend to close the other, then I would like to work on this.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Shulammite-Aso",
            "datetime": "Mar 18, 2020",
            "body": "    I can start working on this after you give your thought on it.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "shreyaa-s-zz",
            "datetime": "Mar 18, 2020",
            "body": "Hey, can I work on this one?  \nThanks!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "alexandra-martin",
            "datetime": "Mar 19, 2020",
            "body": "  has a more general approach for the \"Routines\" page display (the page itself seems a bit zoomed in compared to other pages), while this report looks at more specific changes that need to be done. Hope that clarifies things.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "alexandra-martin",
            "datetime": "Mar 18, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "ianb",
            "datetime": "May 20, 2020",
            "body": [],
            "type": "modified the milestones:",
            "related_issue": null
        },
        {
            "user_name": "ianb",
            "datetime": "Jun 23, 2020",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "danielamormocea",
            "datetime": "Jun 30, 2020",
            "body": [],
            "type": "pull",
            "related_issue": "#1787"
        },
        {
            "user_name": "ianb",
            "datetime": "Jun 30, 2020",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        },
        {
            "user_name": "ianb",
            "datetime": "Jun 30, 2020",
            "body": [],
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "Simpcyclassy",
            "datetime": "Jul 15, 2020",
            "body": [],
            "type": "issue",
            "related_issue": "#1328"
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/1977",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "creativesiva",
            "datetime": "Aug 3, 2020",
            "body": "I am getting error while trying to deploy openvino and pytorch models to nuclio (serverless functions), I have used  'bash serverless/deploy.sh to deploy models. Below is the log error for semantic-segmentation-adas-0001Error - Container wasn't healthy in time\n/nuclio/pkg/dockerclient/shell.go:429Call stack:\nContainer wasn't healthy in time\n/nuclio/pkg/dockerclient/shell.go:429\nFunction wasn't ready in time. Logs:Error - open /etc/nuclio/config/processor/processor.yaml: permission denied\n/nuclio/cmd/processor/app/processor.go:265Call stack:\nFailed to open configuration file\n/nuclio/cmd/processor/app/processor.go:265Error - open /etc/nuclio/config/processor/processor.yaml: permission denied\n/nuclio/cmd/processor/app/processor.go:265Call stack:\nFailed to open configuration file\n/nuclio/cmd/processor/app/processor.go:265Error - open /etc/nuclio/config/processor/processor.yaml: permission denied\n/nuclio/cmd/processor/app/processor.go:265Call stack:\nFailed to open configuration file\n/nuclio/cmd/processor/app/processor.go:265Error - open /etc/nuclio/config/processor/processor.yaml: permission denied\n/nuclio/cmd/processor/app/processor.go:265Call stack:\nFailed to open configuration file\n/nuclio/cmd/processor/app/processor.go:265Error - open /etc/nuclio/config/processor/processor.yaml: permission denied\n/nuclio/cmd/processor/app/processor.go:265Call stack:\nFailed to open configuration file\n/nuclio/cmd/processor/app/processor.go:265Error - open /etc/nuclio/config/processor/processor.yaml: permission denied\n/nuclio/cmd/processor/app/processor.go:265Call stack:\nFailed to open configuration file\n/nuclio/cmd/processor/app/processor.go:265Error - open /etc/nuclio/config/processor/processor.yaml: permission denied\n/nuclio/cmd/processor/app/processor.go:265Call stack:\nFailed to open configuration file\n/nuclio/cmd/processor/app/processor.go:265Error - open /etc/nuclio/config/processor/processor.yaml: permission denied\n/nuclio/cmd/processor/app/processor.go:265Call stack:\nFailed to open configuration file\n/nuclio/cmd/processor/app/processor.go:265Error - open /etc/nuclio/config/processor/processor.yaml: permission denied\n/nuclio/cmd/processor/app/processor.go:265Call stack:\nFailed to open configuration file\n/nuclio/cmd/processor/app/processor.go:265As a end results, it is installing i am able to deploy tensorflow models, below is the error message for rest of the models.\nNAMESPACE |                             NAME                              | PROJECT | STATE | NODE PORT | REPLICAS\nnuclio    | openvino.dextr                                                | cvat    | error |         0 | 1/1\nnuclio    | openvino.omz.intel.person-reidentification-retail-0300        | cvat    | error |         0 | 1/1\nnuclio    | openvino.omz.intel.text-detection-0004                        | cvat    | error |         0 | 1/1\nnuclio    | openvino.omz.public.faster_rcnn_inception_v2_coco             | cvat    | error |         0 | 1/1\nnuclio    | openvino.omz.public.mask_rcnn_inception_resnet_v2_atrous_coco | cvat    | error |         0 | 1/1\nnuclio    | openvino.omz.public.yolo-v3-tf                                | cvat    | error |         0 | 1/1\nnuclio    | openvino.omz.semantic-segmentation-adas-0001                  | cvat    | error |         0 | 1/1\nnuclio    | tf.faster_rcnn_inception_v2_coco                              | cvat    | ready |     39731 | 1/1\nnuclio    | tf.matterport.mask_rcnn                                       | cvat    | ready |     37237 | 1/1\nCONTAINER ID        IMAGE                                                                       COMMAND                  CREATED             STATUS                          PORTS                                                 NAMES\nce454f5ed371        cvat/tf.faster_rcnn_inception_v2_coco:latest                                \"processor\"              44 minutes ago      Up 44 minutes (healthy)         0.0.0.0:39731->8080/tcp                               nuclio-nuclio-tf.faster_rcnn_inception_v2_coco\ndde7ad667e3b        cvat/tf.matterport.mask_rcnn:latest                                         \"processor\"              45 minutes ago      Up 45 minutes (healthy)         0.0.0.0:37237->8080/tcp                               nuclio-nuclio-tf.matterport.mask_rcnn\n2a9b80907c35        cvat/openvino.dextr:latest                                                  \"processor\"              46 minutes ago      Restarting (1) 44 seconds ago                                                         nuclio-nuclio-openvino.dextr\n21170f4a7916        cvat/openvino.omz.intel.person-reidentification-retail-0300:latest          \"processor\"              48 minutes ago      Restarting (1) 3 seconds ago                                                          nuclio-nuclio-openvino.omz.intel.person-reidentification-retail-0300\n13b9d8996523        cvat/openvino.omz.intel.semantic-segmentation-adas-0001:latest              \"processor\"              49 minutes ago      Restarting (1) 28 seconds ago                                                         nuclio-nuclio-openvino.omz.semantic-segmentation-adas-0001\n81c6d6abd728        cvat/openvino.omz.intel.text-detection-0004:latest                          \"processor\"              50 minutes ago      Restarting (1) 57 seconds ago                                                         nuclio-nuclio-openvino.omz.intel.text-detection-0004\n13f30e51675d        cvat/openvino.omz.public.yolo-v3-tf:latest                                  \"processor\"              52 minutes ago      Restarting (1) 20 seconds ago                                                         nuclio-nuclio-openvino.omz.public.yolo-v3-tf\n4e454024a67b        cvat/openvino.omz.public.mask_rcnn_inception_resnet_v2_atrous_coco:latest   \"processor\"              53 minutes ago      Restarting (1) 41 seconds ago                                                         nuclio-nuclio-openvino.omz.public.mask_rcnn_inception_resnet_v2_atrous_coco\n86900a751357        cvat/openvino.omz.public.faster_rcnn_inception_v2_coco:latest               \"processor\"              55 minutes ago      Restarting (1) 6 seconds ago                                                          nuclio-nuclio-openvino.omz.public.faster_rcnn_inception_v2_coco\nc096e1d34a9f        alpine:3.11                                                                 \"/bin/sh -c '/bin/sl…\"   3 hours ago         Up 3 hours                                                                            nuclio-local-storage-reader\n10761a37f44d        nginx:stable-alpine                                                         \"/docker-entrypoint.…\"   9 hours ago         Up 9 hours                      0.0.0.0:8080->80/tcp                                  cvat_proxy\n888326330e63        cvat/server                                                                 \"/usr/bin/supervisord\"   9 hours ago         Up 9 hours                      8080/tcp, 8443/tcp                                    cvat\na82bd68fdccd        cvat_logstash                                                               \"/usr/local/bin/dock…\"   9 hours ago         Up 9 hours                      5000/tcp, 5044/tcp, 9600/tcp                          cvat_logstash\na89ce4f4ad30        cvat_kibana                                                                 \"/usr/local/bin/kiba…\"   9 hours ago         Up 9 hours                      5601/tcp                                              cvat_kibana\n1f55c7d21943        cvat_elasticsearch                                                          \"/usr/local/bin/dock…\"   9 hours ago         Up 9 hours                      9200/tcp, 9300/tcp                                    cvat_elasticsearch\n4117c788c958        cvat/ui                                                                     \"/docker-entrypoint.…\"   9 hours ago         Up 9 hours                      80/tcp                                                cvat_ui\n0c50074a51c5        quay.io/nuclio/dashboard:1.4.8-amd64                                        \"sh -c ./runner.sh\"      9 hours ago         Up 9 hours                      80/tcp, 0.0.0.0:8070->8070/tcp                        nuclio\nnuctl-1.4.14-linux-amd64",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Aug 3, 2020",
            "body": " , could you please provide the full deployment log for functions? Something like I did below:",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "creativesiva",
            "datetime": "Aug 3, 2020",
            "body": " , Below is the deployment log.20.08.03 22:26:11.277            nuctl.platform (I) Waiting for function to be ready {\"timeout\": 60}\n20.08.03 22:26:12.568                     nuctl (I) Function deploy complete {\"functionName\": \"tf.matterport.mask_rcnn\", \"httpPort\": 37237}\n20.08.03 22:26:13.531                     nuctl (I) Deploying function {\"name\": \"\"}\n20.08.03 22:26:13.532                     nuctl (I) Building {\"versionInfo\": \"Label: 1.4.14, Git commit: e10e9fb123caafbe4f95310a0e2ccfc71368ba87, OS: linux, Arch: amd64, Go version: go1.14.3\", \"name\": \"\"}\n20.08.03 22:26:13.767                     nuctl (I) Cleaning up before deployment\n20.08.03 22:26:13.880                     nuctl (I) Function already exists, deleting\n20.08.03 22:26:15.712                     nuctl (I) Staging files and preparing base images\n20.08.03 22:26:15.714                     nuctl (I) Building processor image {\"imageName\": \"cvat/tf.faster_rcnn_inception_v2_coco:latest\"}\n20.08.03 22:26:15.714     nuctl.platform.docker (I) Pulling image {\"imageName\": \"quay.io/nuclio/handler-builder-python-onbuild:1.4.14-amd64\"}\n20.08.03 22:26:22.932     nuctl.platform.docker (I) Pulling image {\"imageName\": \"quay.io/nuclio/uhttpc:0.0.1-amd64\"}\n20.08.03 22:26:34.942            nuctl.platform (I) Building docker image {\"image\": \"cvat/tf.faster_rcnn_inception_v2_coco:latest\"}\n20.08.03 22:26:35.301            nuctl.platform (I) Pushing docker image into registry {\"image\": \"cvat/tf.faster_rcnn_inception_v2_coco:latest\", \"registry\": \"\"}\n20.08.03 22:26:35.301            nuctl.platform (I) Docker image was successfully built and pushed into docker registry {\"image\": \"cvat/tf.faster_rcnn_inception_v2_coco:latest\"}\n20.08.03 22:26:35.301                     nuctl (I) Build complete {\"result\": {\"Image\":\"cvat/tf.faster_rcnn_inception_v2_coco:latest\",\"UpdatedFunctionConfig\":{\"metadata\":{\"name\":\"tf.faster_rcnn_inception_v2_coco\",\"namespace\":\"nuclio\",\"labels\":{\"nuclio.io/project-name\":\"cvat\"},\"annotations\":{\"framework\":\"tensorflow\",\"name\":\"Faster RCNN via Tensorflow\",\"spec\":\"[\\n  { \"id\": 1, \"name\": \"person\" },\\n  { \"id\": 2, \"name\": \"bicycle\" },\\n  { \"id\": 3, \"name\": \"car\" },\\n  { \"id\": 4, \"name\": \"motorcycle\" },\\n  { \"id\": 5, \"name\": \"airplane\" },\\n  { \"id\": 6, \"name\": \"bus\" },\\n  { \"id\": 7, \"name\": \"train\" },\\n  { \"id\": 8, \"name\": \"truck\" },\\n  { \"id\": 9, \"name\": \"boat\" },\\n  { \"id\":10, \"name\": \"traffic_light\" },\\n  { \"id\":11, \"name\": \"fire_hydrant\" },\\n  { \"id\":13, \"name\": \"stop_sign\" },\\n  { \"id\":14, \"name\": \"parking_meter\" },\\n  { \"id\":15, \"name\": \"bench\" },\\n  { \"id\":16, \"name\": \"bird\" },\\n  { \"id\":17, \"name\": \"cat\" },\\n  { \"id\":18, \"name\": \"dog\" },\\n  { \"id\":19, \"name\": \"horse\" },\\n  { \"id\":20, \"name\": \"sheep\" },\\n  { \"id\":21, \"name\": \"cow\" },\\n  { \"id\":22, \"name\": \"elephant\" },\\n  { \"id\":23, \"name\": \"bear\" },\\n  { \"id\":24, \"name\": \"zebra\" },\\n  { \"id\":25, \"name\": \"giraffe\" },\\n  { \"id\":27, \"name\": \"backpack\" },\\n  { \"id\":28, \"name\": \"umbrella\" },\\n  { \"id\":31, \"name\": \"handbag\" },\\n  { \"id\":32, \"name\": \"tie\" },\\n  { \"id\":33, \"name\": \"suitcase\" },\\n  { \"id\":34, \"name\": \"frisbee\" },\\n  { \"id\":35, \"name\": \"skis\" },\\n  { \"id\":36, \"name\": \"snowboard\" },\\n  { \"id\":37, \"name\": \"sports_ball\" },\\n  { \"id\":38, \"name\": \"kite\" },\\n  { \"id\":39, \"name\": \"baseball_bat\" },\\n  { \"id\":40, \"name\": \"baseball_glove\" },\\n  { \"id\":41, \"name\": \"skateboard\" },\\n  { \"id\":42, \"name\": \"surfboard\" },\\n  { \"id\":43, \"name\": \"tennis_racket\" },\\n  { \"id\":44, \"name\": \"bottle\" },\\n  { \"id\":46, \"name\": \"wine_glass\" },\\n  { \"id\":47, \"name\": \"cup\" },\\n  { \"id\":48, \"name\": \"fork\" },\\n  { \"id\":49, \"name\": \"knife\" },\\n  { \"id\":50, \"name\": \"spoon\" },\\n  { \"id\":51, \"name\": \"bowl\" },\\n  { \"id\":52, \"name\": \"banana\" },\\n  { \"id\":53, \"name\": \"apple\" },\\n  { \"id\":54, \"name\": \"sandwich\" },\\n  { \"id\":55, \"name\": \"orange\" },\\n  { \"id\":56, \"name\": \"broccoli\" },\\n  { \"id\":57, \"name\": \"carrot\" },\\n  { \"id\":58, \"name\": \"hot_dog\" },\\n  { \"id\":59, \"name\": \"pizza\" },\\n  { \"id\":60, \"name\": \"donut\" },\\n  { \"id\":61, \"name\": \"cake\" },\\n  { \"id\":62, \"name\": \"chair\" },\\n  { \"id\":63, \"name\": \"couch\" },\\n  { \"id\":64, \"name\": \"potted_plant\" },\\n  { \"id\":65, \"name\": \"bed\" },\\n  { \"id\":67, \"name\": \"dining_table\" },\\n  { \"id\":70, \"name\": \"toilet\" },\\n  { \"id\":72, \"name\": \"tv\" },\\n  { \"id\":73, \"name\": \"laptop\" },\\n  { \"id\":74, \"name\": \"mouse\" },\\n  { \"id\":75, \"name\": \"remote\" },\\n  { \"id\":76, \"name\": \"keyboard\" },\\n  { \"id\":77, \"name\": \"cell_phone\" },\\n  { \"id\":78, \"name\": \"microwave\" },\\n  { \"id\":79, \"name\": \"oven\" },\\n  { \"id\":80, \"name\": \"toaster\" },\\n  { \"id\":81, \"name\": \"sink\" },\\n  { \"id\":83, \"name\": \"refrigerator\" },\\n  { \"id\":84, \"name\": \"book\" },\\n  { \"id\":85, \"name\": \"clock\" },\\n  { \"id\":86, \"name\": \"vase\" },\\n  { \"id\":87, \"name\": \"scissors\" },\\n  { \"id\":88, \"name\": \"teddy_bear\" },\\n  { \"id\":89, \"name\": \"hair_drier\" },\\n  { \"id\":90, \"name\": \"toothbrush\" }\\n]\\n\",\"type\":\"detector\"}},\"spec\":{\"description\":\"Faster RCNN from Tensorflow Object Detection API\",\"handler\":\"main:handler\",\"runtime\":\"python:3.6\",\"resources\":{},\"image\":\"cvat/tf.faster_rcnn_inception_v2_coco:latest\",\"targetCPU\":75,\"triggers\":{\"myHttpTrigger\":{\"class\":\"\",\"kind\":\"http\",\"name\":\"\",\"maxWorkers\":2,\"workerAvailabilityTimeoutMilliseconds\":10000,\"attributes\":{\"maxRequestBodySize\":33554432}}},\"build\":{\"image\":\"cvat/tf.faster_rcnn_inception_v2_coco\",\"baseImage\":\"tensorflow/tensorflow:2.1.1\",\"directives\":{\"postCopy\":[{\"kind\":\"RUN\",\"value\":\"curl -O http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz\"},{\"kind\":\"RUN\",\"value\":\"tar -xzf faster_rcnn_inception_v2_coco_2018_01_28.tar.gz \\u0026\\u0026 rm faster_rcnn_inception_v2_coco_2018_01_28.tar.gz\"},{\"kind\":\"RUN\",\"value\":\"ln -s faster_rcnn_inception_v2_coco_2018_01_28 faster_rcnn\"},{\"kind\":\"RUN\",\"value\":\"pip install pillow pyyaml\"}],\"preCopy\":[{\"kind\":\"RUN\",\"value\":\"apt install curl\"},{\"kind\":\"WORKDIR\",\"value\":\"/opt/nuclio\"}]},\"codeEntryType\":\"image\"},\"platform\":{\"attributes\":{\"restartPolicy\":{\"maximumRetryCount\":3,\"name\":\"always\"}}},\"readinessTimeoutSeconds\":60,\"eventTimeout\":\"30s\"}}}}\n20.08.03 22:26:37.812            nuctl.platform (I) Waiting for function to be ready {\"timeout\": 60}\n20.08.03 22:26:39.205                     nuctl (I) Function deploy complete {\"functionName\": \"tf.faster_rcnn_inception_v2_coco\", \"httpPort\": 39731}\nNAMESPACE |                             NAME                              | PROJECT | STATE | NODE PORT | REPLICAS\nnuclio    | openvino.dextr                                                | cvat    | error |         0 | 1/1\nnuclio    | openvino.omz.intel.person-reidentification-retail-0300        | cvat    | error |         0 | 1/1\nnuclio    | openvino.omz.intel.text-detection-0004                        | cvat    | error |         0 | 1/1\nnuclio    | openvino.omz.public.faster_rcnn_inception_v2_coco             | cvat    | error |         0 | 1/1\nnuclio    | openvino.omz.public.mask_rcnn_inception_resnet_v2_atrous_coco | cvat    | error |         0 | 1/1\nnuclio    | openvino.omz.public.yolo-v3-tf                                | cvat    | error |         0 | 1/1\nnuclio    | openvino.omz.semantic-segmentation-adas-0001                  | cvat    | error |         0 | 1/1\nnuclio    | tf.faster_rcnn_inception_v2_coco                              | cvat    | ready |     39731 | 1/1\nnuclio    | tf.matterport.mask_rcnn                                       | cvat    | ready |     37237 | 1/1",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Aug 4, 2020",
            "body": " , I have updated the documentation. Could you please add  command line argument when you deploy a function (deploy.sh already has the additional argument)? Please notify me if it solves the problem.For further investigation please add --verbose flag to a  command. It will provide additional information.Also it looks like need more information about your system. Which OS do you use? Please provide as much details about your system as possible. For example, docker version.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "AJ-RR",
            "datetime": "Aug 4, 2020",
            "body": "I have the same issue. I am using Ubuntu 18.04.1 and docker version 19.03.6. Adding --platform local command line argument does not solve the issue.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Aug 4, 2020",
            "body": " , could you please also publish your deployment log?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "creativesiva",
            "datetime": "Aug 4, 2020",
            "body": "I have tried with --platfom local, Hard Luck.\nOS:Ubuntu 18.04.4, Docker-version: 19.03.12",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "AJ-RR",
            "datetime": "Aug 4, 2020",
            "body": "\n, Here it is\nError - Container wasn't healthy in time\n/nuclio/pkg/dockerclient/shell.go:429Call stack:\nContainer wasn't healthy in time\n/nuclio/pkg/dockerclient/shell.go:429\nFunction wasn't ready in time. Logs:Error - open /etc/nuclio/config/processor/processor.yaml: permission denied\n/nuclio/cmd/processor/app/processor.go:265Call stack:\nFailed to open configuration file\n/nuclio/cmd/processor/app/processor.go:265Error - open /etc/nuclio/config/processor/processor.yaml: permission denied\n/nuclio/cmd/processor/app/processor.go:265Call stack:\nFailed to open configuration file\n/nuclio/cmd/processor/app/processor.go:265Error - open /etc/nuclio/config/processor/processor.yaml: permission denied\n/nuclio/cmd/processor/app/processor.go:265Call stack:\nFailed to open configuration file\n/nuclio/cmd/processor/app/processor.go:265Error - open /etc/nuclio/config/processor/processor.yaml: permission denied\n/nuclio/cmd/processor/app/processor.go:265Call stack:\nFailed to open configuration file\n/nuclio/cmd/processor/app/processor.go:265Error - open /etc/nuclio/config/processor/processor.yaml: permission denied\n/nuclio/cmd/processor/app/processor.go:265Call stack:\nFailed to open configuration file\n/nuclio/cmd/processor/app/processor.go:265Error - open /etc/nuclio/config/processor/processor.yaml: permission denied\n/nuclio/cmd/processor/app/processor.go:265Call stack:\nFailed to open configuration file\n/nuclio/cmd/processor/app/processor.go:265Error - open /etc/nuclio/config/processor/processor.yaml: permission denied\n/nuclio/cmd/processor/app/processor.go:265Call stack:\nFailed to open configuration file\n/nuclio/cmd/processor/app/processor.go:265Error - open /etc/nuclio/config/processor/processor.yaml: permission denied\n/nuclio/cmd/processor/app/processor.go:265Call stack:\nFailed to open configuration file\n/nuclio/cmd/processor/app/processor.go:265Error - open /etc/nuclio/config/processor/processor.yaml: permission denied\n/nuclio/cmd/processor/app/processor.go:265Call stack:\nFailed to open configuration file\n/nuclio/cmd/processor/app/processor.go:265Error - open /etc/nuclio/config/processor/processor.yaml: permission denied\n/nuclio/cmd/processor/app/processor.go:265Call stack:\nFailed to open configuration file\n/nuclio/cmd/processor/app/processor.go:265Failed to deploy function\n...//nuclio/pkg/platform/abstract/platform.go:171",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Aug 5, 2020",
            "body": " , we are investigating the issue. I cannot reproduce it on my Linux and Mac machines. But an internal team also reported the problem. I know that nuclio guys also are investigating the issue. I hope to find a solution soon. If you can help and investigate on your end, it will be perfect.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Aug 6, 2020",
            "body": " , could you please try a workaround in PR ?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "creativesiva",
            "datetime": "Aug 6, 2020",
            "body": " , Please suggest how can i check this!!, I am not sure, what to do!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "creativesiva",
            "datetime": "Aug 6, 2020",
            "body": "I understand that you have removed       \"- kind: USER value: openvino\" from function.yml and did the same in my local repository. Now it is showing different error.\n\nsudo ./nuctl deploy --project-name cvat --path serverless/openvino/omz/intel/semantic-segmentation-adas-0001/nuclio     --volume serverless/openvino/common:/opt/nuclio/common --platform local\n",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Aug 7, 2020",
            "body": " , the mentioned deploy command isn't correct. The error message is clear here: . For volumes you have to use absolute paths:  Also you don't need to use  if your docker setup is correct (you are in docker group).",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "creativesiva",
            "datetime": "Aug 7, 2020",
            "body": ", Thanks. The model deployment is successful now. (I have not made changes to text-detection function, that is why error, rest all functions are modified as per your suggestion)Thanks a lot.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Aug 7, 2020",
            "body": " , could you please help me to test a fix in nuclio? Below I have attached nuctl for linux with a fix which just adds necessary permissions to /tmp/processor-config-* file (). Please revert all changes inside CVAT and try the binary to deploy functions. Does it work? I cannot check on my end unfortunately.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "creativesiva",
            "datetime": "Aug 7, 2020",
            "body": " , i have reverted function.yml changes and used nuctl-latest-linux-amd64 to run the deploy.sh. It is throwing error.\n",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Aug 7, 2020",
            "body": " , thanks for the info. I have merged the PR. Now it should work. I hope nuclio team will be able to reproduce the issue and fix in future releases.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Aug 7, 2020",
            "body": " , are you sure that you used the attached binary? At least Git commit   in your logs looks strange.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "creativesiva",
            "datetime": "Aug 10, 2020",
            "body": " Sorry i did not noticed your question.\nYes, i have used (nuctl-latest-linux-amd64.zip)",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "thangvip4321",
            "datetime": "Aug 12, 2020",
            "body": " i have updated my code, but the error still persist.\nHere's the log:I'm running on Ubuntu 18.04, docker version : 19.03.11 , nuctl: 1.4.16.\n",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Aug 12, 2020",
            "body": " , indeed it is another issue: ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Aug 12, 2020",
            "body": " , let me check with nuctl 1.4.16 if I can reproduce the issue.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Aug 12, 2020",
            "body": " , I cannot reproduce the problem. Need your help.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Aug 3, 2020",
            "body": [],
            "type": "self-assigned this",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Aug 3, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Aug 3, 2020",
            "body": [],
            "type": "added this to the",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Aug 3, 2020",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Aug 5, 2020",
            "body": [],
            "type": "pull",
            "related_issue": "#1988"
        },
        {
            "user_name": "nmanovic",
            "datetime": "Aug 5, 2020",
            "body": [],
            "type": "changed the title",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Aug 6, 2020",
            "body": [],
            "type": "pull",
            "related_issue": "#1996"
        },
        {
            "user_name": "nmanovic",
            "datetime": "Aug 7, 2020",
            "body": [],
            "type": "pull",
            "related_issue": null
        },
        {
            "user_name": null,
            "datetime": "Aug 7, 2020",
            "body": [],
            "type": "moved this from",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Aug 7, 2020",
            "body": [],
            "type": "reopened this",
            "related_issue": null
        },
        {
            "user_name": null,
            "datetime": "Aug 7, 2020",
            "body": [],
            "type": "moved this from",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Aug 7, 2020",
            "body": [],
            "type": "issue",
            "related_issue": "nuclio/nuclio#1782"
        },
        {
            "user_name": "nmanovic",
            "datetime": "Aug 7, 2020",
            "body": [],
            "type": "pull",
            "related_issue": "#1996"
        },
        {
            "user_name": "nmanovic",
            "datetime": "Aug 7, 2020",
            "body": [],
            "type": "pull",
            "related_issue": null
        },
        {
            "user_name": null,
            "datetime": "Aug 7, 2020",
            "body": [],
            "type": "moved this from",
            "related_issue": null
        },
        {
            "user_name": "thangvip4321",
            "datetime": "Aug 12, 2020",
            "body": [],
            "type": "issue",
            "related_issue": "#2024"
        }
    ]
},
{
    "issue_url": "https://github.com/mozilla-extensions/firefox-voice/issues/1327",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "alexandra-martin",
            "datetime": "Mar 18, 2020",
            "body": "Mic permissions are enabled.\n\"Allow\" or \"Don't Allow\" button from “Allow Firefox Voice to Collect Voice Transcriptions” pop-up needs to be clicked.\nA Google Docs tab is opened.\nThe tab that the user wants to copy the image from is made active.Image is copied in the Google Doc successfully.Other information is copied or nothing happens.Reproduced on Mac 10.14 and Win10x64 with Firefox Nightly 76.0a1 (2020-03-18).\nIf the user right clicks with the mouse on the image and selects \"Copy Image\", then it is possible to copy the picture in the desired tab, e.g. Google Docs, Google Slides, Google Sheets, . (\"Paste\" command works for calmlywriter or Google Sheets. For Google Docs and Google Slides, the paste keyboard command should be used)",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "fleur101",
            "datetime": "Mar 18, 2020",
            "body": "I was able to reproduce the bug. May I try to fix it?\nUpdate: fixed",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "alexandra-martin",
            "datetime": "Mar 31, 2020",
            "body": "Verified on Mac 10.14 with Firefox Nightly 76.0a1 (2020-03-31).\n\"Paste\" commands are not working in Google Docs and Google Slides, like in , but image is copied with the paste keyboard shortcut.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "alexandra-martin",
            "datetime": "Mar 18, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "fleur101",
            "datetime": "Mar 19, 2020",
            "body": [],
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "fleur101",
            "datetime": "Mar 22, 2020",
            "body": [],
            "type": "pull",
            "related_issue": "#1335"
        },
        {
            "user_name": "ianb",
            "datetime": "Mar 30, 2020",
            "body": [],
            "type": "pull",
            "related_issue": null
        },
        {
            "user_name": "ianb",
            "datetime": "Mar 30, 2020",
            "body": [],
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "alexandra-martin",
            "datetime": "Mar 31, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/mozilla-extensions/firefox-voice/issues/976",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "Sav22999",
            "datetime": "Feb 7, 2020",
            "body": "I think it's a good idea add a voice command to open an extension just with the voice.\nFor example. I installed uBlock. If I want to open it, i should click the icon on address bar.\nSo, why don't add \"Open uBlock extension\" voice command to do the same thing?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ianb",
            "datetime": "Feb 19, 2020",
            "body": "This is going to be hard on a couple levels – invoking another extension isn't clear, but it probably means click the accompanying toolbar button. That's not something that we easily have access to. But then once you've done that you have a popup, and an extension popup is impossible for us to control at all, so you would be forced to continue interacting with your mouse and not your voice.Because of this, we don't think this will be a useful experience for someone.Note that we are very open to allowing other extensions to be controlled by voice, if those extensions want to add code to their own extension to run those commands.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ianb",
            "datetime": "Feb 19, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "ianb",
            "datetime": "Feb 19, 2020",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/mozilla-extensions/firefox-voice/issues/704",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "alexandra-martin",
            "datetime": "Dec 10, 2019",
            "body": "Mic permission are enabled.\n\"Allow\" or \"Don't Allow\" button from “Allow Firefox Voice to Collect Voice Transcriptions” pop-up needs to be clicked.\nA command is made beforehand.Button changes color when hovered.Nothing happens.Reproduced on Mac 10.14.6 and Win10x64 with Firefox Nightly 72.0a1 (64-bit).",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ianb",
            "datetime": "Dec 10, 2019",
            "body": "Also the frowny face is not centered",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "alexandra-martin",
            "datetime": "Dec 12, 2019",
            "body": "Verified on Mac 10.14.6 and Win10x64 with Firefox Nightly 73.0a1 (64-bit).",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "alexandra-martin",
            "datetime": "Dec 10, 2019",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "ianb",
            "datetime": "Dec 10, 2019",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "ianb",
            "datetime": "Dec 10, 2019",
            "body": [],
            "type": "added this to the",
            "related_issue": null
        },
        {
            "user_name": "jenniferharmon",
            "datetime": "Dec 11, 2019",
            "body": [],
            "type": "pull",
            "related_issue": "#719"
        },
        {
            "user_name": "jenniferharmon",
            "datetime": "Dec 11, 2019",
            "body": [],
            "type": "pull",
            "related_issue": null
        },
        {
            "user_name": "alexandra-martin",
            "datetime": "Dec 12, 2019",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "ianb",
            "datetime": "Jul 22, 2020",
            "body": [],
            "type": "unassigned",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/mozilla-extensions/firefox-voice/issues/689",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "alexandra-martin",
            "datetime": "Dec 9, 2019",
            "body": "Mic permissions are enabled.\n\"Allow\" or \"Don't Allow\" button from “Allow Firefox Voice to Collect Voice Transcriptions” pop-up needs to be clicked.\nA command is made beforehand.Emoticons change to blue and change size.Nothing happens.Reproduced on Mac 10.14.6 and Win10x64 with Firefox Nightly 72.0a1 (64-bit).",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ianb",
            "datetime": "Dec 10, 2019",
            "body": "The colors do change, but it's so subtle and the lines are so thin that it's hard to tell. to give guidance on colors.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "alexandra-martin",
            "datetime": "Dec 11, 2019",
            "body": " from the mock-up, the emoticons are filled with blue and increased in size after being clicked and I assume this happens also on hover. But  can clarify exactly, if changes also apply when icons are hovered, or only when they are clicked, or both.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "awallin",
            "datetime": "Dec 11, 2019",
            "body": "We'll want a slightly different visual for hover than clicked to ensure there change between the two states is obvious.Attached are SVGs with a hover state for the two icons using a background with a slight opacity.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "alexandra-martin",
            "datetime": "Dec 12, 2019",
            "body": "Verified on Mac 10.14.6 and Win10x64 with Firefox Nightly 73.0a1 (64-bit). Not sure if there are changes when emoticons are clicked though.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "alexandra-martin",
            "datetime": "Dec 9, 2019",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "ianb",
            "datetime": "Dec 10, 2019",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "ianb",
            "datetime": "Dec 10, 2019",
            "body": [],
            "type": "added this to the",
            "related_issue": null
        },
        {
            "user_name": "jenniferharmon",
            "datetime": "Dec 11, 2019",
            "body": [],
            "type": "pull",
            "related_issue": "#730"
        },
        {
            "user_name": "ianb",
            "datetime": "Dec 11, 2019",
            "body": [],
            "type": "pull",
            "related_issue": null
        },
        {
            "user_name": "alexandra-martin",
            "datetime": "Dec 12, 2019",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "ianb",
            "datetime": "Jul 22, 2020",
            "body": [],
            "type": "unassigned",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/mozilla-extensions/firefox-voice/issues/678",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "alexandra-martin",
            "datetime": "Dec 6, 2019",
            "body": "Mic permissions are enabled.\"Settings\" page is displayed without issues.Nothing happens.Reproduced on Mac 10.14.6 and Win10x64 with Firefox Nightly 72.0a1 (64-bit).\nReproduced also for the \"Feedback?\" link when the \"Doorhanger\" is first opened.\nNot reproduced in other \"Doorhanger\" instances, like \"Type Input\", \"In progress\", \"Sorry, there was an issue\", \"Thanks for the feedback\".\n\"Settings\" button and \"Feedback?\" link work, when the \"How was your last experience?\" is displayed in the \"Doorhanger\".\nOn Mac the \"Feedback?\" link can be accessed if the mouse is place on the text underline. (2nd gif)",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ianb",
            "datetime": "Dec 6, 2019",
            "body": "Myself, , and  haven't been able to reproduce this. Do you have any other thoughts  ?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "awallin",
            "datetime": "Dec 6, 2019",
            "body": "Unable to reproduce.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "alexandra-martin",
            "datetime": "Dec 9, 2019",
            "body": "Sorry, it seems something was not right from my part, although I don't know what that was. After several attempts where I made new profiles on both Win and Mac, it was reproducing every time. When I tried it again today, the link and button work.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "jenniferharmon",
            "datetime": "Dec 13, 2019",
            "body": "The issue with some buttons not being clickable was because of a hidden text input field in the view. Even though it wasn't visible it was overlaying some things and preventing clicks. This has been resolved.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "alexandra-martin",
            "datetime": "Dec 16, 2019",
            "body": "Verified on Mac 10.14.6 and Win10x64 with Firefox Nightly 73.0a1 (64-bit).",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "alexandra-martin",
            "datetime": "Dec 6, 2019",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "ianb",
            "datetime": "Dec 6, 2019",
            "body": [],
            "type": "added this to the",
            "related_issue": null
        },
        {
            "user_name": "ianb",
            "datetime": "Dec 6, 2019",
            "body": [],
            "type": "self-assigned this",
            "related_issue": null
        },
        {
            "user_name": "ianb",
            "datetime": "Dec 6, 2019",
            "body": [],
            "type": "modified the milestones:",
            "related_issue": null
        },
        {
            "user_name": "ianb",
            "datetime": "Dec 9, 2019",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        },
        {
            "user_name": "alexandra-martin",
            "datetime": "Dec 13, 2019",
            "body": [],
            "type": "issue",
            "related_issue": "#745"
        },
        {
            "user_name": "alexandra-martin",
            "datetime": "Dec 16, 2019",
            "body": [],
            "type": "added  the",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/mozilla-extensions/firefox-voice/issues/514",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "awallin",
            "datetime": "Oct 30, 2019",
            "body": "When Google returns a sidebar card for a search we should display in the doorhanger (and preference over the main column snippit).Examples utterances:",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ianb",
            "datetime": "Oct 31, 2019",
            "body": "Should be fixed by ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "awallin",
            "datetime": "Nov 4, 2019",
            "body": "Cards are not/no longer being displayed for sidebar cards.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "awallin",
            "datetime": "Oct 30, 2019",
            "body": [],
            "type": "added this to the",
            "related_issue": null
        },
        {
            "user_name": "ianb",
            "datetime": "Oct 31, 2019",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        },
        {
            "user_name": "awallin",
            "datetime": "Nov 1, 2019",
            "body": [],
            "type": "issue",
            "related_issue": "#520"
        },
        {
            "user_name": "awallin",
            "datetime": "Nov 4, 2019",
            "body": [],
            "type": "reopened this",
            "related_issue": null
        },
        {
            "user_name": "ianb",
            "datetime": "Nov 4, 2019",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/mozilla-extensions/firefox-voice/issues/486",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "dholbert",
            "datetime": "Oct 24, 2019",
            "body": "STR:\n(1) Click the mic icon on your toolbar.\n(2) Watch the gear icon (and try to click it, pretending you're a bit slow with your mouse)ACTUAL RESULTS:\nThe gear moves between three different positions, due to the dialog resizing as its content changes.  (There are three phases: \"Listening\", \"One Second\", and then \"Sorry, there was an issue\".  Each phase has a different dialog height and a different position of the gear.)EXPECTED RESULTS:\nThe gear should be at a consistent position so that it is easy to click.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "xlisachan",
            "datetime": "Mar 8, 2020",
            "body": " I am an Outreachy applicant. Can I be assigned to this issue?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ianb",
            "datetime": "Mar 9, 2020",
            "body": "Unless  feels differently, I think there's nothing left to actually fix on this ticket. It does move around a little bit when the examples open up, but otherwise it's OK. Though if  wanted to move it to a more consistent location (e.g., the top of the popup) then we could reopen.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "awallin",
            "datetime": "Mar 9, 2020",
            "body": "Yea, it's ok to close.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ianb",
            "datetime": "Oct 25, 2019",
            "body": [],
            "type": "added this to the",
            "related_issue": null
        },
        {
            "user_name": "ianb",
            "datetime": "Dec 3, 2019",
            "body": [],
            "type": "modified the milestones:",
            "related_issue": null
        },
        {
            "user_name": "ianb",
            "datetime": "Mar 9, 2020",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/OlafenwaMoses/ImageAI/issues/527",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "Sanket307",
            "datetime": "May 1, 2020",
            "body": "Hello,when i try to run customobjectdetection on google colaboratory with gpu getting  below error.Please help me to figure it out.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Terizian",
            "datetime": "May 18, 2020",
            "body": "I think custom_objects takes a CustomObjects object, not a dictionary as you have there.I would suggest commenting the two lines and writing this: ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "vinaykumarprabhu",
            "datetime": "May 30, 2020",
            "body": " ,the parameter that needs to be passed should to custom object should have the values mentioned for all the output categories supported by imageai, which in ur case is not i.e. u have specified only {'person':'valid'}\nInstead u should have done {'person': 'valid', 'bicycle': 'invalid', 'car': 'invalid', 'motorcycle': 'invalid', 'airplane': 'invalid', 'bus': 'invalid', 'train': 'invalid', 'truck': 'invalid', 'boat': 'invalid', 'traffic light': 'invalid', 'fire hydrant': 'invalid', 'stop sign': 'invalid', 'parking meter': 'invalid', 'bench': 'invalid', 'bird': 'invalid', 'cat': 'invalid', 'dog': 'invalid', 'horse': 'invalid', 'sheep': 'invalid', 'cow': 'invalid', 'elephant': 'invalid', 'bear': 'invalid', 'zebra': 'invalid', 'giraffe': 'invalid', 'backpack': 'invalid', 'umbrella': 'invalid', 'handbag': 'invalid', 'tie': 'invalid', 'suitcase': 'invalid', 'frisbee': 'invalid', 'skis': 'invalid', 'snowboard': 'invalid', 'sports ball': 'invalid', 'kite': 'invalid', 'baseball bat': 'invalid', 'baseball glove': 'invalid', 'skateboard': 'invalid', 'surfboard': 'invalid', 'tennis racket': 'invalid', 'bottle': 'invalid', 'wine glass': 'invalid', 'cup': 'invalid', 'fork': 'invalid', 'knife': 'invalid', 'spoon': 'invalid', 'bowl': 'invalid', 'banana': 'invalid', 'apple': 'invalid', 'sandwich': 'invalid', 'orange': 'invalid', 'broccoli': 'invalid', 'carrot': 'invalid', 'hot dog': 'invalid', 'pizza': 'invalid', 'donut': 'invalid', 'cake': 'invalid', 'chair': 'invalid', 'couch': 'invalid', 'potted plant': 'invalid', 'bed': 'invalid', 'dining table': 'invalid', 'toilet': 'invalid', 'tv': 'invalid', 'laptop': 'invalid', 'mouse': 'invalid', 'remote': 'invalid', 'keyboard': 'invalid', 'cell phone': 'invalid', 'microwave': 'invalid', 'oven': 'invalid', 'toaster': 'invalid', 'sink': 'invalid', 'refrigerator': 'invalid', 'book': 'invalid', 'clock': 'invalid', 'vase': 'invalid', 'scissors': 'invalid', 'teddy bear': 'invalid', 'hair dryer': 'invalid', 'toothbrush': 'invalid'}\nand this would have worked.And also as mentioned  if u specify detector.CustomObjects(truck=True) this method actually return a dictionary as mention\n\ned above.Hope this _helps.*\n",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Sanket307",
            "datetime": "Jun 9, 2020",
            "body": "Thanks for your comments.Issue solved, As i am replacing original script but it is not replaced in colab so it generate error.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Sanket307",
            "datetime": "Jun 9, 2020",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/OlafenwaMoses/ImageAI/issues/391",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "rEufrazio",
            "datetime": "Oct 29, 2019",
            "body": "The code I am trying to run is the one below, and it is almost identical to the one available at the documentation for \"Video and Live-Feed Detection and Analysis\":The error is as follows:I have already installed the latest version, v.2.1.5, and tried the YOLOv3 and TinyYOLOv3 models, both returning the same error. Also tried 2 different cameras.At first I thought it might be the threading problem, as I was using the multithreaded solution from imutils, but it turns out that the same thing is happening with the cv2.VideoCapture.Could you please help me out? I have no idea what is causing this problem.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "rEufrazio",
            "datetime": "Nov 6, 2019",
            "body": "Could someone please help me here? I'm two weeks in and still have the same problem.I recently discovered that this just happens when I use the  in any way, even if I assign it to another variable.Already updated and downgraded the library and dependencies to every possible option, and tried using the other \"for\" methods, with no success.If anyone could help me in any way I would be very grateful.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "rEufrazio",
            "datetime": "Nov 6, 2019",
            "body": "I managed to solve the problem. It looks like the function will always display this message when anything wrong happens inside the  call. The error was being caused simply because I was calling the  function incorrectly and not calling  inside the method.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "rEufrazio",
            "datetime": "Nov 6, 2019",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/iNavFlight/inav/issues/2920",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "gianturcom",
            "datetime": "Mar 14, 2018",
            "body": "\nOMNIBUSF7V2\n\n1.9.2\n NO_Go to CLI, execute  command copy its output to  and provide a link to a paste here.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "gianturcom",
            "datetime": "Mar 14, 2018",
            "body": "Zapped LED strip, not a software issue.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "gianturcom",
            "datetime": "Mar 14, 2018",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/iNavFlight/inav/issues/216",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "digitalentity",
            "datetime": "May 17, 2016",
            "body": "I'm thinking about supporting a cheap OpFlow ADNS3080 mouse sensor, but it should be connected to SPI bus. We have a few options:Ideas?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "DzikuVx",
            "datetime": "May 17, 2016",
            "body": "Hmm... can we make our own FC board with 5 UARTs please?\nBut seriously, I'v been thinking about similar problem and the best solution I've found is MSP hub/bridge/proxy with USB port.\nIt allows to connect multiple MSP devices, with different speeds and passes messages to FC and then passes answer to device that asked for info. If messages would be queued then response can be presented to proper external device. But building smth like this is as probable as FC with 5 UARTs",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "DzikuVx",
            "datetime": "May 17, 2016",
            "body": "And from sensor docs: \"Distance from lens reference plane to surface: 2.4mm (typical)\". So what would be this thing useful for?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "digitalentity",
            "datetime": "May 17, 2016",
            "body": "If equipped with a lens it can be used up to several meters distance. ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "DzikuVx",
            "datetime": "May 17, 2016",
            "body": "And now we are talking! How do you think, what kinds of refresh rates would be required here? 10Hz?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "theArchLadder",
            "datetime": "May 17, 2016",
            "body": "Searching youtube for \"optical flow sensor\" gave some interesting videos.\n\nHard to tell but it does not look more accurate than a ublox M8N gps, but i guess that could be up to bad tuning. At least it allows indoor poshold...",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "digitalentity",
            "datetime": "May 17, 2016",
            "body": " the more the better - we don't have an absolute position measurement with this sensor - only relative motion (velocity) in arbitrary units (if we have sonar sensor - in proper cm/s). I think at least 10Hz is absolutely required. 50Hz should give better results.\nThat's likely optical flow without any assistance. We will benefit from inertial position esitmation and quite possibly have much better results. One caveat - we need working sonar to correctly process optical flow data. On miniquads sonar is almost useless - noise from propellers overloads it at altitudes >50-70 cm.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "digitalentity",
            "datetime": "May 17, 2016",
            "body": "Ok, got ADNS3080 working with Arduino. It really needs a good light, but it works. A first step to have optical flow in INAV.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "digitalentity",
            "datetime": "May 17, 2016",
            "body": "Actually, in well-lit environments it's rather stable. I moved the sensor over my desk a few dozen times and accumulated the flow values - error is minimal. Now a big task of attaching it to test copter and make it fly!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "theArchLadder",
            "datetime": "May 17, 2016",
            "body": "I'm guessing it requires some clever code to compensate for when the copter tilts over and it look like the ground is moving, but the copter actually just changes attitude...?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "digitalentity",
            "datetime": "May 17, 2016",
            "body": "Yes, it certainly does.\nThe most challenging part is making it work with our position estimator and provide readings in meters. Also ADNS3080 will likely return invalid data when copter is yawing.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "martinbudden",
            "datetime": "May 20, 2016",
            "body": "This looks very interesting.The new sonar code allows easy implementation of other rangefinders, for example the  infrared rangefinder or the PulsedLight LIDAR-Lite rangefinder (although these may no longer be available now that Garmin has bought PulsedLight). These rangefinders avoid the problems sonar has with propeller noise.Anyway, it's on my todo list to implement drivers for these rangefinders, but in the medium rather than short term future (I have to get hold of one first).",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "johnsilvester",
            "datetime": "Oct 19, 2016",
            "body": "How's the development on this going? Any luck with the ADNS3080 Optical Flow Sensor?\nExcited to hear!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Jivefunk",
            "datetime": "Nov 4, 2016",
            "body": "Just created an account to follow this thread. I also need this implementation for my quad.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "digitalentity",
            "datetime": "Nov 4, 2016",
            "body": "This is a very slo-mo task, sorry. Eventually we'll see opflow support, but probably not very soon.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "kitchung",
            "datetime": "Nov 4, 2016",
            "body": "I'd love to see this implemented too!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "digitalentity",
            "datetime": "Nov 4, 2016",
            "body": "Work is being slowly done here ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "kitchung",
            "datetime": "Nov 4, 2016",
            "body": " Thanks for the info, subscribing there now.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bk79",
            "datetime": "May 5, 2017",
            "body": " playing with a cheap defective mouse from banggood I've found that inside it was using an a flow sensor marked KA8\n\nlooks like it's uses a serial protocol probably is worth trying using I2C protocol to read it",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "digitalentity",
            "datetime": "May 9, 2017",
            "body": " protocol of that sensor seems to be half-duplex SPI and it's possible to connect it to a dedicated SPI interface. Worth trying.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bk79",
            "datetime": "May 11, 2017",
            "body": "  it's a two wire communication, spi half duplex shouldn't be at least with three?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "10ishq",
            "datetime": "Nov 17, 2017",
            "body": " , a separate board with open source hardware with 3080 optical flow sensor which could calculate horizontal movements as well as compensates for tilt using a gyroscope+magnetometer+accelerometer, with a separate processor, cortex M0 seems a good idea, just like ardupilot folks did with PX4Flow but cheaper. your thoughts?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "stale",
            "datetime": "May 13, 2018",
            "body": "This issue / pull request has been automatically marked as stale because it has not had any activity in 60 days. The resources of the INAV team are limited,  and so we are asking for your help.\nThis issue / pull request will be closed if no further activity occurs within two weeks.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "stale",
            "datetime": "May 27, 2018",
            "body": "Automatically closing as inactive.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "markandkymward",
            "datetime": "Mar 11, 2019",
            "body": "Anyone interested in PX4FLOW sensor?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "vc",
            "datetime": "Mar 11, 2019",
            "body": "very important for me",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "0120shrey",
            "datetime": "Apr 28, 2019",
            "body": "Hi! I'm here after reading about the experimental OPFLOW mode in the 2.0.0 release notes. After reading through a lot of threads on github, I now know that it needs an ADNS3080 sensor, and a sonar (I don't know which). But I couldn't find anything on how to actually connect and use it. I have a quad running on Omnibus F4 clone, which i'm willing to crash! Any support would be great!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "georgekucher",
            "datetime": "Apr 28, 2019",
            "body": "+1 I have matek f722 and us100 sonar and desire to buy opt flow sensor. Which one?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "stale",
            "datetime": "Jun 27, 2019",
            "body": "This issue / pull request has been automatically marked as stale because it has not had any activity in 60 days. The resources of the INAV team are limited,  and so we are asking for your help.\nThis issue / pull request will be closed if no further activity occurs within two weeks.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "whoim2",
            "datetime": "Aug 31, 2019",
            "body": "Тоже хочется поэкспериментировать с простыми и недорогими датчиками оптическими. Лазерный дальномер скоро приедет, буду пробовать использовать по i2c.\nОптический датчик хотелось бы подключить по spi либо тоже i2c, поскольку все uart заняты. Но это не критично, для помещения можно отключать gps и перенастраивать inav.\nГотов погрузится в компиляцию прошивки под свои omnibusf4prov3.\nЕсли могу чем то помочь - обращайтесь.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "whoim2",
            "datetime": "Aug 27, 2020",
            "body": "Where i may read about msp2 messages, opflow, sonar data?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "digitalentity",
            "datetime": "May 17, 2016",
            "body": [],
            "type": "added",
            "related_issue": null
        },
        {
            "user_name": "digitalentity",
            "datetime": "Jun 15, 2016",
            "body": [],
            "type": "pull",
            "related_issue": "#283"
        },
        {
            "user_name": "martinbudden",
            "datetime": "Sep 8, 2016",
            "body": [],
            "type": "issue",
            "related_issue": "cleanflight/cleanflight#529"
        },
        {
            "user_name": "stale",
            "datetime": "May 13, 2018",
            "body": [],
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "stale",
            "datetime": "May 27, 2018",
            "body": [],
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "shellixyz",
            "datetime": "Mar 11, 2019",
            "body": [],
            "type": "removed  the",
            "related_issue": null
        },
        {
            "user_name": "shellixyz",
            "datetime": "Mar 11, 2019",
            "body": [],
            "type": "reopened this",
            "related_issue": null
        },
        {
            "user_name": "stale",
            "datetime": "Jun 27, 2019",
            "body": [],
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "digitalentity",
            "datetime": "Jun 27, 2019",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/keras-team/keras/issues/14401",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "GrzegorzKrug",
            "datetime": "Jan 26, 2021",
            "body": "In simple words I got class that loads params and weights. So everytime I recreate model, and load weights with method . But sometimes or maybe every 2 runs, error pops up for no reason.Get 2 questions about this. This most likely corelated with . Reason of error can be cause by model instantly saved after creating? or Ctrl+C is break some keras savings maybe?It does not matter if checkpoint file exists or not. Error still happens.\nAnd I will mention that I am not using any TF checkpoint features, it all happend within kerasWindows 10 x64",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "akloss",
            "datetime": "Jul 22, 2021",
            "body": "I had a similar issue, however I'm working with a custom training loop and checkpoint.read/write instead of using the keras functions.\nMy problem was that the optimizer weights are only created when apply_gradients is called for the first time. So creating a checkpoint object (where the saved weights are then restored to) before that will result in a checkpoint that does not contain the optimizer variables and thus runs into an error when restoring from a file that does.A workaround that seems to work for me is manually calling optimizer._create_all_weights(var_list) before restoring the checkpoint, where var_list is the trainable_weights of the model.Maybe adding a call of optimizer._create_all_weights() in the compile or in save_weights function of keras Models would ensure that the created checkpoint is always complete with respect to the optimizer?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "jvishnuvardhan",
            "datetime": "Oct 26, 2021",
            "body": " Sorry for the late response. Is this still an issue for you?Can you please share a simple standalone code to reproduce the issue? The code you mentioned above is throwing errors. If possible please share a colab gist or jupyter notebnook. Thanks!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "google-ml-butler",
            "datetime": "Nov 2, 2021",
            "body": "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "GrzegorzKrug",
            "datetime": "Nov 3, 2021",
            "body": " sorry, not really, thats why I pust so broad description, it just points to specific state in github. I guess there is some problem with dependencies, did you used package versions from post above  maybe?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "jvishnuvardhan",
            "datetime": "Nov 3, 2021",
            "body": " I tried to run your code with recent TF/keras versions.  library is not getting imported.  is a gist for reference. Thanks!Can you please run your code with recent TF/keras versions?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "GrzegorzKrug",
            "datetime": "Nov 4, 2021",
            "body": "Check my github link, its my module with parameters named ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "jvishnuvardhan",
            "datetime": "Nov 20, 2021",
            "body": "I ran your code (including ) and I don't see any error as your are facing.  is a gist for reference. Thanks!Following is the outputIf you still have any question, please share a simple standalone code. It is hard to debug long code. Thanks!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "google-ml-butler",
            "datetime": "Nov 27, 2021",
            "body": "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "google-ml-butler",
            "datetime": "Dec 4, 2021",
            "body": "Closing as stale. Please reopen if you'd like to work on this further.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "google-ml-butler",
            "datetime": "Jan 26, 2021",
            "body": [],
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "saikumarchalla",
            "datetime": "Feb 4, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "fchollet",
            "datetime": "Jun 16, 2021",
            "body": [],
            "type": "removed  the",
            "related_issue": null
        },
        {
            "user_name": "jvishnuvardhan",
            "datetime": "Oct 26, 2021",
            "body": [],
            "type": "self-assigned this",
            "related_issue": null
        },
        {
            "user_name": "jvishnuvardhan",
            "datetime": "Oct 26, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "google-ml-butler",
            "datetime": "Nov 2, 2021",
            "body": [],
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "google-ml-butler",
            "datetime": "Nov 3, 2021",
            "body": [],
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "jvishnuvardhan",
            "datetime": "Nov 20, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "google-ml-butler",
            "datetime": "Nov 27, 2021",
            "body": [],
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "google-ml-butler",
            "datetime": "Dec 4, 2021",
            "body": [],
            "type": "",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/keras-team/keras/issues/11481",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "brunoalano",
            "datetime": "Oct 24, 2018",
            "body": "I'm trying to build a multiple-input single-output network using Keras (functional API), but I'm getting NaN loss for every epoch (validation loss too).I already tried with other optimizers like Adam and Nadam. I also tested using Tensorback, directly in the TF Session, and got the same issue.Info:",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "brunoalano",
            "datetime": "Oct 24, 2018",
            "body": "I also tried to change it to a , and encode as one_hot of 2 classes (true / false). It also gives NaN as loss.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "kevinluvian",
            "datetime": "Mar 27, 2019",
            "body": "any updates regarding this issue?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "gabrieldemarmiesse",
            "datetime": "Oct 24, 2018",
            "body": [],
            "type": "added",
            "related_issue": null
        },
        {
            "user_name": "Harshini-Gadige",
            "datetime": "Nov 13, 2018",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "Harshini-Gadige",
            "datetime": "Nov 13, 2018",
            "body": [],
            "type": "added",
            "related_issue": null
        },
        {
            "user_name": "fchollet",
            "datetime": "Jun 16, 2021",
            "body": [],
            "type": "removed  the",
            "related_issue": null
        },
        {
            "user_name": "fchollet",
            "datetime": "Jun 24, 2021",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/keras-team/keras/issues/12969",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "ZeroMaxinumXZ",
            "datetime": "Jun 16, 2019",
            "body": "Okay, so... I'm trying to implement a custom loss function in tf-keras.My tf version is 1.13.1, my keras version is 2.2.4, my OS is Linux Mint Ubuntu 16.04, and my python version is Anaconda Python 3.6.8Basically, this loss function is a Keras dense siamese neural network that I'm trying to get to learn a loss between y_true and y_pred. However I receive the above error every time the model above this loss func. compiles. The input_shape param is (1, 1920), and the code is as follows:Siamese Net Code:Error + Traceback:",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "jvishnuvardhan",
            "datetime": "Jun 18, 2019",
            "body": " Please provide a standalone code to reproduce the issue. Thanks!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ZeroMaxinumXZ",
            "datetime": "Jun 20, 2019",
            "body": ", I fixed this issue by adding a tensorflow Session, and using the backend. Closing this.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "jvishnuvardhan",
            "datetime": "Jun 18, 2019",
            "body": [],
            "type": "added",
            "related_issue": null
        },
        {
            "user_name": "jvishnuvardhan",
            "datetime": "Jun 18, 2019",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "ZeroMaxinumXZ",
            "datetime": "Jun 20, 2019",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/label-studio/issues/1797",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "EliasRas",
            "datetime": "Nov 30, 2021",
            "body": "\nIf you zoom in when labeling an image, the movement of the cursor and the crosshair do not match. I haven't tested but the movement of the crosshair seems to be multiplied by the amount of zoom (e.g. 2x distance with 200% zoom).\nThe crosshair and the cursor would move together.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Dec 3, 2021",
            "body": " Thank you for your report, I've created a JIRA ticket for this, hope it will be fixed soon.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "TrueWodzu",
            "datetime": "May 25, 2022",
            "body": "A new Label Studio user here. How can I enable a cross hair? I've searched everywhere but can't find it.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "May 27, 2022",
            "body": "  ---  is an image attribute.<Image crosshair=\"true\" ... >",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "May 27, 2022",
            "body": "btw this issue has been fixed, most likely in 1.4.1. And 100% in the  branch.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "TrueWodzu",
            "datetime": "May 27, 2022",
            "body": " Thank you, works like a charm.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "EliasRas",
            "datetime": "Nov 30, 2021",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Dec 3, 2021",
            "body": [],
            "type": "added",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "May 27, 2022",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/label-studio/issues/1358",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "Morgana025",
            "datetime": "Aug 25, 2021",
            "body": "\nWhen labeling an audio track, the audio pointer does not move where my mouse pointer is but always starts from the beginning. Therefore, it becomes impossible to reproduce only an already labeled region or to listen to a part of the waveform in the middle.\nSteps to reproduce the behavior:\nThe audio playing pointer moves to the position of my mouse pointer.\nThis problem does not exist in the ’interface preview‘ in the ‘Setup’, but it will appear when labeling.This issue was also mentioned here:  and ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Morgana025",
            "datetime": "Aug 26, 2021",
            "body": "\nMay I also ask a question about the audio tracks displaying settings? Is there a method to display only one channel for stereo audio?\nThe strangest thing is that now when I try to label the mono-waveforms, everything works as expected while the problem persists if I work with the stereo audios.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Aug 29, 2021",
            "body": " Do you use Local Storages? If yes, try this PR please: ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Aug 29, 2021",
            "body": "unfortunately, there is no such method. You can simply convert your audios before the import using ffmpeg.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Morgana025",
            "datetime": "Aug 30, 2021",
            "body": " Thanks for the answers.\nI tried both with Local Storage and \"direct\" import. In the end, what seems to work for me, is to use direct import and mono-waveforms.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Morgana025",
            "datetime": "Aug 30, 2021",
            "body": "Today, I see this issue too:\"A page or script is accessing at least one of navigator.userAgent, navigator.appVersion, and navigator.platform. In a future version of Chrome, the amount of information available in the User Agent string will be reduced.\nTo fix this issue, replace the usage of navigator.userAgent, navigator.appVersion, and navigator.platform with feature detection, progressive enhancement, or migrate to navigator.userAgentData.\nNote that for performance reasons, only the first access to one of the properties is shown.\"I'm not very lucky!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Morgana025",
            "datetime": "Aug 30, 2021",
            "body": "Little update: The solution for my last problem was to change the browser from Chrome to Firefox",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Aug 30, 2021",
            "body": "Yes, it looks like a browser specific thing.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Morgana025",
            "datetime": "Aug 25, 2021",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Aug 30, 2021",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/keras-team/keras/issues/12042",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "flyingduck92",
            "datetime": "Jan 15, 2019",
            "body": "Hello guys, I am trying to make a face recognition with VGG16 pretrained model in Keras.However the training did not increase the accuracy.\nI only have 46 data training, 26 validation, and 12 classesHow to increase the accuracy ? Thanks.This is my actual code:On the 7 epoch the accuracy still the same:",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "flyingduck92",
            "datetime": "Jan 15, 2019",
            "body": "I try to change the batch size to 3. The loss become nan on epoch 30",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "abtExp",
            "datetime": "Jan 16, 2019",
            "body": "Use softmax activation.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "flyingduck92",
            "datetime": "Jan 16, 2019",
            "body": " It is works. But the accuracy did not increase:",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "colt18",
            "datetime": "Jan 16, 2019",
            "body": "You need to elaborate the \"face recognition\" that you are dealing with. Is it 12 classes with a total of 46 training and 26 validation images or are there a total of 72 images for each class. In either way your sample size is too small. In addition to this, CNN implementations that you use are better suited for large inter- class variation problems. For instance cat, dog and mouse classification would be more successful then classifying 3 persons with different traits. In the end faces will look a like and your model may not found meaningful features to classify. BTW your val accuracy is just random guess. Try pre-deep learning methods for face recognition such as Eigenfaces, LBP etc.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "flyingduck92",
            "datetime": "Jan 19, 2019",
            "body": " hi thanks for the response. Sir now i am trying to change it using dlib library for face recognition",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "msymp",
            "datetime": "Jan 22, 2019",
            "body": "Thank you  . This issue is now closed. Thanks.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "qiaohong-li",
            "datetime": "May 13, 2019",
            "body": "This is because you do not call the preprocess_input method coming with VGG net.\nYou scale the input by divide it by 224 to the range 0-1.\nThis is not keras VGG preprocessing way.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "msymp",
            "datetime": "Jan 15, 2019",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "msymp",
            "datetime": "Jan 17, 2019",
            "body": [],
            "type": "self-assigned this",
            "related_issue": null
        },
        {
            "user_name": "msymp",
            "datetime": "Jan 17, 2019",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "msymp",
            "datetime": "Jan 22, 2019",
            "body": [],
            "type": "removed  the",
            "related_issue": null
        },
        {
            "user_name": "msymp",
            "datetime": "Jan 22, 2019",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/label-studio/issues/1263",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "royschwartz2",
            "datetime": "Aug 9, 2021",
            "body": "\nThere is a cool feature that highlights the region on which the mouse cursor hovers. However, when zooming into an image, the highlight is thrown off target and shown in the wrong location.\nSteps to reproduce the behavior:\nAnnotate, zoom in, hover over the relevant annotation with the mouse, observe image.\nThe highlight should be in the correct place.\nThe highlighted annotations are for the right-most and left-most purple-annotated lesions in this medical image. Due to the zoom they appear below the originals and in different scale.\nAdd any other context about the problem here.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Gondragos",
            "datetime": "Aug 26, 2021",
            "body": "We have made some fixes for that in LS 1.2, it might help.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Oct 12, 2021",
            "body": " Does the latest version 1.3 fix this issues?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "royschwartz2",
            "datetime": "Oct 20, 2021",
            "body": "Yes it does",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "royschwartz2",
            "datetime": "Aug 9, 2021",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": null,
            "datetime": [],
            "body": [],
            "type": "",
            "related_issue": "heartexlabs/label-studio-frontend#228"
        },
        {
            "user_name": "makseq",
            "datetime": "Oct 12, 2021",
            "body": [],
            "type": "added",
            "related_issue": null
        },
        {
            "user_name": "royschwartz2",
            "datetime": "Oct 20, 2021",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/keras-team/keras/issues/11819",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "marc88",
            "datetime": "Dec 7, 2018",
            "body": "I get the following error after running an embedding layer as;Each datapoint here is a number(index). Upon checking indices[6,4] I found the followingar_train_data is an array of shape (162896, 5) where each value is  between [0, 23624).\nThe training stops towards the end of the first epoch with the error above.Am amazed! 5088 is no where out of range for [0, 23624).  Can anyone suggest what could be the issue here?\nPlease suggest if additional code snippets are required for clarity.\nThe model roughly goes below as:Full error trace:Keras version - 2.2.4\ntensorflow version: 1.5.0Regards",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "SriRangaTarun",
            "datetime": "Dec 8, 2018",
            "body": "You can try increasing vocab_size in the Embedding layer from 23624 to 23625.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Surojit88",
            "datetime": "Dec 9, 2018",
            "body": "  It's a common practice to have the embeddings as vocab_size+1 and I've just done that by having my embeddings at 23624 with a vocab size of 23623. So, the problem doesn't lie there. : Is there anyway you can help? Apologies but, I couldn't understand the meaning of the tag added. Is this a bug that has something to do with these versions of Keras/TF?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "gabrieldemarmiesse",
            "datetime": "Dec 9, 2018",
            "body": "There is a description for each tag that you can see if you put your mouse on it.This means that this may be a bug, but I'm not sure. It could be a user error. Someone needs to investigate to go to the bottom of it. (not necessarily me since I don't have the time to investigate in depth each issue in keras).",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "mkaze",
            "datetime": "Dec 12, 2018",
            "body": " It seems there is (are) an element(s) with index  in the training data: . Use  to find out where they are: .Have you used an ?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "marc88",
            "datetime": "Dec 12, 2018",
            "body": "  As suggested above, that's not the case",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "jvishnuvardhan",
            "datetime": "Mar 13, 2019",
            "body": "\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Could you mention which TF version you are using? Thanks!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "completelyboofyblitzed",
            "datetime": "Mar 14, 2019",
            "body": "I'm having the same issue:increasing the vocabulary length doesn't helpWhat could be the issue in this case?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "jvishnuvardhan",
            "datetime": "May 7, 2019",
            "body": "It looks like you haven't used a template to create this issue. Please resubmit your issue using a template from . We ask users to use the template because it reduces overall time to resolve a new issue by avoiding extra communication to get to the root of the issue. We will close this issue in lieu of the new one you will create from the template. Thank you for your cooperation.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "gabrieldemarmiesse",
            "datetime": "Dec 8, 2018",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "jvishnuvardhan",
            "datetime": "Mar 13, 2019",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "jvishnuvardhan",
            "datetime": "Mar 13, 2019",
            "body": [],
            "type": "self-assigned this",
            "related_issue": null
        },
        {
            "user_name": "jvishnuvardhan",
            "datetime": "Mar 13, 2019",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "jvishnuvardhan",
            "datetime": "May 7, 2019",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/keras-team/keras/issues/2653",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "moon5648",
            "datetime": "May 7, 2016",
            "body": "From this page: It says that I can read labels not as integers, but as meaningful names by reading the batches.meta file in the dataset.But I just can't seem to find a way to read the file.I tried by modifying the keras/datasets/cifar10.py at , like below:But I get an error message like below:KeyError                                  Traceback (most recent call last)\n in ()\n24     return data, labels, label_names\n25\n---> 26 data, labels, label_names = load_data()\n27\n28 print(labels[10], label_names[7]) in load_data()\n20         bpath = os.path.join(path, 'batches.meta')\n21         data, labels = load_batch(fpath)\n---> 22         label_names = load_batch(bpath)\n23\n24     return data, labels, label_names/home/robotics/anaconda3/lib/python3.5/site-packages/keras/datasets/cifar.py in load_batch(fpath, label_key)\n17             d[k.decode(\"utf8\")] = v\n18     f.close()\n---> 19     data = d[\"data\"]\n20     labels = d[label_key]\n21KeyError: 'data'It doesn't look like I'm on the right track, so could anyone help me with this please??In addition, I'm trying to display how my model does via displaying the target image and my model prediction with meaningful names.How can I do those also??Thank you very much in advance.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "fchollet",
            "datetime": "May 7, 2016",
            "body": "The indices of each labels can be read on this page:0 is airplane, 1 is automobile, etc.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "sachin1066",
            "datetime": "Jun 19, 2017",
            "body": "using this code <<     >>\nfor cifar10 for python\ngot this error",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "pGit1",
            "datetime": "Feb 15, 2018",
            "body": "How about for CIFAR 100? I need the Coarse and Fine labels",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dqii",
            "datetime": "May 13, 2018",
            "body": "It would be nice to have the coarse labels easily available as well.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "angpapadi",
            "datetime": "Sep 17, 2018",
            "body": "is it the same for cifar100? are they ordered too in the dataset page? e.g. ids 0-5 are aquatic mammals etc?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "itai12312",
            "datetime": "Dec 27, 2018",
            "body": "No, it doesn't look like that. Here is the list:\ncoarse_label = [\n'apple', # id 0\n'aquarium_fish',\n'baby',\n'bear',\n'beaver',\n'bed',\n'bee',\n'beetle',\n'bicycle',\n'bottle',\n'bowl',\n'boy',\n'bridge',\n'bus',\n'butterfly',\n'camel',\n'can',\n'castle',\n'caterpillar',\n'cattle',\n'chair',\n'chimpanzee',\n'clock',\n'cloud',\n'cockroach',\n'couch',\n'crab',\n'crocodile',\n'cup',\n'dinosaur',\n'dolphin',\n'elephant',\n'flatfish',\n'forest',\n'fox',\n'girl',\n'hamster',\n'house',\n'kangaroo',\n'computer_keyboard',\n'lamp',\n'lawn_mower',\n'leopard',\n'lion',\n'lizard',\n'lobster',\n'man',\n'maple_tree',\n'motorcycle',\n'mountain',\n'mouse',\n'mushroom',\n'oak_tree',\n'orange',\n'orchid',\n'otter',\n'palm_tree',\n'pear',\n'pickup_truck',\n'pine_tree',\n'plain',\n'plate',\n'poppy',\n'porcupine',\n'possum',\n'rabbit',\n'raccoon',\n'ray',\n'road',\n'rocket',\n'rose',\n'sea',\n'seal',\n'shark',\n'shrew',\n'skunk',\n'skyscraper',\n'snail',\n'snake',\n'spider',\n'squirrel',\n'streetcar',\n'sunflower',\n'sweet_pepper',\n'table',\n'tank',\n'telephone',\n'television',\n'tiger',\n'tractor',\n'train',\n'trout',\n'tulip',\n'turtle',\n'wardrobe',\n'whale',\n'willow_tree',\n'wolf',\n'woman',\n'worm',\n]mapping = {\n'aquatic mammals': ['beaver', 'dolphin', 'otter', 'seal', 'whale'],\n'fish': ['aquarium_fish', 'flatfish', 'ray', 'shark', 'trout'],\n'flowers': ['orchid', 'poppy', 'rose', 'sunflower', 'tulip'],\n'food containers': ['bottle', 'bowl', 'can', 'cup', 'plate'],\n'fruit and vegetables': ['apple', 'mushroom', 'orange', 'pear', 'sweet_pepper'],\n'household electrical device': ['clock', 'computer_keyboard', 'lamp', 'telephone', 'television'],\n'household furniture': ['bed', 'chair', 'couch', 'table', 'wardrobe'],\n'insects': ['bee', 'beetle', 'butterfly', 'caterpillar', 'cockroach'],\n'large carnivores': ['bear', 'leopard', 'lion', 'tiger', 'wolf'],\n'large man-made outdoor things': ['bridge', 'castle', 'house', 'road', 'skyscraper'],\n'large natural outdoor scenes': ['cloud', 'forest', 'mountain', 'plain', 'sea'],\n'large omnivores and herbivores': ['camel', 'cattle', 'chimpanzee', 'elephant', 'kangaroo'],\n'medium-sized mammals': ['fox', 'porcupine', 'possum', 'raccoon', 'skunk'],\n'non-insect invertebrates': ['crab', 'lobster', 'snail', 'spider', 'worm'],\n'people': ['baby', 'boy', 'girl', 'man', 'woman'],\n'reptiles': ['crocodile', 'dinosaur', 'lizard', 'snake', 'turtle'],\n'small mammals': ['hamster', 'mouse', 'rabbit', 'shrew', 'squirrel'],\n'trees': ['maple_tree', 'oak_tree', 'palm_tree', 'pine_tree', 'willow_tree'],\n'vehicles 1': ['bicycle', 'bus', 'motorcycle', 'pickup_truck', 'train'],\n'vehicles 2': ['lawn_mower', 'rocket', 'streetcar', 'tank', 'tractor'],\n}",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "adam-dziedzic",
            "datetime": "Nov 19, 2020",
            "body": "I extended the mappings between fine and coarse labels by  to other useful mappings between fine (classes) and coarse labels (super classes) for CIFAR100: An example of a mapping from id of a fine label to id of a coarse label:",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Sehaba95",
            "datetime": "Oct 9, 2021",
            "body": "Here is a CIFAR-100 labels, since, I was facing problems to find them, I will share them in here:You can get the label of a given class with this line of code:I wish that will help.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "fchollet",
            "datetime": "May 7, 2016",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/label-studio/issues/1241",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "royschwartz2",
            "datetime": "Aug 5, 2021",
            "body": "\nWhen making a brush stroke, part of the brush stroke disappears while working on the stroke, only to appear again when releasing the mouse click.\nSteps to reproduce the behavior:\nCreate a brush stroke of more than just a click.\nThe brush stroke (mask) should appear throughout the annotation process. Otherwise, this is quite confusing.\nIf applicable, add screenshots to help explain your problem.\nAdd any other context about the problem here.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nicholasrq",
            "datetime": "Aug 26, 2021",
            "body": "successfully reproduced it. please, expect a fix in the next release",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "hlomzik",
            "datetime": "Oct 14, 2021",
            "body": "Hi,  !\nCan you check PR  ? The problem was in drafts saving in the middle of drawing process, so now I changed the way it triggers and stores, so it should not interfere with drawing no more. Will be merged soon after checks.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Oct 27, 2021",
            "body": " The fix is in the master branch. Feel free to reopen this issue if the problem persists.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "royschwartz2",
            "datetime": "Aug 5, 2021",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "hlomzik",
            "datetime": "Oct 14, 2021",
            "body": [],
            "type": "pull",
            "related_issue": "#1609"
        },
        {
            "user_name": "makseq",
            "datetime": "Oct 15, 2021",
            "body": [],
            "type": "added",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Oct 16, 2021",
            "body": [],
            "type": "added this to the",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Oct 27, 2021",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/label-studio/issues/1096",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "fanweiya",
            "datetime": "Jun 24, 2021",
            "body": "thanks label-studio,very good label annotation tools,please add slide the mouse over the picture and zoom in and out of the picture.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Jul 23, 2021",
            "body": " it's already there. Please add zoom=\"true\" and zoomControl=\"true\" to  tag.\nHope it solves your issue.For more info:\n",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "fanweiya",
            "datetime": "Jun 24, 2021",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Jul 23, 2021",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/label-studio/issues/959",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "danielspicar",
            "datetime": "May 21, 2021",
            "body": "\nIn v. 1.0.1 I could draw a rectangle (bounding box) on top of another bounding box. In v 1.0.2 this sopped working. Using the same procedure I cannot draw a new bounding box.\nWhen drawing the second rectangle on top of the first while pressing the CTRL key, I should be able to draw the second rectangle just like the first one and it should be placed \"on top\" of the first rectangle.\nI think this hotkey was undocumented. However is is extremely important for my use case to be able to draw bounding boxes on top or inside of each other.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "May 22, 2021",
            "body": " Thank you for your report, I've reproduced this bug too.\n",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Jul 1, 2021",
            "body": "This bug was fixed in . Feel free to reopen if you have this problem again.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "danielspicar",
            "datetime": "May 21, 2021",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "May 22, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "May 22, 2021",
            "body": [],
            "type": "added this to the",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Jun 30, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Jul 1, 2021",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/label-studio/issues/862",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "Nuccy90",
            "datetime": "Apr 29, 2021",
            "body": "I'm trying to build from source because I want to get a fix for an issue with the mouse pointer in audio playback. I get the following error:I also tried to run LS afterwards and I get this error:This happens on Ubuntu 20.04 and I am installing in a blank environment.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Apr 29, 2021",
            "body": "Try this one:",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "niklub",
            "datetime": "May 7, 2021",
            "body": " please reopen if Max's suggestion won't work for you",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "arianpasquali",
            "datetime": "May 13, 2021",
            "body": "Same error here on Ubuntu 20.04.I run pipdeptree to check conflicts and this is what I get",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "May 13, 2021",
            "body": " It looks strange, because we don't use Jinja2.. Are you on a fresh python env? Could you check that LS was installed from scratch into the new env?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Nuccy90",
            "datetime": "Apr 29, 2021",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "niklub",
            "datetime": "May 7, 2021",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/label-studio/issues/757",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "suvojit-0x55aa",
            "datetime": "Apr 6, 2021",
            "body": "Having to hold and drag the mouse during bounding box annotation can be a bit jarring specially if zoom level is not set correctly.An option to use two click bounding box drawing where user will click on two diagonal points  of the bounding box.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Jul 1, 2021",
            "body": "This bug was fixed in . Feel free to reopen if you have this problem again.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "suvojit-0x55aa",
            "datetime": "Apr 6, 2021",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Apr 6, 2021",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Apr 6, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "niklub",
            "datetime": "Apr 20, 2021",
            "body": [],
            "type": "removed this from",
            "related_issue": null
        },
        {
            "user_name": "niklub",
            "datetime": "Apr 20, 2021",
            "body": [],
            "type": "added this to the",
            "related_issue": null
        },
        {
            "user_name": "niklub",
            "datetime": "Apr 20, 2021",
            "body": [],
            "type": "added",
            "related_issue": null
        },
        {
            "user_name": "niklub",
            "datetime": "Apr 20, 2021",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "niklub",
            "datetime": "Apr 20, 2021",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "nicholasrq",
            "datetime": "May 31, 2021",
            "body": [],
            "type": "pull",
            "related_issue": "heartexlabs/label-studio-frontend#199"
        },
        {
            "user_name": "makseq",
            "datetime": "Jun 30, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Jul 1, 2021",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        },
        {
            "user_name": "niklub",
            "datetime": "Mar 9, 2022",
            "body": [],
            "type": "removed this from",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/label-studio/issues/424",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "p-sodmann",
            "datetime": "Sep 17, 2020",
            "body": "\nEspecially when modifying existing roi polygons, e.g. prelabeling it is not possible (?) to  add or remove points.\nadd ctrl click on polygon points to remove points and alt click to add new points when clicking on a line.\nalso please add different cursors: ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "hlomzik",
            "datetime": "Sep 17, 2020",
            "body": "Hi! You can always add a point on any edge of polygon — there is green ghost point appears under the cursor when you mouse over the edge. Do you have it?\nBut currently you can not remove point from polygon, this is important lack of functionality, we'll fix it soon. Our plan to delete point by double click on it — pretty common behaviour. Does it fit?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "p-sodmann",
            "datetime": "Sep 17, 2020",
            "body": "That would work as well.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "hlomzik",
            "datetime": "Jun 7, 2021",
            "body": "fixed by  some time ago\nnow you can delete polygon point with double click",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "p-sodmann",
            "datetime": "Sep 17, 2020",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "hlomzik",
            "datetime": "Oct 5, 2020",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "niklub",
            "datetime": "Mar 29, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "hlomzik",
            "datetime": "Jun 7, 2021",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/label-studio/issues/423",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "tlaud",
            "datetime": "Sep 14, 2020",
            "body": "\nOne of the great features of Label Studio is the possibility of keyboard-only labeling by relying on hotkeys. Another great feature is the machine learning backend for label suggestions. In a use case, in which not only a bounding box is labeled but also classes are annotated, it would be nice to toggle the bounding box - which might occlude image parts relevant to the classes labeling - on/off with a hotkey\nA hotkey which toggles the visibility of all bounding boxes for an image.Thanks :)",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "hlomzik",
            "datetime": "Sep 14, 2020",
            "body": "Hi! That's good and simple idea, thank you! First of all we have to add button to hide all regions and then hotkey can be assigned to it)\nWe'll do this soon, I'll update you here.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Oct 8, 2021",
            "body": "Please, try alt + h.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "tlaud",
            "datetime": "Sep 14, 2020",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "hlomzik",
            "datetime": "Oct 5, 2020",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "niklub",
            "datetime": "Mar 29, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Oct 5, 2021",
            "body": [],
            "type": "modified the milestones:",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Oct 7, 2021",
            "body": [],
            "type": "added",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Oct 8, 2021",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/label-studio/issues/825",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "SN4KEBYTE",
            "datetime": "Apr 20, 2021",
            "body": "\nIn the audio task, when I click the audio waveform, the audio playing pointer does not move to the position of my mouse pointer, resulting in that every time I want to listen to a part in the middle, I always listen from the beginning.\nSteps to reproduce the behavior:\nThe audio playing pointer move to the position of my mouse pointer.\nIf applicable, add screenshots to help explain your problem.\nThis problem does not exist in the ’interface preview‘ in the ‘Setup’, but it will appear when labeling.This issue was also mentioned here: ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Apr 20, 2021",
            "body": "Please, try the latest commits from the master branch. I hope it's fixed there.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "SN4KEBYTE",
            "datetime": "Apr 20, 2021",
            "body": "Thank you for response, I'll try it!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "SN4KEBYTE",
            "datetime": "Apr 21, 2021",
            "body": "I've tried the latest commits, but the bug is still active :(",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Apr 23, 2021",
            "body": " Could you send your  page? (or )",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "SN4KEBYTE",
            "datetime": "Apr 27, 2021",
            "body": "\n{\n\"package\": {\n\"version\": \"1.0.1\",\n\"short_version\": \"1.0\",\n\"latest_version_from_pypi\": \"1.0.1\",\n\"latest_version_upload_time\": \"2021-04-05T19:13:41\",\n\"current_version_is_outdated\": false\n},\n\"backend\": {\n\"commit\": \"71278b\",\n\"date\": \"2021-04-05 11:30:54 -0700\",\n\"branch\": \"master\",\n\"version\": \"1.0.0+87.g71278b0b\"\n},\n\"label-studio-frontend\": {\n\"commit\": \"5164462ced2fe8a0bbdd7cd9c4a5bec3772577ab\",\n\"branch\": \"master\",\n\"date\": \"2021-03-31T10:57:00Z\"\n},\n\"dm2\": {\n\"commit\": \"7751a996682f145d651123af27286f4f392c293c\",\n\"branch\": \"master\",\n\"date\": \"2021-04-02T13:15:22Z\"\n}\n}",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Apr 27, 2021",
            "body": "I see you are using LS backend from 05 April, but we fixed it about 14 days ago: I recommend you to use master branch to solve this trouble.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "SN4KEBYTE",
            "datetime": "Apr 28, 2021",
            "body": "Thank you, this problem was solved!\nI've tested it on WSL2 Ubuntu 20.04, but on Windows 10 I had an error while creating project.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Apr 28, 2021",
            "body": " What problem did you have on Windows?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Morgana025",
            "datetime": "Aug 25, 2021",
            "body": "Hi, I'm getting the same error :(\nMy environment is:I tried to downgrade to version 1.1.0 but the issue is still there. Do you have any suggestions?\nThanks",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Aug 25, 2021",
            "body": " Coud you record a video with opened browser console and logs?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "SN4KEBYTE",
            "datetime": "Apr 20, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "SN4KEBYTE",
            "datetime": "Apr 20, 2021",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "SN4KEBYTE",
            "datetime": "Apr 28, 2021",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        },
        {
            "user_name": "Morgana025",
            "datetime": "Aug 25, 2021",
            "body": [],
            "type": "issue",
            "related_issue": "#1358"
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/label-studio/issues/409",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "p-sodmann",
            "datetime": "Aug 28, 2020",
            "body": "When using the ROI Polygon Tool, it is frustrating to have no visual feedback weather you will drag the whole polygon or change a single point. This often results in me dragging the whole polygon instead of a single point as intended.Change the cursor icon depending on the action that will happen when I drag at the current position.\nFor example curser:grab if I would move the whole polygon and cursor:move when I would move a single polygon corner.\nMaybe also change the cursor to cursor:crosshair while drawing new points / a new polygon.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Aug 28, 2020",
            "body": " I think you can implement this very quickly.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "hlomzik",
            "datetime": "Aug 28, 2020",
            "body": "Yes, sounds very easy and helpful, just to change  in one place. Will deploy soon, thanks!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Dec 21, 2020",
            "body": "It's fixed after 0.8.1 release.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "p-sodmann",
            "datetime": "Aug 28, 2020",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "p-sodmann",
            "datetime": "Sep 17, 2020",
            "body": [],
            "type": "issue",
            "related_issue": "#424"
        },
        {
            "user_name": "makseq",
            "datetime": "Dec 21, 2020",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/label-studio/issues/306",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "RenJinan",
            "datetime": "Jun 2, 2020",
            "body": "\nIn the audio task, when I click the audio waveform, the audio playing pointer does not move to the position of my mouse pointer, resulting in that every time I want to listen to a part in the middle, I always listen from the beginning.\nthe audio playing pointer move to  the position of my mouse pointer.\nThis problem does not exist in the ’interface preview‘ in the ‘Setup’, but it will appear when labeling.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Jun 2, 2020",
            "body": "",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "hlomzik",
            "datetime": "Jun 5, 2020",
            "body": "Hey, ! It sounds strange, especially if it works in preview. Could you please provide your config? How long is your audio? And what the error do you see? Screenshots or browser console output would be very helpful.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "RenJinan",
            "datetime": "Jun 6, 2020",
            "body": "Thank you very much for your reply! My configuration file is the same as the official sample, but the problem still exists. I made a GIF to show this problem and look forward to your help.\n",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Jun 8, 2020",
            "body": " have you any ideas?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "hlomzik",
            "datetime": "Jun 9, 2020",
            "body": "No ideas sadly :(\n do you have errors in browser console?\nI checked this config in LSF, it works well. I'll check in LS soon.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Jul 8, 2020",
            "body": " have you tried to use AudioPlus tag?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Sep 28, 2020",
            "body": "I hope it's fixed after 0.7.3 release.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "RenJinan",
            "datetime": "Jun 2, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "RenJinan",
            "datetime": "Jun 2, 2020",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "hlomzik",
            "datetime": "Jun 5, 2020",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Sep 28, 2020",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        },
        {
            "user_name": "SN4KEBYTE",
            "datetime": "Apr 20, 2021",
            "body": [],
            "type": "issue",
            "related_issue": "#825"
        },
        {
            "user_name": "Morgana025",
            "datetime": "Aug 25, 2021",
            "body": [],
            "type": "issue",
            "related_issue": "#1358"
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/label-studio/issues/265",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "johann-petrak",
            "datetime": "Apr 19, 2020",
            "body": "Create text classification project that shows text to the annotator. The text also includes URLs or terms that the annotator may want to look up.\nHowever normal copying the string to look up is not possible, presumably because the code that normally handles text selection in order create a sequence annotation (like for NER) is active.\n\"Normal copying\" would be that the  user marks the text to copy with the mouse, releases the mouse button (the marked text span stays highligthed) then presses Ctrl-C or right-clicks and chooses \"Copy\". This is not possible because the highlighted text immediately gets de-selected when the mouse button is released.A workaround is to press Ctrl-C while the mouse button for selecting the text is still being held, but this is unintuitive and hard to discover.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "johann-petrak",
            "datetime": "Apr 19, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "johann-petrak",
            "datetime": "Apr 19, 2020",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "hlomzik",
            "datetime": "May 20, 2020",
            "body": [],
            "type": "pull",
            "related_issue": "heartexlabs/label-studio-frontend#84"
        },
        {
            "user_name": "makseq",
            "datetime": "Jun 1, 2020",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/label-studio/issues/105",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "vijaygill",
            "datetime": "Oct 22, 2019",
            "body": "\nMany times I end up dragging whole polygon where I just want to move a point. In some cases it is very difficult to make it fit back in on the image.\nAllowing user to have a flag in config.json / config.xml to allow dragging of polygon when only CTRL key is pressed. This way I will be moving stuff when I am sure I want it to move.I am using only polygons for now so my problem may seem to be related to those only. But you can evaluate it for other shapes too and decide.\nNone TBH..\nNone",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "shevchenkonik",
            "datetime": "Oct 25, 2019",
            "body": "Yes, your point is scalable for other labeling types (for example bounding boxes) and I think that we implement this one on the next versions of LS. Currently, we are focused on features and bugs of polygons, bounding boxes, key points, image segmentation.If you can describe your workflow with polygons and Image zoom, then we'll implement more correct UI.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "VictorAtPL",
            "datetime": "Oct 25, 2019",
            "body": " \nI think this issue can have something in common with my list I wrote in :I think we should make here some conclusions what would be the best. I am planning to implement some improvements to  next month.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Jul 24, 2020",
            "body": "Polygons are strongly reworked and now it's much more comfortable.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "vijaygill",
            "datetime": "Oct 22, 2019",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "vijaygill",
            "datetime": "Oct 22, 2019",
            "body": [],
            "type": "changed the title",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Jul 24, 2020",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/apache/airflow/issues/25861",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "hwooson12",
            "datetime": "Aug 22, 2022",
            "body": "2.3.3On DAG Dependencies, all nodes don’t have links even though they seem clickable.The mouse pointer turns clickable(sorry, I couldn't capture the mouse pointer) and it activates the node. However it cannot be actually clicked.Each node has its reference so that having a link to move to a page that belongs to it could be better for users in terms of UX.Linux, but it's not depending on OSOtherDeployed with customized helm charts",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bbovenzi",
            "datetime": "Aug 22, 2022",
            "body": "Yes, I've wanted to add links and make this page more integrated into the app.That's what I've done over in . Right now, we're only showing dataset dependencies there. But we may expand it to be a more dynamic replacement of tis view.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "hwooson12",
            "datetime": "Aug 22, 2022",
            "body": [],
            "type": "added",
            "related_issue": null
        },
        {
            "user_name": "uranusjr",
            "datetime": "Aug 22, 2022",
            "body": [],
            "type": "added",
            "related_issue": null
        },
        {
            "user_name": "bbovenzi",
            "datetime": "Aug 22, 2022",
            "body": [],
            "type": "added",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/label-studio/issues/27",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "VictorAtPL",
            "datetime": "Aug 17, 2019",
            "body": "Hi,When can we expect the guide how to extend annotations types in your app?I need to annotate the part of pictures, in general:\nimage; many polygons; each polygon should have label like text/logo.I also need an annotation like image to text (for OCR fine-tuning).I am able to try writing the code myself, although I need your guidance. Could you tell me what files should I modify to add more annotation types?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "deppp",
            "datetime": "Aug 19, 2019",
            "body": "Hey Yep, we're working on updating the documentation as well as releasing a \"Getting Started\" guide. It will be covering both embedding and extending the functionality with additional data types.There is an initial implementation of the polygons, try out this config:For an image to text, you can use a config like this:To add more annotation types, I'd first check how other types are implemented  for example the one for .Let me know right away if you get stuck somewhere. We're glad to help!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "VictorAtPL",
            "datetime": "Aug 19, 2019",
            "body": ",\nThank you for your response. I will test it till Wednesday and get back here to presumably ask more questions.If it's ok for you, please do not close this issue for now.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "VictorAtPL",
            "datetime": "Aug 25, 2019",
            "body": " \nSorry guys, I didn't have time to look at it, but will in next week for sure.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "VictorAtPL",
            "datetime": "Sep 11, 2019",
            "body": "I made some little tests and it looks like the polygons are now not usable. I will make a list of changes I need to introduce to make it usable in my use case and I will try to address them.Could you tell me what was the purpose of  in ? Except making Polygon labels I need also to write some comment what is inside that (it varies every label, because it's text). Should I use  or develop another type in. e. ?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "VictorAtPL",
            "datetime": "Sep 13, 2019",
            "body": " \nMy question above is still up to date (about the ).I am now struggling with another problem. I try to run \"frontend\" (written in React) live, so not the compiled version run by backend. I try to do it by running the backend, and then executing  with . The frontend starts, but it looks like it's not in the production, because I can not see \"go to task list\" link.If you have some time, please answer me to these two questions.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "VictorAtPL",
            "datetime": "Sep 13, 2019",
            "body": "Well, so how can I debug the frontend? If I need to compile it every time and run it via backend to see the effect, it would take ages to progress with the code.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "VictorAtPL",
            "datetime": "Sep 14, 2019",
            "body": "I do not understand the way, how files with task and completions for it are created.When I place one task in  file and make a submit for it in frontend, it creates a file with completions, but without ,  and  keys. File such as this cannot be loaded later via frontend for in. e. update annotations.What's wrong with it? The task file should be created even before making completion, or the first completion should be saved with the fields containing information about task?It seems like there is some bug, or I use the app not how I should be.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "VictorAtPL",
            "datetime": "Sep 15, 2019",
            "body": "I hope  fixes the problem described above.Unfortunately I will have to look at the , because it looks like they are not loaded in the task view mode. It has the highest priority on my  list.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "deppp",
            "datetime": "Sep 16, 2019",
            "body": "Yep, normalization is a bit misleading name right now, as it's just a way to add a piece of extra information to the labeled part of data (entity). Alternatively, based on your use case, you can create a new tag that subclasses  and adds an input for that additional info you need.When you're saying that it's not usable, can you describe what's going wrong when you're using it?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "VictorAtPL",
            "datetime": "Sep 28, 2019",
            "body": "\nAs you can see the main problem is that the annotations doesn't load after save.Here are more code which could help in debugging the problem:\n",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "deppp",
            "datetime": "Oct 4, 2019",
            "body": " we've recently released an updated version for the Polygons, as well as the website, here some links you may find useful:Please let me know if the updated version works well for you.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "VictorAtPL",
            "datetime": "Oct 4, 2019",
            "body": "\nI've pulled your code and tested it deeply.I think a couple of things doesn't work at all, a couple of them are not intuitive and a couple of things are lack.Here is detailed list:Overall, your app is the best open-source annotation tool in the market, but for my case I have to work a little bit on details of polygon labels.The bugs are presented in following video:\nI will take care of the improvements & new features in the end of this month, or next month. But for the sake of your users use-experience, it would be nice if you fixed the bugs.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "deppp",
            "datetime": "Oct 7, 2019",
            "body": " Thanks for such a thorough testing and bug reporting! That's really helpful!We'll be looking into the bugs you've listed this week. Can I please ask you to add them as separate issues so that we have a more natural way to track what gets fixed and when. Thanks!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "VictorAtPL",
            "datetime": "Oct 10, 2019",
            "body": "\nSure, but next week. I am quite busy nowadays. I hope you can wait.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "shevchenkonik",
            "datetime": "Oct 18, 2019",
            "body": "\nThank you, your bug report is very helpful. Every item of your report will be a new issue. But I will write on this issue if the bug or feature will be ready.\nWill be fixed in patch release 0.2.1-4: ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "VictorAtPL",
            "datetime": "Oct 21, 2019",
            "body": "\nI've added three bugs listed above as new issues. The rest (2 bugs) have already corresponding issues and as you stated, one of them is already fixed.I won't create issues for improvements & new features, because I suppose you've got a plenty of work even without it. I will try to do it on my own at the end of the month or next month.I consider this issue as resolved, so I am closing this issue. Thank you.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "shevchenkonik",
            "datetime": "Aug 22, 2019",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "VictorAtPL",
            "datetime": "Oct 21, 2019",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        },
        {
            "user_name": "VictorAtPL",
            "datetime": "Oct 25, 2019",
            "body": [],
            "type": "issue",
            "related_issue": "#105"
        },
        {
            "user_name": "ReDeiPirati",
            "datetime": "Dec 6, 2019",
            "body": [],
            "type": "issue",
            "related_issue": "#142"
        },
        {
            "user_name": "snyk-bot",
            "datetime": "Apr 27, 2022",
            "body": [],
            "type": "pull",
            "related_issue": "gamerXI1/label-studio#12"
        }
    ]
},
{
    "issue_url": "https://github.com/botpress/botpress/issues/4464",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "hacheybj",
            "datetime": "Feb 3, 2021",
            "body": "\nWhen working with large flows, the flow-editor gives us a \"birds-eye view\" of the flow, which tends to make the nodes very small and unreadable.Also, the current mouse scroll-in implementation isn't super friendly.\nI've thought of a few ideas, but I'm definitely open to more.\nAlternatively, and probably the better solution would be to fix the scroll in implementation\n",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "hacheybj",
            "datetime": "Feb 3, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "Michael-N-M",
            "datetime": "Feb 3, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/carla-simulator/carla/issues/3579",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "flacomalone",
            "datetime": "Nov 12, 2020",
            "body": "Hi,When running CARLA server, if I try to use the mouse to drag and change the orientation of the camera (not the position), it will, but so much I have no control on it. Is there any way to change mouse sensibility? I don't remember having this issue in previous versions of CARLA",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Axel1092",
            "datetime": "Mar 3, 2021",
            "body": "Hi @davidtena98, sorry for the late response. We don't have means to change the sensitivity of the server camera. The rotation will be larger the greater the fps you get at any given point.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "uebian",
            "datetime": "Jul 18, 2021",
            "body": "Is there any options to set the sensitivity of the server camera?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "satyamjay-iitd",
            "datetime": "Feb 4, 2022",
            "body": "I have the same issue. I am running on ubuntu 18.04 with -vulkan. Mouse sensitivity is too high to navigate around the world. W/A/S/D works fine though. Was anyone able to fix this?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "stale",
            "datetime": "Apr 16, 2022",
            "body": "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Axel1092",
            "datetime": "Mar 3, 2021",
            "body": [],
            "type": "self-assigned this",
            "related_issue": null
        },
        {
            "user_name": "corkyw10",
            "datetime": "Mar 3, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "stale",
            "datetime": "Apr 16, 2022",
            "body": [],
            "type": "",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/botpress/botpress/issues/5584",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "bassamtantawi-botpress",
            "datetime": "Oct 19, 2021",
            "body": "\nI followed the below link to use an upload control:\nIt worked successfully but I found couple of problems:\n",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Michael-N-M",
            "datetime": "Oct 26, 2021",
            "body": "The worst problem with the document upload currently in use is that you have no way of easily linking the uploaded document to the uploader.I think either the naming should be very clear or the document should be stored against unique user id in the database for easier querying.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "codeilm",
            "datetime": "Jun 21, 2022",
            "body": "Hi,\nMay I know, how to use the uploaded image by user?Means, I want to send the uploaded file to server using api.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bassamtantawi-botpress",
            "datetime": "Oct 19, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "Michael-N-M",
            "datetime": "Oct 26, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "EFF",
            "datetime": "Nov 1, 2021",
            "body": [],
            "type": "pull",
            "related_issue": "#5647"
        }
    ]
},
{
    "issue_url": "https://github.com/carla-simulator/carla/issues/5362",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "Chup123",
            "datetime": "Apr 13, 2022",
            "body": "CARLA version: 0.9.12\nPlatform/OS: ubuntu 18.04\nProblem you have experienced: When I move the mouse in any direction, the camera will always do the same thing. It will look at the ground and spin to the right. Even when I try to move the mouse somewhere else.\nWhat you expected to happen: When i point the mouse up, I except the camera to move to the position I put my mouse, just like in a video game\nSteps to reproduce: Move the mouse in any map. It will always move in this direction\nOther information (documentation you consulted, workarounds you tried): I tried to lower to mouse sensitivity in the DefaultInput.ini file. This made it much more clear that the mouse always moves in this direction",
            "type": "commented",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/botpress/botpress/issues/5108",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "hacheybj",
            "datetime": "Jun 15, 2021",
            "body": "\nThe auto-complete in a nodes Edit Action is too small with nested scroll bars.Additional note: the nested scrollbar cannot be clicked for scroll as it makes the \"dropdown\" disappear. Only use of the mouse scroll is possible.\nWider value fields, and potentially a taller popup window.\n",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "EFF",
            "datetime": "Jun 19, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "Michael-N-M",
            "datetime": "Jun 29, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/botpress/botpress/issues/4742",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "dvncan",
            "datetime": "Mar 23, 2021",
            "body": "\nThe code editor's file view does not change when toggling between a local & global file of the same name. The bug causes confusion when copying a global file to a local bot or vise versa. As the tab which has the file name does not denote if it is a global or local file, you must close the tab and be sure to open the correct file before editing.\nEither two tabs open, one for each copy of the file. A denotation will have to accompany the file title.\nor\nThe file tab toggles between the two files being selected, and the title of the tab does not change.\nLocal file (clicking both)\n\nGlobal file (clicking both)\n\nDemo deployment",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Michael-N-M",
            "datetime": "Mar 26, 2021",
            "body": "With the new tab support in code editor, maybe opening it in a seperate tab then appending the file paths to the title to differentiate them.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dvncan",
            "datetime": "Mar 26, 2021",
            "body": "that would work, something like \"global/hitlnext.json\" right next to \"local/hitlnext.json\".. You only really need to differentiate the second tab, but right now it makes me confused as to which file I am editing.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dvncan",
            "datetime": "Mar 23, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "Michael-N-M",
            "datetime": "Mar 26, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "charlescatta",
            "datetime": "Oct 6, 2021",
            "body": [],
            "type": "issue",
            "related_issue": "#5467"
        },
        {
            "user_name": null,
            "datetime": [],
            "body": [],
            "type": "",
            "related_issue": "#5632"
        }
    ]
},
{
    "issue_url": "https://github.com/carla-simulator/carla/issues/5100",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "kanji95",
            "datetime": "Jan 21, 2022",
            "body": "I am having trouble getting the 3D world coordinates in CARLA. Basically, I use mouse click to select the destination point (pixel coordinate) in the front-view RGB camera image and get the depth of that point through a depth sensor. Now, I get the 3D coordinate using the following,\n\nHere, K is the intrinsic camera matrix and T_cam is Camera extrinsic transformation matrix. However, the final point I get after the above transformation is not correct, it is basically a point behind the vehicle's starting position. I am unable to figure out what I am doing wrong.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "brscholz",
            "datetime": "Feb 7, 2022",
            "body": "Correct me if I'm wrong, but I think that won't work anyway because you have zero clue as to where along its way the ray that is represented by the pixel met a surface? How do you want to extract that depth information from the image?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "stale",
            "datetime": "Apr 16, 2022",
            "body": "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "stale",
            "datetime": "Apr 16, 2022",
            "body": [],
            "type": "",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/facebookresearch/fairseq/issues/4405",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "gutzcha",
            "datetime": "May 9, 2022",
            "body": "Hey,\nIs it possible to change the sampling rate from 16k to 250k?\nI am trying to use the wav2vec model and pretrain it on animal (mouse) vocalizations which are emitted at ~100 kHz, so my sampling rate is 250 kHz. I can't downsample it to 16kHz as was suggested to others with similar questions.\nEach audio segment is about 2-5 seconds long.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "gutzcha",
            "datetime": "May 9, 2022",
            "body": [],
            "type": "added",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/voxel51/fiftyone/issues/113",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "tylerganter",
            "datetime": "May 29, 2020",
            "body": "Google Photos please!!!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "brimoor",
            "datetime": "Jun 1, 2020",
            "body": "Spelling this out in a bit more detail:No selection mode:Image selection mode:Image selection mode (nice to have):",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "tylerganter",
            "datetime": "Jun 1, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "tylerganter",
            "datetime": "Jun 1, 2020",
            "body": [],
            "type": "changed the title",
            "related_issue": null
        },
        {
            "user_name": "tylerganter",
            "datetime": "Jun 1, 2020",
            "body": [],
            "type": "changed the title",
            "related_issue": null
        },
        {
            "user_name": "tylerganter",
            "datetime": "Jun 1, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "brimoor",
            "datetime": "Jun 1, 2020",
            "body": [],
            "type": "changed the title",
            "related_issue": null
        },
        {
            "user_name": "brimoor",
            "datetime": "Jun 1, 2020",
            "body": [],
            "type": "issue",
            "related_issue": "#139"
        },
        {
            "user_name": "lethosor",
            "datetime": "Aug 28, 2020",
            "body": [],
            "type": "issue",
            "related_issue": "#472"
        },
        {
            "user_name": "brimoor",
            "datetime": "Aug 28, 2020",
            "body": [],
            "type": "added",
            "related_issue": null
        },
        {
            "user_name": "lethosor",
            "datetime": "Sep 8, 2020",
            "body": [],
            "type": "pull",
            "related_issue": "#509"
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/4629",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "withtimesgo1115",
            "datetime": "May 11, 2022",
            "body": "Hi, I tried to import the canvas2d module and then use its API to draw a  Rect shape instead of using cvat web labeling tools. However, after creating a canvas2d instance and mounting the canvas.html() to my root container element, I cannot draw a rectangle on the canvas. Actually, I can see the red lines to draw the rectangle shape but once I clicked the mouse, the shape cannot appear on the canvas anymore. I just call the API like this:what's wrong with this, could anyone give me some kind of guidance? Thanks in advance!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "May 18, 2022",
            "body": "HiNeed more details to suggest, maybe code snippet, HTML code, gif demonstration, etc.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "kirill-sizov",
            "datetime": "Sep 19, 2022",
            "body": "Hi, , Is this issue still relevant for you?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "withtimesgo1115",
            "datetime": "Sep 19, 2022",
            "body": "Hey,  , nope, actually I have solved the problem. Thank you for your reminder :)",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "kirill-sizov",
            "datetime": "Sep 19, 2022",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Sep 19, 2022",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/4184",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "aschernov",
            "datetime": "Jan 16, 2022",
            "body": "Due to our experience based on annotation tasks with large number of object classes which need to be annotated, we formed our proposal about segmentation and layer modes development. Briefly, we are suggesting to move work with layers to a separate segmentation mode. We tried to imagine how it can look like on the image below:\nBelow I will list what exactly we'd like to see implemented in the tool:We're suggesting to move the main actions which we can do with a polygon to its (object) separate menu where we could turn on/off different action for this polygon, for example, auto bordering.\nA couple of words of automatic bordering. The logic we want to see here is when we choose the first point of a polygon to which we want to make auto bordering, the rest points of other polygons will be hidden.\nThe example of a polygons menu implemented in one annotation tool:\nListed and demonstrated aboveTried to make some proposals aboveYou may  channel for community support.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Sep 2, 2022",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Sep 2, 2022",
            "body": [],
            "type": "added this to",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/3941",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "katab",
            "datetime": "Nov 23, 2021",
            "body": "When you have used the mouse to edit an attribute you can use a keyboard shortcut directly after, without clicking in the frame or pressing TAB first.If you have used the mouse to edit an attribute you then have to either click in the frame with the mouse or press TAB before you can use any other keyboard shortcut.The annotation process would be more efficient and reliable if the keyboard shortcut works directly as expected.You may  channel for community support.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Nov 23, 2021",
            "body": " , thanks for the report. I will consider it as a bug because it can kill UX.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Nov 23, 2021",
            "body": [],
            "type": "added",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Nov 23, 2021",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Nov 23, 2021",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Dec 2, 2021",
            "body": [],
            "type": "self-assigned this",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/3438",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "nmanovic",
            "datetime": "Jul 19, 2021",
            "body": "When an user goes to a frame he/she should see the full scene. I will recommend to use \"bird eye view\" (top view) because it is easy to recognize the road, cars and other objects. Now users have to zoom out always (unnecessary action). The reference tool is initialized by a side view where all points are visible. It is also an acceptable solution.It was already a long story. Let me come back to the decision to show black and white points. The reference tool assigns different colors to a point depends on the distance from the ego-vehicle. Let me understand reasons why CVAT doesn't do that as well.When a 3D task is loaded, it doesn't allow users to manipulate with the loaded 3D frame using mouse. It isn't how the reference tool works and CVAT 2D works. It isn't convenient.\nFurthermore, if I choose \"move\" mode and go to another frame, \"select\" mode is activated and I  manipulate with the frame. Thus I can reproduce performance problems, which were reported previously.AR: please fix performance problems, but don't break/disable expected features and functionality.Projection of points on \"side\" and \"front\" views is excess. Please look at the reference tool and compare the current implementation in CVAT and expected implementation in the reference tool. On the same PCD file, in CVAT it is mostly impossible to see boundaries of objects on \"side\" and \"front\" views. Looks like points which are far away of the 3D bounding box should not be displayed at all.When I'm moving mouse under shapes, the selection works with a significant delay. I don't see the problem in the reference tool. Also, if I change \"opacity\" in the right side bar, UI is very unresponsive.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Aug 4, 2021",
            "body": "Start drawing a cuboid using a standard way, double-click a perspective view. UI is broken, cuboid cannot be drawn anymore, even in a new drawing session. Need to reload the page.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Jul 19, 2021",
            "body": [],
            "type": "pull",
            "related_issue": "#3234"
        },
        {
            "user_name": "nmanovic",
            "datetime": "Jul 19, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Aug 2, 2021",
            "body": [],
            "type": "issue",
            "related_issue": "#1475"
        },
        {
            "user_name": "bsekachev",
            "datetime": "Aug 4, 2021",
            "body": [],
            "type": "pull",
            "related_issue": "#3493"
        },
        {
            "user_name": "nmanovic",
            "datetime": "Aug 6, 2021",
            "body": [],
            "type": "pull",
            "related_issue": "#3524"
        },
        {
            "user_name": "nmanovic",
            "datetime": "Nov 20, 2021",
            "body": [],
            "type": "added this to",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/2550",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "aschernov",
            "datetime": "Dec 9, 2020",
            "body": "We have several suggestions how to improve the review mode:",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Dec 9, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Dec 9, 2020",
            "body": [],
            "type": "self-assigned this",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Dec 9, 2020",
            "body": [],
            "type": "added this to the",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Nov 24, 2021",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Nov 24, 2021",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Nov 24, 2021",
            "body": [],
            "type": "removed this from the",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/4642",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "aldyhelnawan",
            "datetime": "May 18, 2022",
            "body": "Greetings,Hi, I've faced a problem when I try to deploy a model to docker followed the documentation from the .\nEverything is working fine until the   part while I try to run this command:I got an error with the message as shown:I want to try to use the automatic annotation on my Windows 10  WSL2 machine, but I'm stuck on that error. Am I missing something during the installation? Or is there an alternative way to use it?\nThank you in advance,Best regards,\nAldy",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "aldyhelnawan",
            "datetime": "May 18, 2022",
            "body": "So I've managed to reinstall and continue to follow the steps that provided from the . When I tried to use the command:The process completed:And for using:I tried to deploy the YOLO v3 model, the process completed as message shown:Then I check the , the model is shown. But when I tried to use the AI Tool, the message shown:\nI checked , the model is shown and running:\nI'm actually getting confused here.\nIs the building process took that long? Or there's some error that I don't understand happen on my machine? I would appreciate any assistance.\nThank you in advance.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "May 18, 2022",
            "body": "Hi, I remember there was an issue that Deep extreme cut is not working in the latest version \nDid you pull CVAT from DockerHub or built it from sources (build with -f docker-compose.dev.yml file)?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "aldyhelnawan",
            "datetime": "May 18, 2022",
            "body": "Hi , thank you for your reply.I don't clearly understand the meaning of . But what I know is I've followed all the steps from  to installing the  for my .\nWhen installing the Automatic Annotation, I've also faced some issues similar to this  and managed to fix it.And also, I've tried to install it on my  from  to installing the  and it works fine with no error.I will try to follow from  and I will update the result.Thank you in advance.P.S.:\nSo, I notice from the  command that there are 2 , but one of them is . Is that normal?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "May 18, 2022",
            "body": "Sorry, I can't suggest anything about WSL, because I do not use it.If your built command does not include dev file (), installation receives the latest available image from DockerHub instead of making image using files from develop branch.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "aldyhelnawan",
            "datetime": "May 18, 2022",
            "body": "Hi .\nAs far as I follow the steps, I believe my built command doesn't include the dev file. Because there's no  on the command from the guide.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "aldyhelnawan",
            "datetime": "May 20, 2022",
            "body": "Hi , I've tried to follow these suggestions, but the error is still the same on my Windows 10 WSL2 machine. Even after reinstalling (again) from the beginning by following  to use the .I think it's ok for me now to use the CVAT auto annotation on my Linux Ubuntu 20.04 machine since there's no error or issue while I'm using it.\nThank you in advance.Best regards,\nAldy",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "kirill-sizov",
            "datetime": "Sep 13, 2022",
            "body": "Hi , Is this issue still relevant for you?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "aldyhelnawan",
            "datetime": "Sep 14, 2022",
            "body": "Hi   , I think we can close this issue for now. I have used Ubuntu 20.04 to use all CVAT features on my machine, and no issues to date (other than the cityscapes-dataset format that doesn't provide the JSON polygon file while exported).\nThank you for all your support.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "kirill-sizov",
            "datetime": "Sep 13, 2022",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "kirill-sizov",
            "datetime": "Sep 13, 2022",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Sep 14, 2022",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        },
        {
            "user_name": null,
            "datetime": "Sep 14, 2022",
            "body": [],
            "type": "moved this from",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/3387",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "hnuzhy",
            "datetime": "Jul 4, 2021",
            "body": "I have read and searched the official docs and past issues for the solution. No one had the same problem with me.I want to annotate the head orientation of people in 2D image with a standard 3D cube. Here, the head is a rigid object. A standard cube is defined as follows: three sides of any vertex are perpendicular to each other, and all twelve sides are equal in length, or in unit length.After labeling, we could get the eight projected vertices of the cube in the two-dimensional coordinate system. If three Euler angles (pitch, yaw, roll) are used to represent the orientation of the head, these precise projection points can be converted into corresponding angles.I have three suggestions or roadmaps for adding unit  label in the new version of CVAT.Here are two examples of 3D model interaction. The first is the rotation interaction of a 3D head model in mayavi. The interactive operation needs to rely on both mouse and keyboard. The second is to use the 3D image editing tool in Windows 10 to place and operate 3D models on 2D images. All you need to do is use the mouse.\nExample 1\nExample 2Looking forward to your reply. I will be willing to do whatever I can to advance this functional part.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "chiehpower",
            "datetime": "Jul 7, 2021",
            "body": "this is so cool feature ...",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Jul 7, 2021",
            "body": " , I agree that we need to improve the functionality. Your explanation is really helpful. Could you please describe your research area and organization? Unfortunately my team has huge amount of requests and we already have an approximate roadmap for Q3'21 and Q4'21. Thus I'm trying to clarify details which will help me to increase the priority of the feature.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "hnuzhy",
            "datetime": "Jul 8, 2021",
            "body": "Yes, it is a pretty cool function which is not easy to realize :-(",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "hnuzhy",
            "datetime": "Jul 8, 2021",
            "body": " Hi, I'm glad you agree to my proposal. I am a PhD student in computer department from SJTU University. My research field is the intersection of AI and education. The detailed research direction is object detection and pose estimation in computer vision. I would like to talk about the motivation of this question from two aspects.Recently, I've been studying the methods of attention detection for students in the classroom. Among them, head orientation (head pose estimation) is one of the key factors. However, as far as I know, the head pose estimation algorithm of multi-person in 2D image is not well developed. At present, there are some SOTA algorithms for head pose estimation of a single well cropped head, including  and . But their effect is not ideal, and it is not easy to extend to the case of multiple people in a single image. Most importantly, the datasets used by these algorithms are obtained by 3D head projection (), or the 3D Euler collected by depth camera in the experimental scene ().\nPrediction example 1 of FSA-Net (The input can only be a single person's head with visible face.)\nPrediction example 2 of FSA-Net (First, the head bbox of each person is detected by MTCNN, and then the single head is estimated. Therefore, this is not an efficient or essential multi-person head pose estimation algorithm.)\nPrediction example of WHE-Net (The input can only be a single person's head with wide range pose. The predictable yaw angle of the head is omnidirectional.)Dataset has always been the cornerstone of deep learning algorithms, so is head pose estimation. Therefore, I want to try to annotate the 3D head orientation, or three Euler angles of the head directly in the 2D image. As mentioned for the first time in this issue, the most accurate annotation scheme focuses on how to use 3D cube to interact freely on 2D images. In my opinion, once such a dataset is constructed, it will help promote the great progress of the corresponding algorithm research. For example, a bottom-up method could be designed to directly predict the pose of all heads in the image at one time. At the same time, compared with a single captured head image, the complete scene and human body information in the original image can assist more accurate head pose estimation.:After investigation, I didn't find tools with real 3D cube annotation. Fortunately, close functional options were found in CVAT. The first is . However, the new builded cuboid lacks rotation freedom. The second is . By annotating three consecutive non coplanar edges of a 3D cube approaching the head orientation, we can deduce the approximate Euler angle. Unfortunately, there is a great subjectivity error in this annotation process. We can't see the actual pose of the generated cube directly, unless we use a real 3D cube to annotate interactively. If we use this method reluctantly, the credibility of the final annotation will be questioned.Here are three examples of rough annotation results with . Images are all from the public  dataset. The object we annotate is the head with any orientation in the image, including the visible, occluded and invisible face. In many cases, the current method of  annotation is difficult and inaccurate.In a word, it is very useful to add interactive annotation of rigid 3D graphics (which can only be rotated, translated and scaled) to 2D images. In addition to supporting the head orientation marking, the new function can also be extended to the annotation of other rigid objects. After the construction of similar datasets about general objects, we can try to develop a simple and direct 3D object pose estimation algorithm only based on 2D images. We expect that this method can be comparable to estimation algorithms based on RGB-D or 3D point cloud.Finally, I am not good at giving the overall improvement framework of CVAT about this enhancement from UI design or code addition, but I am willing to do what I can. I sincerely thank CVAT's main contributors for their work, and hope to carefully consider adding this task to roadmap.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Kucev",
            "datetime": "Apr 7, 2022",
            "body": "I support the request. We also have a need for such functionality.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "schliffen",
            "datetime": "May 28, 2022",
            "body": "This is a growing request from automotive industry as well, we need cuboid annotations to be done on RGB images not points clouds.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "hnuzhy",
            "datetime": "May 28, 2022",
            "body": "Yes, you are right. Actually, I have written a simple 2D head pose annotation tool using  last year. As shown below, the annotator can label one head with adding a bounding box in the 2D image, and adjust the 3D head model through mouse or keyboard in the right area to make it have the similar orientation/pose with boxed head. The co-existed 3D cube will be projected in the 2D image. For every appearing head pose status, we will record the corresponding Euler angles.\n\nHowever, this tool can only run in desktop, and is not fully as what I expected originally (refer above question for details). Then, I was busy on other things until now. I did not update and perfect this tool for a long time. If possible, I still look forward to seeing this annotation function in .",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Jul 7, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Nov 20, 2021",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Nov 20, 2021",
            "body": [],
            "type": "changed the title",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/2088",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "jinzishuai",
            "datetime": "Aug 26, 2020",
            "body": "I am training a model using YOLOv5 and the objects are labelled using the :I am having a bit of challengens creating a labeling task in CVAT. I am able to generate the 80 labels in JSON format but  it seems that CVAT will reorder them labels  therefore breaking the original order of COCO.Note that \"person\" is the first entry in the COCO list.It seems that we have a bug in the placement of the first label to the very end.It is my understanding that the order of the labels are important for machine learning trainings since in the end, each label is represented as a integer number such as  for the \"cup\" class. If the data is now labelled with a different number, then the model will be completely wrong.You may  channel for community support.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "jinzishuai",
            "datetime": "Aug 26, 2020",
            "body": "Please note that I originally thought CVAT reorders the labels alphabetically but after further look at the resulting labels (screenshot above), they are actually not alphabetic either.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ActiveChooN",
            "datetime": "Dec 9, 2021",
            "body": ", can you please check if  would resolve the issue?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "jinzishuai",
            "datetime": "Aug 26, 2020",
            "body": [],
            "type": "changed the title",
            "related_issue": null
        },
        {
            "user_name": "jinzishuai",
            "datetime": "Aug 26, 2020",
            "body": [],
            "type": "changed the title",
            "related_issue": null
        },
        {
            "user_name": "snyk-bot",
            "datetime": "Oct 8, 2020",
            "body": [],
            "type": "pull",
            "related_issue": "#2278"
        },
        {
            "user_name": "azhavoro",
            "datetime": "Nov 30, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "azhavoro",
            "datetime": "Nov 30, 2020",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "azhavoro",
            "datetime": "Nov 30, 2020",
            "body": [],
            "type": "added this to the",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Nov 26, 2021",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Nov 26, 2021",
            "body": [],
            "type": "added",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Nov 26, 2021",
            "body": [],
            "type": "removed this from the",
            "related_issue": null
        },
        {
            "user_name": "ActiveChooN",
            "datetime": "Dec 9, 2021",
            "body": [],
            "type": "self-assigned this",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/2051",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "manybodycpa",
            "datetime": "Aug 19, 2020",
            "body": "Would it be possible to have a shortcut to quickly navigate through the different tracks? For example, I have track 1 from frames 50-100, track 2 from 75-125 and track 3 from 150 to 200. With the shortcut, I would press the corresponding key once to go from frame 0 directly to 50, a second time to jump to frame 75, and a third time to jump to frame 150. For example, this would be very useful to loop through tracks and eliminate false positive detections or check immutable labels of entire tracks.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Aug 26, 2020",
            "body": "I can suggest adding shortcuts to jump to the first/last frame of a track under mouse.\nGoing to the first frame of a next track looks at least not obvious (we can have a lot of tracks on different frames)",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "manybodycpa",
            "datetime": "Aug 26, 2020",
            "body": "Good point. Could we jump to the next frame that contains the beginning (first box) of one or more tracks?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Aug 26, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Aug 26, 2020",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Aug 26, 2020",
            "body": [],
            "type": "added this to the",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Nov 26, 2021",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Nov 26, 2021",
            "body": [],
            "type": "removed this from the",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Nov 26, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/1979",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "yohayonyon",
            "datetime": "Aug 3, 2020",
            "body": "Right click on any shape should open the track shape menu and not just the delete shape optionRight clicking when a rectangle or a cuboid s chosen a track shape menu is opened.\nOn any other shape type, only a delete shape option is opened.Open the same menu for all shapes. It would shorten the annotation time.The expected behavior will fasten the annotation process.You may  channel for community support.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Aug 10, 2020",
            "body": "Here are some statements:For cuboids and rectangles you can open only shape menu (as on your screenshots it's like a copy of side panel item for convenience)\nFor polygons and polylines you can also open shape menu (right click a shape, not a point of the shape) and you can open points menu (by clicking a point of the shape)\nFor points you can open only point menuSo, according to your request all shapes except of a points set have the same right-click behaviour.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "yohayonyon",
            "datetime": "Aug 10, 2020",
            "body": "Thank you for the clarification regarding polygons and polylines.\nIt will be more efficient to have the same right-screen-side menu opened for a point as well. This way annotators will be able to set label and attributes faster.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Aug 10, 2020",
            "body": "On the one hand I agree with you. On the other hand we should left ability to remove points from UI (without shortkeys).\nOne possible solution I see is to add a modifier key. So, if the key is pressed, we always open right-screen-side.\nMaybe you have other suggestions?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "yohayonyon",
            "datetime": "Aug 10, 2020",
            "body": "The points shape has no way to be marked as a whole, only a single point may be be marked at a time. I suggest to define such a way and when the entire shape is marked, the shape menu is opened.A modifier key sounds good to me.\nFor mouse users a 1st click on a point may mark only 1 point and a second may mark the entire points shape (and to generalize every following click may switch).",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "yohayonyon",
            "datetime": "Aug 3, 2020",
            "body": [],
            "type": "changed the title",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Aug 10, 2020",
            "body": [],
            "type": "changed the title",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Aug 10, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Aug 10, 2020",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Aug 10, 2020",
            "body": [],
            "type": "added this to the",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Nov 26, 2021",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Nov 26, 2021",
            "body": [],
            "type": "removed this from the",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/425",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "nmanovic",
            "datetime": "Apr 25, 2019",
            "body": "For some tasks it is better to view 4, 9, or even more images on one screen and use mouse clicks to choose relevant images (e.g. classification face/non-face).The feature can be used to review interpolation results or tracking as well.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "rushtehrani",
            "datetime": "Jun 12, 2019",
            "body": " would this support classification scenarios like this?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Jun 13, 2019",
            "body": " , sure. On server side we already support classification. Only need to implement it in UI.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "verasativa",
            "datetime": "Jan 3, 2020",
            "body": "We have an UI component for this task just running in the developer machine. I'm currently working on moving it to our production machine, and then we would love to make a PR with it.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "danielrich",
            "datetime": "Jan 30, 2020",
            "body": " This would be super cool. I am curious if you have any ETA on that PR being available.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Cittadini",
            "datetime": "Nov 13, 2020",
            "body": " can you give us any updates?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "verasativa",
            "datetime": "Nov 13, 2020",
            "body": "Actually I was emailed yesterday by Yoav from notraffic.tech asking about it. But I not longer work at Odd where we developed this feature, still I put him in contact with my old colleagues whom coded it and also would like to be integrated too. I'm now sending them a link to this tread, so they can comment on the issue.Good luck everybody!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Cittadini",
            "datetime": "Nov 13, 2020",
            "body": "Ok, thank you very much!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dotXem",
            "datetime": "Jan 3, 2022",
            "body": "Sorry for reopening this thread, but has this feature been added to CVAT? It would be very handy to have it!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Jan 4, 2022",
            "body": " , at the moment it isn't implemented and it isn't planned for the next release.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Apr 25, 2019",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Apr 25, 2019",
            "body": [],
            "type": "added this to the",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Jul 22, 2019",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Jul 22, 2019",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Oct 21, 2019",
            "body": [],
            "type": "issue",
            "related_issue": "#786"
        },
        {
            "user_name": "snyk-bot",
            "datetime": "Jul 13, 2021",
            "body": [],
            "type": "pull",
            "related_issue": "hixio-mh/cvat#33"
        },
        {
            "user_name": "nmanovic",
            "datetime": "Nov 28, 2021",
            "body": [],
            "type": "removed this from the",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/1215",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "ActiveChooN",
            "datetime": "Feb 28, 2020",
            "body": "Now we have only zoom control with scroll wheel movement, but it can be useful to add position control like in graphic editors. For example  for horizontal movement and  for vertical movement.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ActiveChooN",
            "datetime": "Feb 28, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Feb 29, 2020",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Feb 29, 2020",
            "body": [],
            "type": "added this to the",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Nov 28, 2021",
            "body": [],
            "type": "removed this from the",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Nov 28, 2021",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Nov 28, 2021",
            "body": [],
            "type": "issue",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/772",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "rsnk96",
            "datetime": "Oct 14, 2019",
            "body": "It would be nice to have a feature to generate superpixels, and label superpixels in one mouse-click (sort of like a brush, but it labels the superpixel if the mouse has hovered over with the Mouse Button pressed down). An easy idea for this is to run K-means in RGB+(x,y) space, like the SLIC/ algorithm doesA sample implementation of SLIC in C++ is available , this can be ported to OpenCV.js",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Oct 14, 2019",
            "body": " , did you try to annotate data using the approach? What is the annotation speed in the case? I like new features but I need some information how to prioritize them. Does the approach give better quality or better speed than traditional methods?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "rsnk96",
            "datetime": "Oct 14, 2019",
            "body": "This is a feature that is available in , sample usage:\nI believe this would give better speed in the following cases:",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "jrreyes29",
            "datetime": "Dec 6, 2019",
            "body": "How do you can port this to opencvjs because opencvjs don't support this method createSuperpixelLSC()",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "rsnk96",
            "datetime": "Dec 6, 2019",
            "body": "I'm not quite sure I followed you . Where is that method being called?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "jrreyes29",
            "datetime": "Dec 9, 2019",
            "body": "Hi  the method in opencv is this one ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "rsnk96",
            "datetime": "Dec 9, 2019",
            "body": "Ah, didn't know that it comes as a part of  now.I guess that leaves us with no option but to implement the superpixel method in JS from scratch...",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "jrreyes29",
            "datetime": "Dec 9, 2019",
            "body": "but implement that in js from scratch take long time hahahaha that is the idea about opencvjs",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "luiztauffer",
            "datetime": "May 10, 2020",
            "body": "superpixel annotation would be awesome!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "patzhang",
            "datetime": "Dec 17, 2020",
            "body": " is an implementation in javascript for Superpixels using SLIC. It has a nice  that you can try online.  Is the demo good enough to compare?Also, the  used superpixels (shown in the paper) in their .",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Hommus",
            "datetime": "May 3, 2022",
            "body": "\nAny ETA on this feature?How would one go about implementing a new tool / feature like this? I have created it in Python, I'm just struggling to re-implement it in javascript.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Oct 14, 2019",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Oct 14, 2019",
            "body": [],
            "type": "added this to the",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Oct 14, 2019",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Nov 20, 2019",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "juanmed",
            "datetime": "May 5, 2020",
            "body": [],
            "type": "issue",
            "related_issue": "#1492"
        },
        {
            "user_name": "snyk-bot",
            "datetime": "Nov 20, 2020",
            "body": [],
            "type": "pull",
            "related_issue": "#2468"
        },
        {
            "user_name": "nmanovic",
            "datetime": "Dec 17, 2020",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Feb 19, 2021",
            "body": [],
            "type": "issue",
            "related_issue": "#2800"
        },
        {
            "user_name": "nmanovic",
            "datetime": "Nov 28, 2021",
            "body": [],
            "type": "removed this from the",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/iNavFlight/inav/issues/1849",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "digitalentity",
            "datetime": "Jul 1, 2017",
            "body": "Finding a compact board that would support all of required sensors may become tricky, also wiring may become a pain in the back.Suggestion - create a very simple board (or family of boards) that will talk to main FC over a new half-duplex protocol and act as a bridge between actual sensor and FC with INAV firmware.To keep things compatible with most boards out there and also to keep additional costs low I suggest we use common UART in half-duplex mode. Transfer will happen in TDMA fashion with all data transfer scheduled by the FC (master). For physical interface I see two options:Bill of materials price for the convertor board would be abour 4-5$, fairly large SMD components can be used to allow DIY-style.List of possible use-cases for the convertor board:",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "giacomo892",
            "datetime": "Jul 1, 2017",
            "body": "Nice idea.I see also some others use-cases:",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "moggiex",
            "datetime": "Jul 4, 2017",
            "body": " I think I understand what you're trying to do here, my suggestion would be to try & keep everything as simple as possible.With that in mind, could a secondary flight controller be used as a \"slave\" device to achieve this?Matt",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "digitalentity",
            "datetime": "Jul 4, 2017",
            "body": "Yes, a secondary flight controller could be used (in fact it's a great idea).\nHowever I'm thinking also about higher reliability for bigger machines.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "digitalentity",
            "datetime": "Jul 6, 2017",
            "body": "Sensor bus protocol proposal (using one-wire UART as an interface).Master initiates transmission by sending command+slot identifier packed into 1 byte:\n - where CC is command code and SSSSSS is slot identifier.DISCOVER command is followed by 1 byte of DevID. A device with matching DevID must respond with 2 bytes of desired poll interval and 2 bytes of CRC-16. A slot number must be remembered by the device and used in further transmissionThis command doesn't have any argumentrs. A device that was assigned a slot must respond  with 8 bytes of data and 2 bytes of CRC. Response delay shouldn't be longer than 2ms (to avoid mixing it up for guard interval).At 100kbps speed transmission of 1 byte command + 10 byts of response will take ~1.3ms. If device makes 0.5ms delay we still fit info <3ms total activity time to allow 2ms guard interval after transfer finishes.A maximum of 8 bytes of data is allowed for compatibility with CAN Bus so one message will fit into one CAN frame. A sensor may have more than one ID (i.e. GPS)Proposed assignment scheme: 4 bits data class + 4 bits data typeClass 0x0 - AHRS/MARG sensors\n0x00 - reserved for something really high priority\n0x08 - Magnetic field vector (3D)Class 0x1 - Altitude and climb rate data\n0x10 - GPS altitude and climb rate\n0x11 - Barometric altitude\n0x12 - Rangefinder altitudeClass 0x2 - 2D-position and velocity data\n0x20 - GPS coordinates (LAT/LON) + validity flag (LAT/LON fit into 31 bits, this leaves us 2 bits for flags)\n0x21 - GPS velocities (2D) and CoG + validity flag\n0x22 - Optical flow vector (2D) and qualityClass 0x8 - RC control\n0x80 - RC channels (4 channels with 10-bit resolution + 4 channels with 6-bit resolution)Class 0xF - sensor statistics and information (low priority, low rate)\n0xF0 - GPS sat count, HDOP etc",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "DzikuVx",
            "datetime": "Jul 6, 2017",
            "body": "",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "digitalentity",
            "datetime": "Jul 6, 2017",
            "body": " that's just an idea of what sensor assignment may look like. Airspeed and surroundings - good catch :)WRITE messages could be implemented in a similar way as READ ones - only with different source of data on the wire.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "moggiex",
            "datetime": "Jul 6, 2017",
            "body": "Daft question gents, this line got me thinking:Thinking about FrSky kit whom has no \"satellite\" receivers support (there is the ability with the X8R I believe but the range is still low > 2.6Km) , could a second receiver be added to the child board, thus if the main one hits failsafe, the secondary one could be checked and if working, used instead?Thinking of your note around \"bigger machines\", on a bigger machine a secondary receiver could be easily placed in a different position to the main receiver.Just a thought!Matt",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Redshifft",
            "datetime": "Jul 6, 2017",
            "body": "RC Receivers are insignificant over Flight controller, sensors and code to control a Multirotor.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "digitalentity",
            "datetime": "Jul 7, 2017",
            "body": " good idea, it would be good to have multiple receiver support - we need to think about it.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "digitalentity",
            "datetime": "Jul 7, 2017",
            "body": " yes, sensor are more important, but reliable pilot input is also quite important thing to have. If we can add extra reliability - why shouldn't we?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Redshifft",
            "datetime": "Jul 7, 2017",
            "body": " You don't need to be far away before any RC link is useless to try and guide a multirotor home - might be inconvenient to drop RC link the but the FC and sensors will get you home and backed up by a second sensor suite which on the side could even be logging waypoints to get back safely. You could even add to that Airplane style mag-less navigation to home.\nIt's more likely  any RX backup will be subject to the same cause of failure as the primary ( generally blanking or interference)",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "digitalentity",
            "datetime": "Jul 8, 2017",
            "body": " Any redundancy is better than no redundancy. Also, nobody is restricting you to use two receivers of the same type. One, for instance, could be DragonLink, the other - Crossfire.\nEven if all sensors fail, if you have a working RC link - you still may be able to switch to manual and bring the plane back.\nFor copters, however, things are different - here I totally agree with you that having a set of backup sensors is better than a reliable link.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "digitalentity",
            "datetime": "Jul 8, 2017",
            "body": "Other ideas for this \"UAVBus\" protocol:",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "cabinw",
            "datetime": "Jul 10, 2017",
            "body": "  Got similar idea. It's really convenient for both multi-rotors and fixed-wings.\n Great idea! Using a secondary flight controller could be very helpful especially for long range fpv flights.I've designed a companion board for spracing f3 mainly for integrated OSD and separated BEC for servos. A companion board is not only for adding functions but also useful for deploying and wiring.Hope get more infos about \"UAVBus\" protocol.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "digitalentity",
            "datetime": "Jul 11, 2017",
            "body": "See this for first draft of  ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "stale",
            "datetime": "May 13, 2018",
            "body": "This issue / pull request has been automatically marked as stale because it has not had any activity in 60 days. The resources of the INAV team are limited,  and so we are asking for your help.\nThis issue / pull request will be closed if no further activity occurs within two weeks.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "stale",
            "datetime": "May 27, 2018",
            "body": "Automatically closing as inactive.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dimon777",
            "datetime": "Jan 28, 2020",
            "body": "There is a big class problems which are not directly related to the flight aspect and require not only sensor boards but full companion computer. Deep sensor fusion (which require more powerful CPU). Inferring/classifying the land objects types during low pass flights or on the approach. It would be great if INAV would expose/allow such integration. I was able to connect RPI nano board to Pixhawk and expose FC to commands from RPI over Mavlink.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "digitalentity",
            "datetime": "Jan 29, 2020",
            "body": " what commands are you talking about specifically?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dimon777",
            "datetime": "Jan 29, 2020",
            "body": "Disclaimer: I am not a professional drone expert :) yet! So for example, we want to implement an obstacle avoidance. The solution for this problem can't be generalized, because it is too complex and environmentally and situationally specific. I have a set of simple  sensors or in more complex use case set of matrix sensors outputting point cloud. This point cloud is fused with other sensors: gyro, acc, baro, cameras, perhaps with some static data like terrain heightmaps etc. to allow navigation in a complex environment and help drone become environment aware. What commands? Anything from roll/pitch/yaw/throttle corrections to help drone safely deliver that pizza to the customer avoiding trees, power lines, people, animals and what's not and make sure a parcel is not landed into the water from the overnight rainfall. This requires lot of computation and I feel ultimately not a job for a FC. If this makes sense.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "digitalentity",
            "datetime": "Jul 1, 2017",
            "body": [],
            "type": "added",
            "related_issue": null
        },
        {
            "user_name": "digitalentity",
            "datetime": "Jul 15, 2017",
            "body": [],
            "type": "pull",
            "related_issue": "#1899"
        },
        {
            "user_name": "stale",
            "datetime": "May 13, 2018",
            "body": [],
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "stale",
            "datetime": "May 27, 2018",
            "body": [],
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "digitalentity",
            "datetime": "Jan 29, 2020",
            "body": [],
            "type": "reopened this",
            "related_issue": null
        },
        {
            "user_name": "stale",
            "datetime": "Jan 29, 2020",
            "body": [],
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "digitalentity",
            "datetime": "Jan 29, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "DzikuVx",
            "datetime": "Sep 3, 2022",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/opencv/cvat/issues/747",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "4sfaloth",
            "datetime": "Oct 1, 2019",
            "body": "Hi all,this is just a feature suggestion I thought might be useful.Are there any plans on allowing users to customize the keyboard shortcuts? I feel like I it would be considerably easier to perform annotation tasks if one could adapt the shortcuts for each task",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "mistermult",
            "datetime": "Jan 28, 2020",
            "body": " I'm interested in implementing custom shortcuts. However, I'm not sure what's best.I hope I can get your ideas or preferences on this topic.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Jan 29, 2020",
            "body": " , great news! Sorry for delay with your previous PR. We definitely will integrate it in the future. Now we are busy with the new UI.I prefer the option . CVAT should have some settings per user (serialize/deserialize arbitrary JSON configuration into a DB table = (user_id, json_settings)). I don't think that it makes sense to have presets for a task. If a user has own settings they will be used otherwise default settings applied (shortcuts, options, theme, ...). What do you think?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "mistermult",
            "datetime": "Jan 30, 2020",
            "body": "  First,  mentioned task specific shortcuts. But I agree that shortcuts per user (or default vales) sound better for me.\nSaving an arbitrary JSON was my first idea. However, then migration, e.g. changing the names for shortcuts, might be little harder but still possible. So the alternative would be a table (user_id, shortcut_id, keys). If you don't have any objection, I'll go with JSON.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Jan 30, 2020",
            "body": " , for tasks we can implement in the future. It can be a cascade scheme (default settings -> user settings -> task settings). Let's implement UserSettings = (user_id, settings) table where settings string is a json string. REST API could be  with GET, PATCH, DELETE, PUT methods. JSON settings should have a special key \"shortcuts\": { \"name1\": \"shortcut1\", ... }. Thus in the future we will use the approach as well to keep other settings. , could you please give us some hints how to implement shortcuts in the new UI?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Jan 30, 2020",
            "body": "Hi, we are going to replace legacy annotation view with a React based single page application soon.\nBasic work with the new annotation view is complete. The latest version always can be found in the branch  and we merge it to develop regularly.Now the UI doesn't have any shortcuts and you would help us with it.\nHere are some ideas about client implementation:Something like:\nAction 1: [Ctrl + A]\nAction 2: [Ctrl + C]",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Feb 25, 2020",
            "body": "Hi,\nAny news here?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "celhannah",
            "datetime": "Jul 5, 2021",
            "body": "Is there any update on user customizable shortcuts?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "jnothman",
            "datetime": "Aug 12, 2021",
            "body": "It seems to me that there is sense in allowing task-specific shortcuts, for instance, to allow a shortcut that creates a rectangle with a particular label.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Meriipu",
            "datetime": "Aug 12, 2021",
            "body": "you can do ctrl+1 to at least ctrl+5 to change the default label rect (e.g for the next one)or you can do ctrl+1 to ctrl+5 while hovering a rect to change it",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Meriipu",
            "datetime": "Aug 12, 2021",
            "body": "personally I would benefit from shortcuts to  but none are configured atm",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Aug 13, 2021",
            "body": "\nJust interested, why not to use mousewheel? Actually it has the same meaning (zoom in/out with keeping cursor position at the center)",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Meriipu",
            "datetime": "Aug 13, 2021",
            "body": "the scroller on my mousewheel is broken so I realize that is a bit unique",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Meriipu",
            "datetime": "Aug 13, 2021",
            "body": "Additionally I often use a graphics tablet combined with a keyboard key bound to left-click to annotate as 4-point annotation is a bit smoother that way, and I do not have a scroll-wheel on the tablet.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "doctorcolossus",
            "datetime": "Jan 28, 2022",
            "body": "I would also like this. I usually use my laptop's trackpad, rather than a mouse. If I only needed to draw one or two bounding boxes, it would be no biggy, but when it comes to annotating hundreds or thousands of images, CVAT causes me a lot of pain. Having used AutoCAD and GIMP extensively, it's very frustrating to me that CVAT offers no keyboard controls for panning or zooming.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "timurlenk07",
            "datetime": "Mar 26, 2022",
            "body": "I would also be interested in this feature. In our use case, certain attributes of tags should be updated on a hotkey press (for instance, tick/untick a checkbox), which would help us to be more performant.What is the current situation on this feature request? Does it have a planned feature launch date yet? ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dudulasry",
            "datetime": "Jun 26, 2022",
            "body": "I'd also love to see shortcuts customization in CVAT. The current setup is not very convenient for me.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Oct 2, 2019",
            "body": [],
            "type": "changed the title",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Oct 2, 2019",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Oct 2, 2019",
            "body": [],
            "type": "added this to the",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Nov 20, 2019",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "bsekachev",
            "datetime": "Feb 27, 2020",
            "body": [],
            "type": "issue",
            "related_issue": "#1209"
        },
        {
            "user_name": "nmanovic",
            "datetime": "Nov 28, 2021",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "nmanovic",
            "datetime": "Nov 28, 2021",
            "body": [],
            "type": "removed this from the",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/label-studio/issues/1703",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "Janus-Xu",
            "datetime": "Nov 5, 2021",
            "body": "\ntimeseries labeling demo csv：\ndata with  rows no in 10000，goes fine；\n\ndata with  rows no in 20000\nbug1：\nbackground lines disappeared ，when mouse in，can still see data points：\n\nbut zoom out selection，background lines appeared；\nbug2：\nzoom out to a small selection，than scroll zooming to the end whole component crashed and page blank；\n\ndemo data here：\n\n",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Nov 5, 2021",
            "body": "Relative:\nMaybe too (last point NaN):\n",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "InCaseOf",
            "datetime": "May 18, 2022",
            "body": "Any updates on this bug?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Janus-Xu",
            "datetime": "Nov 5, 2021",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Nov 5, 2021",
            "body": [],
            "type": "added",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Nov 6, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Feb 9, 2022",
            "body": [],
            "type": "added  the",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/label-studio/issues/1549",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "dsanders11",
            "datetime": "Sep 30, 2021",
            "body": "I'd like to be able to copy/duplicate a label. For example, I have a task where the different items to label are all the same size, so I'd like to draw the rectangle once, then duplicate it and change the label on the copy, ensuring that all of the rectangles are identical sizes. CVAT has copy functionality as described.A way to copy/duplicate a layer. In CVAT it's called copy, but I think duplicate might be a better word since copy might imply you'll then paste it, rather than immediately creating another label.None.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Oct 1, 2021",
            "body": " Since LS 1.3 the selection of multiple regions and ctrl+c/ctrl+v hotkeys are available, have you tried them?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dsanders11",
            "datetime": "Oct 1, 2021",
            "body": ", looks like Ctrl+D does exactly what I wanted, thanks! Using Ctrl+C and Ctrl+V was buggy for me, sometimes it worked, sometimes it didn't, and I couldn't figure out why, but Ctrl+D always worked. It seems like Ctrl+C/Ctrl+V did nothing for me when I first switch to an image and click an existing label.I see now that it's mentioned in the docs, but not in the list of hotkeys in Label Studio itself (at least under Settings), and there doesn't appear to be any way to do it without hotkeys. It would be nice if it was part of the UI so that it was better discoverable, and could be used with only a mouse, as I think a mouse-only workflow can be easier at times.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Oct 1, 2021",
            "body": "Thank you for your points. So, if we add the duplicate button for regions, will your issue be solved?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dsanders11",
            "datetime": "Oct 1, 2021",
            "body": "I think so, yea.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dsanders11",
            "datetime": "Sep 30, 2021",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Oct 6, 2021",
            "body": [],
            "type": "added",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Oct 6, 2021",
            "body": [],
            "type": "added this to the",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Oct 7, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/label-studio/issues/1326",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "alexandrnikitin",
            "datetime": "Aug 19, 2021",
            "body": "\nNavigating time series (moving forward) is pretty hard and frustrating. I need to move my mouse over the bottom window and move it slowly. With a long time series it's unusable.\nIt looks like scroll and/or hotkeys can ease the work, e.g. arrows or <,> or h,l (vim style)\n",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dflatow",
            "datetime": "Mar 1, 2022",
            "body": "This would be very useful.   for performance with longer time series.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "alexandrnikitin",
            "datetime": "Sep 4, 2022",
            "body": "Any updates on this? It would be great to have easier navigation.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Sep 9, 2022",
            "body": " unfortunately there are no updates :-(",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "alexandrnikitin",
            "datetime": "Aug 19, 2021",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "smoreface",
            "datetime": "Sep 2, 2021",
            "body": [],
            "type": "added",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Oct 16, 2021",
            "body": [],
            "type": "added",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Oct 16, 2021",
            "body": [],
            "type": "added this to the",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Mar 7, 2022",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "dflatow",
            "datetime": "Mar 11, 2022",
            "body": [],
            "type": "issue",
            "related_issue": "#2118"
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/label-studio/issues/1680",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "kaustuk",
            "datetime": "Oct 27, 2021",
            "body": "\nConsider the following scenario,An ASR system is giving a segment and we populate it in label studio. Now the person who is doing labeling needs to listen to the region and write text in textarea with is per region. To iterate over the region he would be using  to go to the next region. Doing this still it doesn't play the audio region automatically. So we need to click on the audio pane to actually play the audio region. Which slows down the labeling process.The current process step looks something like thisIdeally, steps should be this\n",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "kaustuk",
            "datetime": "Oct 27, 2021",
            "body": "I would like to contribute to this feature. I actually explored this part. Here is the solution I would like to purposeOver here I would like to replace with the following if else",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Oct 28, 2021",
            "body": " Nice idea! I would make it optional via LSF settings. Could you add a checkbox there like \"Autoplay next region\"?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "kaustuk",
            "datetime": "Nov 11, 2021",
            "body": "Hi , thanks for the reply and sorry for the delay in reply from my side. Yeah, that makes sense to have this feature configurable and it's the user's call if they want to enable it or not.Just to be clear  is this panel, right? And here we need to add a new checkbox for \"Autoplay next region\"?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Nov 11, 2021",
            "body": " Yes, LSF Settings is what we can see on this screenshot. \"Autoplay next region\" makes sense.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "kaustuk",
            "datetime": "Nov 12, 2021",
            "body": "Hi , I have created the PR with this feature implemented. I tested it manually and it's working as expected.I haven't added any unit test case. Since I am not completely aware of the codebase and newbie in react, Can you provide some pointers around which test case I should refer to write testcase for this feature?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "kaustuk",
            "datetime": "Dec 5, 2021",
            "body": "Hi  , it's been a long time I have created PR with this feature, any approx timeline when PR would get reviewed or this feature would get added?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Dec 7, 2021",
            "body": " Sorry for this long waiting, I'll force our frontend team to merge it.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "kaustuk",
            "datetime": "Feb 12, 2022",
            "body": "Hi , sorry to bother you. Just wanted to check the status on this. Any thought by when this feature/PR would get reviewed?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Feb 14, 2022",
            "body": " Thank you for pinging, I've asked to review your PR, then we will merge it.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "kaustuk",
            "datetime": "Oct 27, 2021",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Oct 28, 2021",
            "body": [],
            "type": "added",
            "related_issue": null
        },
        {
            "user_name": "kaustuk",
            "datetime": "Nov 12, 2021",
            "body": [],
            "type": "pull",
            "related_issue": "heartexlabs/label-studio-frontend#348"
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/label-studio/issues/1215",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "miwojc",
            "datetime": "Jul 24, 2021",
            "body": "\nRotating rectangles/polygons only works by using a mouse at the moment, there are no predefined rotations like horizontal, verical\nAdd buttons/keyboard shortcuts to quickly rotate rectangle/polygon by say 45deg and then fine tune it by 1deg\nThe only alternative for now is using mouse to rotate the rectangle/polygon manually.\nNone",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "miwojc",
            "datetime": "Jul 24, 2021",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Jul 28, 2021",
            "body": [],
            "type": "added",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Oct 12, 2021",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "github-actions",
            "datetime": "Dec 1, 2021",
            "body": [],
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "github-actions",
            "datetime": "Dec 9, 2021",
            "body": [],
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Dec 9, 2021",
            "body": [],
            "type": "reopened this",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/label-studio/issues/812",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "NickShargan",
            "datetime": "Apr 15, 2021",
            "body": "\nAt the moment sliding window for signal can be moved only by mouse. Considering it is quite frequent action it feels unproductive during labeling.\nIt would be great to have hotkeys for sliding to right and left. It may save a lot of time.\nDon't see good alternatives.\n",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "smoreface",
            "datetime": "Nov 11, 2021",
            "body": "Check out these hotkeys:  and let me know if they work for you in the latest version of Label Studio!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "reesehopkins",
            "datetime": "Nov 30, 2021",
            "body": "Unfortunately, these shortcuts do not work in the latest Docker build (v1.4). Also, you might consider alternative hotkeys for decreasing/increasing the region size --  is the keyboard shortcut to Go Back in Chrome.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "hlomzik",
            "datetime": "Dec 13, 2021",
            "body": "Hi,  ! We really don't have such hotkeys, but we are working on a good new shortcut system, and this will be there. I'll let you know when this happens!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "NickShargan",
            "datetime": "Apr 15, 2021",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Apr 15, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "niklub",
            "datetime": "Apr 20, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "niklub",
            "datetime": "Apr 20, 2021",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Oct 6, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Oct 6, 2021",
            "body": [],
            "type": "added this to the",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Oct 6, 2021",
            "body": [],
            "type": "moved this from",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Dec 14, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/label-studio/issues/530",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "MNMaqsood",
            "datetime": "Jan 5, 2021",
            "body": "\nA clear and concise description of what the problem is. Ex. I'm always frustrated when [...]\nA clear and concise description of what you want to happen.\nA clear and concise description of any alternative solutions or features you've considered.\nAdd any other context or screenshots about the feature request here.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "MNMaqsood",
            "datetime": "Jan 5, 2021",
            "body": "Hey is it possible for you add an option to view the text of relevant labels after the addition of relations in the Relations panels? It only shows the \"A text\" now for every label of the relation. You can hover your mouse over that relation but it will be nice to also the text.\nP.S I have also requested it on Slack",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Jan 15, 2021",
            "body": " This is not simple to build a good UX for this feature, because texts can be very long. Only tooltips are the fast solution.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "MNMaqsood",
            "datetime": "Jan 5, 2021",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "niklub",
            "datetime": "Jan 13, 2021",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "niklub",
            "datetime": "Mar 29, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Oct 8, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/label-studio/issues/814",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "ankurhanda",
            "datetime": "Apr 15, 2021",
            "body": "\nBeing able to annotate rewards is missing in this label studio. This reward annotation is useful for training RL agents.\nI'd like to have a way to create reward sketches like done here  on video data.\nI have not seen anything close to this in the repo.\nThese reward sketches are useful to have to train RL agents. This is the closest you can get to have a supervised signal for robotics.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Apr 15, 2021",
            "body": " What kind of reward sketches do you want to have?\nLS has ratings, checkboxes and text areas, so you can have  for video.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ankurhanda",
            "datetime": "Apr 15, 2021",
            "body": " I'd like to draw a continuous function with X-axis being the frame number and Y-axis being the reward. To clarify what that means check the reward sketching section in  where you slide (and click) your mouse along and it draws the curves for you.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Apr 15, 2021",
            "body": "Thanks! Now I've got it. It's a very cool feature!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ankurhanda",
            "datetime": "Apr 15, 2021",
            "body": "Do you think it is worth adding that in label-studio?I implemented it in python already (using matplotlib) but it's fairly simple and often requires more clicking.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ankurhanda",
            "datetime": "Apr 15, 2021",
            "body": "The code looks like this in case you're interested.`\nimport math\nimport numpy as npimport matplotlib.pyplot as plt\nfrom matplotlib.backend_bases import MouseEventclass DraggablePlotExample(object):\nu\"\"\" An example of plot with draggable markers \"\"\"if  == \"\":\nplot = DraggablePlotExample(hdf5File='images.hdf5')\n`",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ankurhanda",
            "datetime": "Apr 15, 2021",
            "body": "some of this is inspired from ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Apr 15, 2021",
            "body": "Thank you very much! But we need to re-implement it in JS React for LS.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ankurhanda",
            "datetime": "Apr 15, 2021",
            "body": "Yes, sure. Let me know if you ever get to it. I'm happy to do testing for you. Thanks a lot for listening.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Jul 19, 2022",
            "body": " - we introduced Number tag, it can help here.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ankurhanda",
            "datetime": "Apr 15, 2021",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Apr 15, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Oct 6, 2021",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "makseq",
            "datetime": "Oct 8, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/labelImg/issues/915",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "Joelvgent",
            "datetime": "Jul 13, 2022",
            "body": "When adjusting rectangles/boxes on objectss, it is quite time-inefficient to manually drag corners to the correct position. For example when 1/4 sides of the rectangle needs to be adjusted, it is required to drag the corner and possibly move the other side unintentionally, adding time to readjust sides that were not supposed to be moving in the first place. A possible solution that increases efficiency greatly would be the option to add any sort of WASD or arrow setup to move each side of a box individually by one tick. Adjusting boxes could then be done very accurately and swiftly, perhaps even a changing tick size feature depending on how far a photo is zoomed in on. Secondly, The option to switch ''target'' or jump from one box to another with the keyboard would eliminate the need for sketchy mouse adjustments. Combined with my previous Idea, it would lead to a huge jump in accuracy and speed when scanning a large number of photos.Imagine it like this: There is a photo with 8 objects, and some of them need readjustments. By using TAB for example it goes to the first box it can find, followed by pressing any WASD structure on the computer to adjust the sides in less than a few seconds. Press TAB to select the next box and repeat. The only use of the mouse would then be to create an entirely new box on an undentified item.I have a lot of experience readjusting object rectangles with the mouse, and am confident that adjustment efficiency could greatly be increased by implementing these features.Thank you for reading!",
            "type": "commented",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/labelImg/issues/862",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "wyfffffei",
            "datetime": "Mar 29, 2022",
            "body": "I suggest setting the shortcut key for adding the matrix（w） to a key near enter, which may be more convenient, otherwise it is tiring to press w and then press enter with one hand.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Regenhardt",
            "datetime": "May 18, 2022",
            "body": "Why press enter?\nUsually it's (w) -> draw box with mouse -> (d) to get to next image -> (w) again",
            "type": "commented",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/labelImg/issues/885",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "vzeman",
            "datetime": "May 20, 2022",
            "body": "Python 3.10Traceback:Error occured, when I wanted to create rectangle and moved mouse over the image - application always crash",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "vzeman",
            "datetime": "May 20, 2022",
            "body": "Update: with python 3.8 is application not crashing",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ropinheiro",
            "datetime": "May 26, 2022",
            "body": "I have this error with Python 3.10.4",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "AjibolaPy",
            "datetime": "Jun 3, 2022",
            "body": "i also have this error python 3.10",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nine",
            "datetime": "Jun 9, 2022",
            "body": "Can not reproduce this bug on Debian GNU/Linux with following software versions:",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dvaupel",
            "datetime": "Jul 4, 2022",
            "body": "Same here. Ubuntu 22.04, installed with pip3.The manual installation from the start page works.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Logiase",
            "datetime": "Jul 20, 2022",
            "body": "same error on Windows, installed with pip",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Tylermarques",
            "datetime": "Jul 22, 2022",
            "body": "Same issue with me. Solution was to use python3.8 for me.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dhanashreemhatre",
            "datetime": "Aug 4, 2022",
            "body": "i am having same problem\npls someone help me to resolve it .\nQuestion",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "windowshopr",
            "datetime": "Aug 21, 2022",
            "body": "same. Windows 10, python 3.10.5",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "windowshopr",
            "datetime": "Sep 5, 2022",
            "body": "",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": null,
            "datetime": [],
            "body": [],
            "type": "",
            "related_issue": "#886"
        },
        {
            "user_name": "matobodo",
            "datetime": "Jul 11, 2022",
            "body": [],
            "type": "issue",
            "related_issue": "#912"
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/labelImg/issues/699",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "bonorico",
            "datetime": "Feb 3, 2021",
            "body": "[Feature request]: After closing rectangular box, a dialog with available classes pops up in the middle of the screen. It is extremely tiring for the eye to repeatedly wander here and there to get back to this dialog box to click the class label. It would be much more efficient to have this dialog box popping up exactly next to mouse pointer where the object is being annotated.A typical set-up is to have one hand on mouse and other one on W button. Additional to that, if classes dialog box could open there where image is being annotated, it would dramatically speed up things I believe.\nI tried to figure out how I could adapt this in present source code using qt, but I am not expert here... any suggestion ? Or would it be difficult for the developer to add this feat ?Thank you very much",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bonorico",
            "datetime": "Feb 9, 2021",
            "body": "SOLUTION: keyboard buttons can be customized by editing the source code (labelImg.py). For instance, in my case I change button \"w\" to \"+\", which is next to Enter key and allows me a much quicker combo open-window-draw-bow-confirm-class, not having to move my eyes away from annotation target too often. Also, holding mouse with left hand you can quickly switch to ctrl-+ to zoom in. In order to edit source code you must install by source:python3 -m venv \nsource /bin/activate\ncd \ngit clone  \npip install pyqt5==5.12.1 lxml\ncd labelImg\nmake qt5py3\npython3 labelImgNow custom-edit the key-strokes in labelImg.py and git-commit your changes.",
            "type": "commented",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/labelImg/issues/610",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "chrisrapson",
            "datetime": "Jun 25, 2020",
            "body": "First of all, thanks for developing an excellent tool and making it available! Our team has built our workflow around it and annotated about 1000 images already. While we were doing that, we came up with a few ideas for improvements. I have actually implemented them already, and could provide a PR for some or all of them, as you prefer.One more thing: I think, but am not completely sure, that you should subtract 1 when loading VOC bounding box coordinates. (And +1 when saving them.) That is because VOC was originally developed in matlab, and uses 1-based indices. We are using YOLO's annotation format, so this didn't affect us and I haven't modified anything.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "radek1991",
            "datetime": "Sep 7, 2020",
            "body": "Hey  at what price point supported and improved version of this tool is still interesting for you :) ?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "chrisrapson",
            "datetime": "Sep 8, 2020",
            "body": " I don't understand. The license on this repository is MIT, so it is free in all respects. Having access to the code allowed me to make modifications (I would say \"improvements\" but that's only subjective until I get input from others). I'm offering those modifications as a pull request - also free.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "chrisrapson",
            "datetime": "Oct 1, 2020",
            "body": " are you interested in a pull request for the other suggestions?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "tzutalin",
            "datetime": "Oct 2, 2020",
            "body": "Sure. I am open to any pull request if it can be beneficial to users",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "wch1446",
            "datetime": "Oct 23, 2020",
            "body": "allow panning by clicking and dragging  这个怎么实现呢",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "chrisrapson",
            "datetime": "Oct 26, 2020",
            "body": "Hi  I'm sorry I didn't understand your message. Is that the mandarin translation for \"allow panning by clicking and dragging\"? Are you asking for it to be included in a menu or readme somewhere?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "wch1446",
            "datetime": "Oct 27, 2020",
            "body": "你的那个第三个要求是怎么实现呢？    我是中国人不好意思 英文不好 也不是程序员  只是现在有个项目用到了这个工具 发现放大图片后不能去拖动图片  去标注的时候效率很低  不知道你实现的是不是放大图片后能随意去拖动图片？",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "chrisrapson",
            "datetime": "Oct 28, 2020",
            "body": " assuming the automatic translations are working correctly, I understand you're asking about how I implemented the panning by click and drag? You can see the changes in this commit:Basically, while the mouse button is held down, it uses the motion of the cursor to change the offset position of the frame. It works for me, and since tzutalin accepted the pull request, I assume it works for them. If you can provide any more details on why/when it's not working for you, I'd be happy to look into it.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "wch1446",
            "datetime": "Oct 29, 2020",
            "body": "I got it wrong. Your translation is to pull out the box to translate. What I want is that the marked picture can be translated after zooming in",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "chrisrapson",
            "datetime": "Aug 24, 2020",
            "body": [],
            "type": "pull",
            "related_issue": "#636"
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/labelImg/issues/426",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "keides2",
            "datetime": "Jan 5, 2019",
            "body": "I use xrdp on Ubuntu 16.04 and I remotely connect from Windows 7 remote desktop.\nI can key in the terminal on Ubuntu, but I can not key in labelImg. Mouse input is available.",
            "type": "commented",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/labelImg/issues/335",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "acscas",
            "datetime": "Jul 23, 2018",
            "body": "This is not an issue per-se, but suggests added functionality that is basic and would improve the App. App works great (Py 2.7, CentOS) -- thanks so much for contributing!I'm wondering if it's possible to add a panning ability for labelling large images? It's currently difficult to do so since you have to use the scroll wheel at bottom.I don't have experience in PyQt, but if someone does could they suggest a way to enable this? Or would it require a large time investment?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "vdalv",
            "datetime": "Jul 26, 2018",
            "body": "Can you clarify the experience you're looking for?For example, if you move the mouse off to the right, the focus should shift towards the right?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "acscas",
            "datetime": "Jul 26, 2018",
            "body": "Sure thing -- When I zoom into an image it is no longer completely displayed in the window. Is there a way to pan to the left or right? For example, in some GUIs you can shift+click and then when you move the mouse the image moves instead. In this way, if it's hidden out of view you can slide it back into view without going to the horizontal scroll bar at the bottom of the window.When I click to make a new bounding box and then drag off screen (after first zooming in first so the image flows beyond the window), the window does not slide to show the endiing position of the bounding box (for example). This is shown in the attached image.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "vdalv",
            "datetime": "Jul 28, 2018",
            "body": "Thanks for the clarification. These are definitely worthwhile features, but unfortunately tzutalin and I are a bit strapped for time, so not sure when we could have this implemented.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "vdalv",
            "datetime": "Jul 26, 2018",
            "body": [],
            "type": "added  the",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/labelImg/issues/194",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "mrgloom",
            "datetime": "Nov 7, 2017",
            "body": "Is it possible to move through image via dragging by mouse?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "tzutalin",
            "datetime": "Nov 17, 2017",
            "body": "Can you elaborate more? Now, it can use the mouse to drag each bounding box.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "mrgloom",
            "datetime": "Nov 17, 2017",
            "body": "I talking not about dragging bboxes, but about behaviour of 'dragging image view' like we have on google maps, etc.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "luoyetx",
            "datetime": "Dec 7, 2017",
            "body": "I think this feature is helpful to label a big image.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "cooli7wa",
            "datetime": "Jul 30, 2018",
            "body": "\nI add dragging in , you can try.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "mrgloom",
            "datetime": "Nov 17, 2017",
            "body": [],
            "type": "issue",
            "related_issue": "wkentaro/labelme#37"
        },
        {
            "user_name": "vdalv",
            "datetime": "May 24, 2018",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "rjdbcm",
            "datetime": "Apr 25, 2019",
            "body": [],
            "type": "",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/labelImg/issues/546",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "vik748",
            "datetime": "Jan 21, 2020",
            "body": "Hi,\nWe have been working with labeling on very high resolution photo mosaics. This package is great at being able to handle the resolutions.  The only annoying thing we found is that when we click the zoom out button in the toolbar, the image jumps around to a random new location.  It would be nice to get more consistent behavior with high res images.Thanks for the great package,\nVik",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "teusbenschop",
            "datetime": "Jun 24, 2020",
            "body": "I am seeing the same behaviour when zooming in a lot to label very small objects. It will be similar to high resolution images in this issue. When zooming through the mouse and keyboard, the Control key is to be kept down for zooming. But at times the program loses track of the state of the Control key. Instead of zooming through the mouse, it scrolls. That causes undefined jumps in the experience of our labeller.",
            "type": "commented",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/labelImg/issues/499",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "DamonDBT",
            "datetime": "Sep 4, 2019",
            "body": "\nNow when you are making a box, click the left button, hold down the mouse, and release the mouse to form a box.\nBut if you do a lot of label, it is very painful.\nClick the left button, release the left button, move the mouse, the box displays in real time, click the left button again to confirm the box.\nAvoid moving the mouse with the left button for a long time, reducing labor intensity.\nCan the software default to a rectangular box instead of a square box? Save the switch operation, thank you.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "jyxjjj",
            "datetime": "Oct 30, 2019",
            "body": "The Author is form Canada.\nEnglish plz.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "DamonDBT",
            "datetime": "Oct 31, 2019",
            "body": [],
            "type": "changed the title",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/labelImg/issues/243",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "eypros",
            "datetime": "Feb 23, 2018",
            "body": "I am using labelImg to annotate object for object annotation task. I found it quite useful but I noticed that when an annotation is modified and I switch to another image the annotation is lost. This is quite strange for a program feature.The more intuitive approach would be to ask if changes should be saved and then proceed to opening the new image. Another alternative would be to automatically save changes if file already exist (annotation file is being edited and not created from scratch for example).",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "vdalv",
            "datetime": "May 17, 2018",
            "body": "I'm not experiencing this w/ the latest code, so I believe this issue has since been dealt w/. Please pull the latest code or build.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "eypros",
            "datetime": "May 24, 2018",
            "body": "I have now a better understanding of the program. So, on version 1.6 the problem is still present but in a specific situation:\nIf I move between images using the / or their keyboard shortcut the warning exists (as was expected) BUT if I choose to pick an image by mouse it does not.\nSo, please take a look into that also.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "vdalv",
            "datetime": "May 24, 2018",
            "body": "Interesting, thanks for the update.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "vdalv",
            "datetime": "May 23, 2018",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        },
        {
            "user_name": "vdalv",
            "datetime": "May 24, 2018",
            "body": [],
            "type": "reopened this",
            "related_issue": null
        },
        {
            "user_name": "vdalv",
            "datetime": "May 24, 2018",
            "body": [],
            "type": "added  the",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/labelImg/issues/186",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "andrew-veresov",
            "datetime": "Oct 29, 2017",
            "body": "Please add an ability to use the keyboard to move bounding box borders.\nLet each border has a key combination assigned to it. For example for the left border, ctrl+shift+w for the top, ctrl+shift+x for the bottom border and ctrl+shift+d for the right one.\nBy pressing key combination and left/right or top/bottom arrows user can move the border in the left/right or top/bottom direction.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "tzutalin",
            "datetime": "Nov 6, 2017",
            "body": "Hi  ,\nSo far, it supports using arrow keyboard to move the selected bounding box. Does it not work in your environment?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "andrew-veresov",
            "datetime": "Nov 6, 2017",
            "body": "Hi  !\nYes it works. But it will be really great if LabelImg get an ability to resize a box via keyboard. May be an ability to simply increase/decrease height or width of a rectangle using a keyboard.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "vdalv",
            "datetime": "May 27, 2018",
            "body": " \nI'm thinking that WASD would  the bounding box size in the up/left/down/right direction, respectively... What should be the keyboard input for  the box size? SHIFT + WASD?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lorenzob",
            "datetime": "May 27, 2018",
            "body": "My idea was this:I think directly using WSAD is confusing. Usually W goes in one direction, S does the opposite. Here S moves a different element. If I moved a border too much I cannot simply \"go back\" as I'm used to do with the arrows keys.\nSHIFT+WSAD also complicates things because you probably have one hand on the mouse and it is not so easy to use SHIFT+WSAD with one hand only. Also is not very natural to press SHIFT+D to go left.Selecting the element with the mouse pointer takes a little time but I'm already using the mouse, probably I'm still very close to the box and by selecting one corner I can move two borders.In general, I think that arrow keys should also act like WSAD for left-handed people.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "andrew-veresov",
            "datetime": "Jun 3, 2018",
            "body": "I think it's better to focus on moving edges not the corners. Usually when the need to shift an edge  appears you'are looking at the middle of an edge, not at the corner. This is cause most of the real life objects are not rectangular.\nSo, I think it will be easy if WSAD will move a corresponding edge. Yep it will affect two corners at a time. But it's exactly what I needed most of the time. In this case Shift+WSAD might move an edge in the opposite direction. And the mouse still could be used to select a rectangle.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "tzutalin",
            "datetime": "Oct 30, 2017",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "vdalv",
            "datetime": "May 27, 2018",
            "body": [],
            "type": "issue",
            "related_issue": "#171"
        },
        {
            "user_name": "rjdbcm",
            "datetime": "Apr 25, 2019",
            "body": [],
            "type": "",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/labelImg/issues/56",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "alexdominguez09",
            "datetime": "Feb 20, 2017",
            "body": "Hi,\nI am using this tools to distribute it to students so they can annotate images. We have been trying it for a while, in UBUNTU 16.04 machines and it is a very simple and straight forward tool. Perfect for the job.However, our students claim that they need too many mouse clicks per image, and after evaluating the user interface and usability, we have come to the conclusion that the label image tool would need an improvement in the usability.At the moment, a whole annotation requires:Next Image button (1 click) -> Create Box button (1 click)->  actual box creation (2 clicks) -> Select label dialogue (2 fast clicks) -> Save button (1 click) -> Enter (1 touch key) ->Next Image ... -> ...That is 7 clicks plus 1 enter key.Our request (as we dont have the knowledge or resources to accomplish it) would be to reduce it to 2 clicks.That would be, once the image to work with is on the screen:That way, we reduce the work form 8 interactions to 2. Obviously, that would be implemented with a mode that user could select (turbo mode), so the user can always go back to the normal mode, to change the label, location..or any other setting.Well, that is our result of a studding after using it for a while.Thanks for the good work.Alex",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "alexdominguez09",
            "datetime": "Feb 20, 2017",
            "body": "I forgot to comment, that our proposition would be such, as it is faster to annotate just one label per operator, than going to several labels per image. Eg. One operator labels only dog, other operator label cats, other does cars, ..and so on.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "tzutalin",
            "datetime": "Feb 21, 2017",
            "body": "Hi  ,\nThanks for your suggestion. I will take your suggestion into account. If adding a turbo mode, it will be better. I even thought I should create a tool to help people label automatically for the first time. I will try to think about it and do it when I have free time.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "zuphilip",
            "datetime": "Feb 21, 2017",
            "body": "Usually, it can also be that there are more object of the same label you have to annotate. Thus, I am not sure how often we can automatically continue after the first box is entered. Moreover, it might be that I want to edit the box a little after the first sketch, but then with your turbo mode I would already be on the next image.I like the option that one does not have to choose a label, if there is a default label which is used all over. This would be similar to  .I envision more, that creating a new rectangle and the next page will be entered with the keyboard shortcut. Thus my left hand is on the keyboard pressing , ,  and my right hand entering the rectangles with the mouse. The annotations are IMO automatically saved when I click on \"next image\".",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "cooli7wa",
            "datetime": "Jul 30, 2018",
            "body": "I also think two click is nice, one click one corner.But I think dialogue box is necessary, because:So I modify this in , you can try it.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "tzutalin",
            "datetime": "May 18, 2017",
            "body": [],
            "type": "added  the",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/microsoft/malmo/issues/590",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "Brigadirk",
            "datetime": "Aug 18, 2017",
            "body": "When I start up the Minecraft server, I'm able to move and adjust the screen as I please.However, after starting a mission, any attempt to move the Minecraft window will send it spiralling out of control across the screen, often sliding out of vision, necessitating a restart of the server.Additionally, adding a videoproducer to the XML centers the Minecraft window. Combined with the screen playing ice hockey with the Minecraft window, this can make it very annoying to run tests on a single laptop screen.According to David Bignell, this only happens on Mac, hence the title.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "DaveyBiggers",
            "datetime": "Aug 18, 2017",
            "body": "Yes, after some digging it seems it's due to to the following code in EntityRenderer:This is also the reason why the OSX Minecraft window is so reluctant to relinquish the mouse capture (Malmo contains code to ensure Minecraft doesn't keep hold of the mouse, which works fine on Windows and Linux). Any time the window gains focus and the mouse is outside of the window, the mouse is automatically grabbed, and moved to within the window... Unfortunately, if you are dragging the window, the window gets moved with the mouse (leaving the mouse outside the window client area again, thus re-triggering the move, shifting the window again, etc.etc.)",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "DaveyBiggers",
            "datetime": "Aug 21, 2017",
            "body": "As for the automatic centring of the window after resize...\nIn theory this should be an easy fix - just grab the x/y coords of the window before resizing, and reset them afterwards:Unfortunately there are a few problems with this:\nFirstly, lwjgl (which Minecraft uses) has mismatched position getters/setters - the getters seem to take into account the window furniture (title bar etc), whereas the setters don't - so callingwill result in the window gradually creeping up and to the left.Secondly, this is lwjgl's helpful OSX implementation of the  method (which is called by ):So calling  on OSX doesn't actually move the window at all... though it does cache the values for x and y, which will then be used the next time the window is recreated (eg when the dimensions change), so, somewhat counter-intuitively, this almost works:Why is the  necessary at all, in this case?\nBecause Display's cached x and y values (which are used when recreating the window) have nothing to do with the window's  position. They are not updated if the window is moved by the user. (This is what causes the centring in the first place - by default they are set to -1, which is a magic value used to indicate that the window should be centred, and moving the window manually doesn't change them, so each resize re-centres the window.)Fortunately  and  get the  window positions (hence the mismatch between getters and setters - the  and  methods which return the cached values are private), and then these values can be written back to the cached values using , so that the window will appear in  the right place after recreation.Ugh.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "DaveyBiggers",
            "datetime": "Aug 22, 2017",
            "body": "To make matters worse, according to the lwjgl documentation for , \"The window is clamped to remain entirely on the screen.\"\nAs far as I can tell, this is just a lie. There doesn't appear to be any code anywhere that actually implements this. So the result of creeping up and to the left, eventually, is that the Minecraft window disappears off screen entirely.Admittedly, it takes a while for this to happen, and under normal working conditions the Minecraft window won't be changing size often, so it shouldn't present a problem in most cases.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "DaveyBiggers",
            "datetime": "Sep 28, 2017",
            "body": "This has been \"fixed\" (allowing for the above ugliness) in 0.31.0.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "DaveyBiggers",
            "datetime": "Oct 13, 2017",
            "body": "Am reopening this because the fix (making sure  is false for the check in ) breaks the continuous attack command.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Brigadirk",
            "datetime": "Aug 18, 2017",
            "body": [],
            "type": "changed the title",
            "related_issue": null
        },
        {
            "user_name": "DaveyBiggers",
            "datetime": "Sep 28, 2017",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        },
        {
            "user_name": "DaveyBiggers",
            "datetime": "Oct 13, 2017",
            "body": [],
            "type": "reopened this",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/heartexlabs/labelImg/issues/458",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "yxchng",
            "datetime": "Apr 1, 2019",
            "body": "Using latest master code",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "meatball-guy",
            "datetime": "Apr 4, 2019",
            "body": "I am also facing this issue. It is quite frustrating to use.\nIt happens randomly. Sometimes it is ok and sometimes it just does it\nEDIT 2: I also realised that the box also moves after moving to the next page, also by 1 pixel.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "yxchng",
            "datetime": "Apr 4, 2019",
            "body": " Any suggestion for better tools?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "duming",
            "datetime": "Apr 22, 2019",
            "body": "I also got this problem.\nWhen you want to label some small objects, the box will shift down or shift right by one pixel.\nSteps to reproduce:And I traced the bug a little bit.\nI think it may caused by different drawing functions labelimg using while/after creating the box.\nBefore you release your mouse left button, the shape is not add to canvas.shapes list yet. So canvas class draws the box using \nHowever after the the mouse is released, the shape is inserted to canvas.shapes. And canvas will call each shape's own paint() function to draw the box. In shape.paint(), it using QpainterPath API to draw the the vertexes and lines separately. These two functions may have different behaviors.I hope somebody familiar with QT can look into this issue.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "sunnyzhong812",
            "datetime": "Sep 25, 2020",
            "body": " ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "sunnyzhong812",
            "datetime": "Sep 30, 2020",
            "body": "I found that this happens when the viewing ratio ends at 1, 2, 6 and 7. But I don't know how can solve this problem.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "sunnyzhong812",
            "datetime": "Sep 30, 2020",
            "body": "I think it's ok.",
            "type": "commented",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/microsoft/malmo/issues/577",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "DaveyBiggers",
            "datetime": "Jul 13, 2017",
            "body": "This is a regression as of version 0.30.0 - Minecraft sometimes steals focus (mouse and keyboard). This seems to happen at the end of each mission.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "DaveyBiggers",
            "datetime": "Jul 20, 2017",
            "body": "Can't seem to reproduce this now, but have definitely seen it recently.",
            "type": "commented",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/photoprism/photoprism/issues/2401",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "Dulanic",
            "datetime": "Jun 4, 2022",
            "body": "**Is your feature request related to a problem? Please describe. **As a user, I would like to be able to easily remove faces without having to move my mouse all over. As part of this, I would like to be able to keep my mouse in place and just keep clicking to remove faces.As x is pressed to remove faces, that face should roll to the bottom of the webui and move the next face to the top. The other option I've thought of just now and maybe is a better idea, allow bulk select on the people tab?  A select all button could be a option?Other option I thought of too, maybe set keys (1,2,3,4) toggle the the remove face on the people tab for each face (1 for 1st photo, 2 for 2nd photo and so on?) Though that would likely be seperate coverage under enhanced keyboard uses. So Ill focus on 1st thing i said.Moving my mosue from face to fce over and over. Not a huge problem, but when it is say a group photo, it can have 10+ faces to click x on.See how the X'ed faces stay at the top.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "pabsi",
            "datetime": "Jun 9, 2022",
            "body": "In the meantime, I'd appreciate a query on MySQL that could just remove all faces from a photo (or the equivalent of clicking \"X\" on each one of them as discarded faces).\n",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "centralhardware",
            "datetime": "Jul 5, 2022",
            "body": "it would be grate, if i can batch select photos and have button for remove all faces from all image",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Dulanic",
            "datetime": "Jun 4, 2022",
            "body": [],
            "type": "added  the",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/microsoft/malmo/issues/869",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "DarthMalloc",
            "datetime": "Feb 29, 2020",
            "body": "I have built Malmo on Linux Mint 19.3 with OpenJDK8, and when I attempt to run Minecraft with the Malmo mod using./launchClient.sh -port 10234 -envI get the following output, as shown in the screenshot below:As the picture shows, the second last line is[15:13:59] [Realms Notification Availability checker /INFO]: Could not authorize you against Realms server: Invalid session idI think this is preventing my from running missions, because when I try to run tutorial_1.py, nothing happens. There is no error message, but the terminal gets stuck on the commandpython3.7 tutorial_1.py.\nI would greatly appreciate help in resolving this issue.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "DaveyBiggers",
            "datetime": "Mar 2, 2020",
            "body": "I believe the Realms server error message is a red-herring - if memory serves, this is always displayed, and is nothing to worry about. From the log, it looks as though Minecraft is running and is ready for use (the line \"CLIENT enter state: DORMANT\" means we're ready to receive a mission).I suspect there are two problems here:a) Malmo's default communication port is 10000 - if that's undesirable for some reason, you can override it - as you are doing, by passing the \"-port 10234\"cmdline argument. But the client code (eg tutorial_1.py) needs to know what to connect to. The tutorials all assume the default port, so you either need to run Minecraft on the default port, or change your client code to pass in 10234. For details of how to do that, see (for example)  - look for the ClientPool stuff around line 70.b) The other problem might be your use of the -env flag - this runs Malmo in the \"MalmoEnv\" mode, where it can present as a gym environment, but the tutorials (and all the python samples) were written before this feature became available, and communicate with Minecraft using a non-gym protocol (which is much more flexible but potentially less convenient, depending on your needs). I suspect none of the samples will work if the -env flag is specified.Let us know if this helps - if not, we'll do some more digging.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "DarthMalloc",
            "datetime": "Mar 3, 2020",
            "body": "Thank you very much for getting back to me. I tried the approach that you suggested, but I am still seeing the same problem. Here is the entire output that I am seeing when I run the command./launchClient.sh -port 10000This mapping 'snapshot_20161220' was designed for MC 1.11! Use at your own peril.\n#################################################\nForgeGradle 2.2-SNAPSHOT-3966cea\n\n#################################################\nPowered by MCP unknown\n\nby: Searge, ProfMobius, Fesh0r,\nR4wk, ZeuX, IngisKahn, bspkrs\n#################################################\n:deobfCompileDummyTask\n:deobfProvidedDummyTask\n:getVersionJson\n:extractUserdev UP-TO-DATE\n:extractDependencyATs SKIPPED\n:extractMcpData SKIPPED\n:extractMcpMappings SKIPPED\n:genSrgs SKIPPED\n:downloadClient SKIPPED\n:downloadServer SKIPPED\n:splitServerJar SKIPPED\n:mergeJars SKIPPED\n:deobfMcSRG SKIPPED\n:decompileMc SKIPPED\n:fixMcSources SKIPPED\n:applySourcePatches\n:remapMcSources SKIPPED\n:recompileMc SKIPPED\n:extractNatives SKIPPED\n:getAssetIndex UP-TO-DATE\n:getAssets\n:makeStart SKIPPED\n:setupDecompWorkspaceBUILD SUCCESSFULTotal time: 13.407 secsThis build could be faster, please consider using the Gradle Daemon: \nThis mapping 'snapshot_20161220' was designed for MC 1.11! Use at your own peril.\n#################################################\nForgeGradle 2.2-SNAPSHOT-3966cea\n\n#################################################\nPowered by MCP unknown\n\nby: Searge, ProfMobius, Fesh0r,\nR4wk, ZeuX, IngisKahn, bspkrs\n#################################################\n:deobfCompileDummyTask\n:deobfProvidedDummyTask\n:sourceApiJava UP-TO-DATE\n:compileApiJava UP-TO-DATE\n:processApiResources UP-TO-DATE\n:apiClasses UP-TO-DATE\n:copyModToClient\n:copyModToServer\n:deleteSchemas\n:copySchemas\n:jaxb UP-TO-DATE\n:sourceMainJava UP-TO-DATE\n:compileJava\nwarning: [options] bootstrap class path not set in conjunction with -source 1.6\nNote: Some input files use or override a deprecated API.\nNote: Recompile with -Xlint:deprecation for details.\nNote: Some input files use unchecked or unsafe operations.\nNote: Recompile with -Xlint:unchecked for details.\n1 warning\n:processResources UP-TO-DATE\n:classes\n:jar UP-TO-DATE\n:sourceTestJava UP-TO-DATE\n:compileTestJava UP-TO-DATE\n:processTestResources UP-TO-DATE\n:testClasses UP-TO-DATE\n:test UP-TO-DATE\n:extractMcpData SKIPPED\n:extractMcpMappings SKIPPED\n:getVersionJson\n:extractUserdev UP-TO-DATE\n:genSrgs SKIPPED\n:reobfJar\n:assemble\n:check UP-TO-DATE\n:buildBUILD SUCCESSFULTotal time: 7.514 secsThis build could be faster, please consider using the Gradle Daemon: \nThis mapping 'snapshot_20161220' was designed for MC 1.11! Use at your own peril.\n#################################################\nForgeGradle 2.2-SNAPSHOT-3966cea\n\n#################################################\nPowered by MCP unknown\n\nby: Searge, ProfMobius, Fesh0r,\nR4wk, ZeuX, IngisKahn, bspkrs\n#################################################\n:deobfCompileDummyTask\n:deobfProvidedDummyTask\n:sourceApiJava UP-TO-DATE\n:compileApiJava UP-TO-DATE\n:processApiResources UP-TO-DATE\n:apiClasses UP-TO-DATE\n:copyModToClient\n:copyModToServer\n:deleteSchemas\n:copySchemas\n:jaxb UP-TO-DATE\n:sourceMainJava UP-TO-DATE\n:compileJava\nwarning: [options] bootstrap class path not set in conjunction with -source 1.6\nNote: Some input files use or override a deprecated API.\nNote: Recompile with -Xlint:deprecation for details.\nNote: Some input files use unchecked or unsafe operations.\nNote: Recompile with -Xlint:unchecked for details.\n1 warning\n:processResources UP-TO-DATE\n:classes\n:jar\n:getVersionJson\n:extractNatives SKIPPED\n:extractUserdev UP-TO-DATE\n:getAssetIndex UP-TO-DATE\n:getAssets\nCurrent status: 1048/1196   87%\n:makeStart SKIPPED\n:runClient\n[20:17:53] [main/INFO] [GradleStart]: Extra: []\n[20:17:53] [main/INFO] [GradleStart]: Found and added coremod: com.microsoft.Malmo.OverclockingPlugin\n[20:17:53] [main/INFO] [GradleStart]: Running with arguments: [--userProperties, {}, --assetsDir, /home/justin/.gradle/caches/minecraft/assets, --assetIndex, 1.11, --accessToken{REDACTED}, --version, 1.11.2, --tweakClass, net.minecraftforge.fml.common.launcher.FMLTweaker, --tweakClass, net.minecraftforge.gradle.tweakers.CoremodTweaker]\n[20:17:53] [main/INFO] [LaunchWrapper]: Loading tweak class name net.minecraftforge.fml.common.launcher.FMLTweaker\n[20:17:53] [main/INFO] [LaunchWrapper]: Using primary tweak class name net.minecraftforge.fml.common.launcher.FMLTweaker\n[20:17:53] [main/INFO] [LaunchWrapper]: Loading tweak class name net.minecraftforge.gradle.tweakers.CoremodTweaker\n[20:17:53] [main/INFO] [LaunchWrapper]: Calling tweak class net.minecraftforge.fml.common.launcher.FMLTweaker\n[20:17:53] [main/INFO] [FML]: Forge Mod Loader version 13.20.0.2228 for Minecraft 1.11.2 loading\n[20:17:53] [main/INFO] [FML]: Java is Java HotSpot(TM) 64-Bit Server VM, version 1.8.0_221, running on Linux:amd64:4.15.0-76-generic, installed at /usr/lib/jvm/jdk1.8.0_221/jre\n[20:17:53] [main/INFO] [FML]: Managed to load a deobfuscated Minecraft name- we are in a deobfuscated environment. Skipping runtime deobfuscation\n[20:17:53] [main/INFO] [FML]: Found a command line coremod : com.microsoft.Malmo.OverclockingPlugin\n[20:17:53] [main/WARN] [FML]: The coremod com.microsoft.Malmo.OverclockingPlugin does not have a MCVersion annotation, it may cause issues with this version of Minecraft\n[20:17:53] [main/INFO] [LaunchWrapper]: Calling tweak class net.minecraftforge.gradle.tweakers.CoremodTweaker\n[20:17:53] [main/INFO] [GradleStart]: Injecting location in coremod net.minecraftforge.fml.relauncher.FMLCorePlugin\n[20:17:53] [main/INFO] [GradleStart]: Injecting location in coremod net.minecraftforge.classloading.FMLForgePlugin\n[20:17:53] [main/INFO] [GradleStart]: Injecting location in coremod com.microsoft.Malmo.OverclockingPlugin\n[20:17:53] [main/INFO] [LaunchWrapper]: Loading tweak class name net.minecraftforge.fml.common.launcher.FMLInjectionAndSortingTweaker\n[20:17:53] [main/INFO] [LaunchWrapper]: Loading tweak class name net.minecraftforge.fml.common.launcher.FMLDeobfTweaker\n[20:17:53] [main/INFO] [LaunchWrapper]: Loading tweak class name net.minecraftforge.gradle.tweakers.AccessTransformerTweaker\n[20:17:53] [main/INFO] [LaunchWrapper]: Calling tweak class net.minecraftforge.fml.common.launcher.FMLInjectionAndSortingTweaker\n[20:17:53] [main/INFO] [LaunchWrapper]: Calling tweak class net.minecraftforge.fml.common.launcher.FMLInjectionAndSortingTweaker\n[20:17:53] [main/INFO] [LaunchWrapper]: Calling tweak class net.minecraftforge.fml.relauncher.CoreModManager$FMLPluginWrapper\n[20:17:53] [main/ERROR] [FML]: The binary patch set is missing. Either you are in a development environment, or things are not going to work!\n[20:17:53] [main/ERROR] [FML]: FML appears to be missing any signature data. This is not a good thing\n[20:17:53] [main/INFO] [LaunchWrapper]: Calling tweak class net.minecraftforge.fml.relauncher.CoreModManager$FMLPluginWrapper\n[20:17:53] [main/INFO] [LaunchWrapper]: Calling tweak class net.minecraftforge.fml.relauncher.CoreModManager$FMLPluginWrapper\n[20:17:53] [main/INFO] [LaunchWrapper]: Calling tweak class net.minecraftforge.fml.common.launcher.FMLDeobfTweaker\n[20:17:53] [main/INFO] [LaunchWrapper]: Calling tweak class net.minecraftforge.gradle.tweakers.AccessTransformerTweaker\n[20:17:53] [main/INFO] [LaunchWrapper]: Loading tweak class name net.minecraftforge.fml.common.launcher.TerminalTweaker\n[20:17:53] [main/INFO] [LaunchWrapper]: Calling tweak class net.minecraftforge.fml.common.launcher.TerminalTweaker\n[20:17:53] [main/INFO] [LaunchWrapper]: Launching wrapped minecraft {net.minecraft.client.main.Main}\n[20:17:53] [main/INFO] [STDOUT]: [com.microsoft.Malmo.OverclockingClassTransformer:transform:58]: MALMO: Attempting to transform MinecraftServer\n[20:17:53] [main/INFO] [STDOUT]: [com.microsoft.Malmo.OverclockingClassTransformer:overclockRenderer:187]: MALMO: Found Minecraft, attempting to transform it\n[20:17:53] [main/INFO] [STDOUT]: [com.microsoft.Malmo.OverclockingClassTransformer:overclockRenderer:193]: MALMO: Found Minecraft.runGameLoop() method, attempting to transform it\n[20:17:53] [main/INFO] [STDOUT]: [com.microsoft.Malmo.OverclockingClassTransformer:overclockRenderer:208]: MALMO: Hooked into call to Minecraft.updateDisplay()\n[20:17:54] [main/INFO] [STDOUT]: [com.microsoft.Malmo.OverclockingClassTransformer:transform:42]: Transformed Name: net.minecraft.client.entity.EntityPlayerSP\n[20:17:54] [main/INFO] [STDOUT]: [com.microsoft.Malmo.OverclockingClassTransformer:transform:42]: Transformed Name: net.minecraft.client.entity.AbstractClientPlayer\n[20:17:54] [Client thread/INFO] [STDOUT]: [com.microsoft.Malmo.OverclockingClassTransformer:transform:58]: MALMO: Attempting to transform MinecraftServer\n[20:17:54] [Client thread/INFO] [STDOUT]: [com.microsoft.Malmo.OverclockingClassTransformer:overclockServer:123]: MALMO: Found MinecraftServer, attempting to transform it\n[20:17:54] [Client thread/INFO] [STDOUT]: [com.microsoft.Malmo.OverclockingClassTransformer:overclockServer:129]: MALMO: Found MinecraftServer.run() method, attempting to transform it\n[20:17:54] [Client thread/INFO] [STDOUT]: [com.microsoft.Malmo.OverclockingClassTransformer:overclockServer:137]: MALMO: Transforming LDC\n[20:17:54] [Client thread/INFO] [STDOUT]: [com.microsoft.Malmo.OverclockingClassTransformer:overclockServer:137]: MALMO: Transforming LDC\n[20:17:54] [Client thread/INFO] [STDOUT]: [com.microsoft.Malmo.OverclockingClassTransformer:overclockServer:137]: MALMO: Transforming LDC\n[20:17:54] [Client thread/INFO] [STDOUT]: [com.microsoft.Malmo.OverclockingClassTransformer:overclockServer:137]: MALMO: Transforming LDC\n[20:17:54] [Client thread/INFO]: Setting user: Player243\n[20:17:56] [Client thread/WARN]: Skipping bad option: lastServer:\n[20:17:56] [Client thread/INFO]: LWJGL Version: 2.9.4\n[20:17:57] [Client thread/INFO]: [STDOUT]: MALMO: Attempting to transform MinecraftServer\n[20:17:57] [Client thread/INFO]: [STDOUT]: MALMO: Found GlStateManager, attempting to transform it\n[20:17:57] [Client thread/INFO]: [STDOUT]: MALMO: Found GlStateManager.bindTexture() method, attempting to transform it\n[20:17:57] [Client thread/INFO]: [STDOUT]: MALMO: Hooked into call to GlStateManager.bindTexture()\n[20:17:57] [Client thread/INFO]: [STDOUT]: ---- Minecraft Crash Report ----\n// Everything's going to plan. No, really, that was supposed to happen.Time: 3/2/20 8:17 PM\nDescription: Loading screen debug infoThis is just a prompt for computer specs to be printed. THIS IS NOT A ERROR-- System Details --\nDetails:\nMinecraft Version: 1.11.2\nOperating System: Linux (amd64) version 4.15.0-76-generic\nJava Version: 1.8.0_221, Oracle Corporation\nJava VM Version: Java HotSpot(TM) 64-Bit Server VM (mixed mode), Oracle Corporation\nMemory: 149972144 bytes (143 MB) / 590348288 bytes (563 MB) up to 1908932608 bytes (1820 MB)\nJVM Flags: 1 total; -Xmx2G\nIntCache: cache: 0, tcache: 0, allocated: 0, tallocated: 0\nFML:\nLoaded coremods (and transformers):\nOverclockingPlugin (MalmoMod-0.37.0.jar)\ncom.microsoft.Malmo.OverclockingClassTransformer\nGL info: ' Vendor: 'nouveau' Version: '4.3 (Compatibility Profile) Mesa 19.2.8' Renderer: 'NV117'\n[20:17:57] [Client thread/INFO] [FML]: MinecraftForge v13.20.0.2228 Initialized\n[20:17:57] [Client thread/INFO] [FML]: Replaced 232 ore recipes\n[20:17:57] [Client thread/INFO] [FML]: Found 0 mods from the command line. Injecting into mod discoverer\n[20:17:57] [Client thread/INFO] [FML]: Searching /home/justin/MalmoPlatform/build/install/Minecraft/run/mods for mods\n[20:17:58] [Client thread/INFO] [FML]: Forge Mod Loader has identified 5 mods to load\n[20:17:58] [Client thread/INFO] [FML]: Attempting connection with missing mods [minecraft, mcp, FML, forge, malmomod] at CLIENT\n[20:17:58] [Client thread/INFO] [FML]: Attempting connection with missing mods [minecraft, mcp, FML, forge, malmomod] at SERVER\n[20:17:58] [Client thread/INFO]: Reloading ResourceManager: Default, FMLFileResourcePack:Forge Mod Loader, FMLFileResourcePack:Minecraft Forge, FMLFileResourcePack:Microsoft Malmo Mod\n[20:17:58] [Client thread/WARN]: ResourcePack: ignored non-lowercase namespace: MalmoMod in /home/justin/MalmoPlatform/build/install/Minecraft/build/libs/MalmoMod-0.37.0.jar\n[20:17:58] [Client thread/WARN]: ResourcePack: ignored non-lowercase namespace: MalmoMod in /home/justin/MalmoPlatform/build/install/Minecraft/build/libs/MalmoMod-0.37.0.jar\n[20:17:58] [Client thread/WARN]: ResourcePack: ignored non-lowercase namespace: MalmoMod in /home/justin/MalmoPlatform/build/install/Minecraft/build/libs/MalmoMod-0.37.0.jar\n[20:17:58] [Client thread/INFO] [FML]: Processing ObjectHolder annotations\n[20:17:58] [Client thread/INFO] [FML]: Found 444 ObjectHolder annotations\n[20:17:58] [Client thread/INFO] [FML]: Identifying ItemStackHolder annotations\n[20:17:58] [Client thread/INFO] [FML]: Found 0 ItemStackHolder annotations\n[20:17:58] [Client thread/INFO] [FML]: Applying holder lookups\n[20:17:58] [Client thread/INFO] [FML]: Holder lookups applied\n[20:17:58] [Client thread/INFO] [FML]: Applying holder lookups\n[20:17:58] [Client thread/INFO] [FML]: Holder lookups applied\n[20:17:58] [Client thread/INFO] [FML]: Applying holder lookups\n[20:17:58] [Client thread/INFO] [FML]: Holder lookups applied\n[20:17:58] [Client thread/INFO] [FML]: Configured a dormant chunk cache size of 0\n[20:17:58] [Client thread/INFO]: [STDOUT]: Testing schemas against internal version number: 0.37\n[20:17:58] [Forge Version Check/INFO] [ForgeVersionCheck]: [forge] Starting version check at \n[20:17:59] [Forge Version Check/INFO] [ForgeVersionCheck]: [forge] Found status: OUTDATED Target: 13.20.1.2386\n[20:17:59] [Client thread/INFO] [FML]: Applying holder lookups\n[20:17:59] [Client thread/INFO] [FML]: Holder lookups applied\n[20:17:59] [Client thread/INFO] [FML]: Injecting itemstacks\n[20:17:59] [Client thread/INFO] [FML]: Itemstack injection complete\n[20:17:59] [Sound Library Loader/INFO]: Starting up SoundSystem...\n[20:18:00] [Thread-7/INFO]: Initializing LWJGL OpenAL\n[20:18:00] [Thread-7/INFO]: (The LWJGL binding of OpenAL.  For more information, see )\n[20:18:00] [Thread-7/INFO]: OpenAL initialized.\n[20:18:00] [Sound Library Loader/INFO]: Sound engine started\n[20:18:00] [Client thread/INFO] [FML]: Max texture size: 16384\n[20:18:00] [Client thread/INFO]: Created: 16x16 textures-atlas\n[20:18:01] [Client thread/INFO]: [STDOUT]: CLIENT request state: WAITING_FOR_MOD_READY\n[20:18:01] [Client thread/INFO] [FML]: Injecting itemstacks\n[20:18:01] [Client thread/INFO] [FML]: Itemstack injection complete\n[20:18:01] [Client thread/INFO] [FML]: Forge Mod Loader has successfully loaded 5 mods\n[20:18:01] [Client thread/INFO]: Reloading ResourceManager: Default, FMLFileResourcePack:Forge Mod Loader, FMLFileResourcePack:Minecraft Forge, FMLFileResourcePack:Microsoft Malmo Mod\n[20:18:01] [Client thread/WARN]: ResourcePack: ignored non-lowercase namespace: MalmoMod in /home/justin/MalmoPlatform/build/install/Minecraft/build/libs/MalmoMod-0.37.0.jar\n[20:18:01] [Client thread/WARN]: ResourcePack: ignored non-lowercase namespace: MalmoMod in /home/justin/MalmoPlatform/build/install/Minecraft/build/libs/MalmoMod-0.37.0.jar\n[20:18:01] [Client thread/WARN]: ResourcePack: ignored non-lowercase namespace: MalmoMod in /home/justin/MalmoPlatform/build/install/Minecraft/build/libs/MalmoMod-0.37.0.jar\n[20:18:01] [Client thread/INFO]: SoundSystem shutting down...\n[20:18:02] [Client thread/WARN]: Author: Paul Lamb, \n[20:18:02] [Sound Library Loader/INFO]: Starting up SoundSystem...\n[20:18:02] [Thread-9/INFO]: Initializing LWJGL OpenAL\n[20:18:02] [Thread-9/INFO]: (The LWJGL binding of OpenAL.  For more information, see )\n[20:18:02] [Thread-9/INFO]: OpenAL initialized.\n[20:18:02] [Sound Library Loader/INFO]: Sound engine started\n[20:18:02] [Client thread/INFO] [FML]: Max texture size: 16384\n[20:18:02] [Client thread/INFO]: Created: 512x512 textures-atlas\n[20:18:03] [Client thread/WARN]: Skipping bad option: lastServer:\n[20:18:04] [Client thread/INFO]: [STDOUT]: CLIENT enter state: WAITING_FOR_MOD_READY\n[20:18:04] [Thread-11/INFO]: [STDOUT]: INFO: ->mcp(10000) Listening for messages on port 10000\n[20:18:04] [Client thread/INFO]: [STDOUT]: CLIENT request state: DORMANT\n[20:18:04] [Client thread/INFO]: [STDOUT]: CLIENT enter state: DORMANT\n[20:18:04] [Realms Notification Availability checker /INFO]: Could not authorize you against Realms server: Invalid session idI am wondering if this provides any useful information as to what the problem might be. One detail that might be important is that there are two instances of ./launchClient.sh. One is in the MalmoPlatform/Minecraft directory, and the other is in the MalmoPlatform/build/install/Minecraft directory. The one that I have been running is the latter of the two, and I am curious about whether that might have something to do with the problem.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "DaveyBiggers",
            "datetime": "Mar 3, 2020",
            "body": "Thanks for the trace. Okay, so what happens when you try to run the samples? You say the terminal just gets stuck on the command ? Can you step through the python code and see exactly where it gets stuck?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "DarthMalloc",
            "datetime": "Mar 3, 2020",
            "body": "Thank you very much for getting back to me again. I put in some print commands to mark checkpoints in tutorial_1.py. The code runs normally until it gets to the line\n\nOnce it hits this point, it just gets stuck, but does not show any error messages. I ran the ctest command in verbose mode inside the MalmoPlatform/build directory, and I got the following output:UpdateCTestConfiguration  from :/home/justin/MalmoPlatform/build/DartConfiguration.tcl\nParse Config file:/home/justin/MalmoPlatform/build/DartConfiguration.tcl\nUpdateCTestConfiguration  from :/home/justin/MalmoPlatform/build/DartConfiguration.tcl\nParse Config file:/home/justin/MalmoPlatform/build/DartConfiguration.tcl\nTest project /home/justin/MalmoPlatform/build\nConstructing a list of tests\nDone constructing a list of tests\nUpdating test list for fixtures\nAdded 0 tests to meet fixture requirements\nChecking test dependency graph...\nChecking test dependency graph end\ntest 1\nStart   1: CppTests_create_tcp_server1: Test command: /home/justin/MalmoPlatform/build/Malmo/test/CppTests/CppTests_create_tcp_server\n1: Environment variables:\n1:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n1: Test timeout computed to be: 1500\n1: Server listening on port: 10062\n1/113 Test   : CppTests_create_tcp_server .....................................   Passed    0.07 sec\ntest 2\nStart   2: CppTests_test_agent_host2: Test command: /home/justin/MalmoPlatform/build/Malmo/test/CppTests/CppTests_test_agent_host\n2: Environment variables:\n2:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n2: Test timeout computed to be: 1500\n2: Malmo version: 0.37.0\n2:\n2: Allowed options:\n2:   -h [ --help ]         show description of allowed options\n2:   --test                run this as an integration test\n2:\n2:\n2/113 Test   : CppTests_test_agent_host .......................................   Passed    0.03 sec\ntest 3\nStart   3: CppTests_test_argument_parser3: Test command: /home/justin/MalmoPlatform/build/Malmo/test/CppTests/CppTests_test_argument_parser\n3: Environment variables:\n3:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n3: Test timeout computed to be: 1500\n3/113 Test   : CppTests_test_argument_parser ..................................   Passed    0.01 sec\ntest 4\nStart   4: CppTests_test_client_server4: Test command: /home/justin/MalmoPlatform/build/Malmo/test/CppTests/CppTests_test_client_server\n4: Environment variables:\n4:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n4: Test timeout computed to be: 1500\n4: Starting server..\n4: Sending messages..\n4: Exiting..\n4/113 Test   : CppTests_test_client_server ....................................   Passed    0.21 sec\ntest 5\nStart   5: CppTests_test_mission5: Test command: /home/justin/MalmoPlatform/build/Malmo/test/CppTests/CppTests_test_mission\n5: Environment variables:\n5:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n5: Test timeout computed to be: 1500\n5/113 Test   : CppTests_test_mission ..........................................   Passed    0.01 sec\ntest 6\nStart   6: CppTests_test_parameter_set6: Test command: /home/justin/MalmoPlatform/build/Malmo/test/CppTests/CppTests_test_parameter_set\n6: Environment variables:\n6:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n6: Test timeout computed to be: 1500\n6/113 Test   : CppTests_test_parameter_set ....................................   Passed    0.00 sec\ntest 7\nStart   7: CppTests_test_persistence7: Test command: /home/justin/MalmoPlatform/build/Malmo/test/CppTests/CppTests_test_persistence\n7: Environment variables:\n7:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n7: Test timeout computed to be: 1500\n7: ERROR: Cannot write to /home/justin/MalmoPlatform/build/Malmo/test/CppTests/c://path//that//probably//does//not//exist//output.tgz - check the path exists and you have permission to write there.\n7: Error starting mission: Failed to find an available client for this mission - tried all the clients in the supplied client pool.\n7:\n7/113 Test   : CppTests_test_persistence ......................................***Failed   60.64 sec\ntest 8\nStart   8: CppTests_test_string_server8: Test command: /home/justin/MalmoPlatform/build/Malmo/test/CppTests/CppTests_test_string_server\n8: Environment variables:\n8:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n8: Test timeout computed to be: 1500\n8: Starting server..\n8: Sending messages..\n8: Exiting..\n8: Starting server..\n8: Sending messages..\n8: terminate called after throwing an instance of 'std::runtime_error'\n8:   what():  Response read failed Operation canceled\n8/113 Test   : CppTests_test_string_server ....................................***Exception: Child aborted 61.24 sec\ntest 9\nStart   9: CppTests_test_video_server9: Test command: /home/justin/MalmoPlatform/build/Malmo/test/CppTests/CppTests_test_video_server\n9: Environment variables:\n9:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n9: Test timeout computed to be: 1500\n9/113 Test   : CppTests_test_video_server .....................................   Passed    5.19 sec\ntest 10\nStart  10: CppTests_test_video_writer10: Test command: /home/justin/MalmoPlatform/build/Malmo/test/CppTests/CppTests_test_video_writer\n10: Environment variables:\n10:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n10: Test timeout computed to be: 1500\n10: beginning video writer test...complete.\n10: test complete.\n10/113 Test  : CppTests_test_video_writer .....................................   Passed    0.54 sec\ntest 11\nStart  11: JavaTests_test_agent_host11: Test command: /usr/bin/java \"-cp\" \"/home/justin/MalmoPlatform/build/Malmo/test/JavaTests/test_agent_host.jar:/home/justin/MalmoPlatform/build/Malmo/src/JavaWrapper/MalmoJavaJar.jar\" \"-Djava.library.path=/home/justin/MalmoPlatform/build/Malmo/src/JavaWrapper\" \"test_agent_host\"\n11: Environment variables:\n11:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n11: Test timeout computed to be: 1500\n11: Error: A JNI error has occurred, please check your installation and try again\n11: Exception in thread \"main\" java.lang.UnsupportedClassVersionError: test_agent_host has been compiled by a more recent version of the Java Runtime (class file version 55.0), this version of the Java Runtime only recognizes class file versions up to 52.0\n11: \tat java.lang.ClassLoader.defineClass1(Native Method)\n11: \tat java.lang.ClassLoader.defineClass(ClassLoader.java:763)\n11: \tat java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)\n11: \tat java.net.URLClassLoader.defineClass(URLClassLoader.java:468)\n11: \tat java.net.URLClassLoader.access$100(URLClassLoader.java:74)\n11: \tat java.net.URLClassLoader$1.run(URLClassLoader.java:369)\n11: \tat java.net.URLClassLoader$1.run(URLClassLoader.java:363)\n11: \tat java.security.AccessController.doPrivileged(Native Method)\n11: \tat java.net.URLClassLoader.findClass(URLClassLoader.java:362)\n11: \tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n11: \tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)\n11: \tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n11: \tat sun.launcher.LauncherHelper.checkAndLoadMain(LauncherHelper.java:495)\n11/113 Test  : JavaTests_test_agent_host ......................................***Failed    0.47 sec\ntest 12\nStart  12: JavaTests_test_argument_parser12: Test command: /usr/bin/java \"-cp\" \"/home/justin/MalmoPlatform/build/Malmo/test/JavaTests/test_argument_parser.jar:/home/justin/MalmoPlatform/build/Malmo/src/JavaWrapper/MalmoJavaJar.jar\" \"-Djava.library.path=/home/justin/MalmoPlatform/build/Malmo/src/JavaWrapper\" \"test_argument_parser\"\n12: Environment variables:\n12:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n12: Test timeout computed to be: 1500\n12: Error: A JNI error has occurred, please check your installation and try again\n12: Exception in thread \"main\" java.lang.UnsupportedClassVersionError: test_argument_parser has been compiled by a more recent version of the Java Runtime (class file version 55.0), this version of the Java Runtime only recognizes class file versions up to 52.0\n12: \tat java.lang.ClassLoader.defineClass1(Native Method)\n12: \tat java.lang.ClassLoader.defineClass(ClassLoader.java:763)\n12: \tat java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)\n12: \tat java.net.URLClassLoader.defineClass(URLClassLoader.java:468)\n12: \tat java.net.URLClassLoader.access$100(URLClassLoader.java:74)\n12: \tat java.net.URLClassLoader$1.run(URLClassLoader.java:369)\n12: \tat java.net.URLClassLoader$1.run(URLClassLoader.java:363)\n12: \tat java.security.AccessController.doPrivileged(Native Method)\n12: \tat java.net.URLClassLoader.findClass(URLClassLoader.java:362)\n12: \tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n12: \tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)\n12: \tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n12: \tat sun.launcher.LauncherHelper.checkAndLoadMain(LauncherHelper.java:495)\n12/113 Test  : JavaTests_test_argument_parser .................................***Failed    0.06 sec\ntest 13\nStart  13: JavaTests_test_mission13: Test command: /usr/bin/java \"-cp\" \"/home/justin/MalmoPlatform/build/Malmo/test/JavaTests/test_mission.jar:/home/justin/MalmoPlatform/build/Malmo/src/JavaWrapper/MalmoJavaJar.jar\" \"-Djava.library.path=/home/justin/MalmoPlatform/build/Malmo/src/JavaWrapper\" \"test_mission\"\n13: Environment variables:\n13:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n13: Test timeout computed to be: 1500\n13: Error: A JNI error has occurred, please check your installation and try again\n13: Exception in thread \"main\" java.lang.UnsupportedClassVersionError: test_mission has been compiled by a more recent version of the Java Runtime (class file version 55.0), this version of the Java Runtime only recognizes class file versions up to 52.0\n13: \tat java.lang.ClassLoader.defineClass1(Native Method)\n13: \tat java.lang.ClassLoader.defineClass(ClassLoader.java:763)\n13: \tat java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)\n13: \tat java.net.URLClassLoader.defineClass(URLClassLoader.java:468)\n13: \tat java.net.URLClassLoader.access$100(URLClassLoader.java:74)\n13: \tat java.net.URLClassLoader$1.run(URLClassLoader.java:369)\n13: \tat java.net.URLClassLoader$1.run(URLClassLoader.java:363)\n13: \tat java.security.AccessController.doPrivileged(Native Method)\n13: \tat java.net.URLClassLoader.findClass(URLClassLoader.java:362)\n13: \tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n13: \tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)\n13: \tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n13: \tat sun.launcher.LauncherHelper.checkAndLoadMain(LauncherHelper.java:495)\n13/113 Test  : JavaTests_test_mission .........................................***Failed    0.06 sec\ntest 14\nStart  14: JavaTests_test_parameter_set14: Test command: /usr/bin/java \"-cp\" \"/home/justin/MalmoPlatform/build/Malmo/test/JavaTests/test_parameter_set.jar:/home/justin/MalmoPlatform/build/Malmo/src/JavaWrapper/MalmoJavaJar.jar\" \"-Djava.library.path=/home/justin/MalmoPlatform/build/Malmo/src/JavaWrapper\" \"test_parameter_set\"\n14: Environment variables:\n14:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n14: Test timeout computed to be: 1500\n14: Error: A JNI error has occurred, please check your installation and try again\n14: Exception in thread \"main\" java.lang.UnsupportedClassVersionError: test_parameter_set has been compiled by a more recent version of the Java Runtime (class file version 55.0), this version of the Java Runtime only recognizes class file versions up to 52.0\n14: \tat java.lang.ClassLoader.defineClass1(Native Method)\n14: \tat java.lang.ClassLoader.defineClass(ClassLoader.java:763)\n14: \tat java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)\n14: \tat java.net.URLClassLoader.defineClass(URLClassLoader.java:468)\n14: \tat java.net.URLClassLoader.access$100(URLClassLoader.java:74)\n14: \tat java.net.URLClassLoader$1.run(URLClassLoader.java:369)\n14: \tat java.net.URLClassLoader$1.run(URLClassLoader.java:363)\n14: \tat java.security.AccessController.doPrivileged(Native Method)\n14: \tat java.net.URLClassLoader.findClass(URLClassLoader.java:362)\n14: \tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n14: \tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)\n14: \tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n14: \tat sun.launcher.LauncherHelper.checkAndLoadMain(LauncherHelper.java:495)\n14/113 Test  : JavaTests_test_parameter_set ...................................***Failed    0.05 sec\ntest 15\nStart  15: JavaTests_test_wrapping15: Test command: /usr/bin/java \"-cp\" \"/home/justin/MalmoPlatform/build/Malmo/test/JavaTests/test_wrapping.jar:/home/justin/MalmoPlatform/build/Malmo/src/JavaWrapper/MalmoJavaJar.jar\" \"-Djava.library.path=/home/justin/MalmoPlatform/build/Malmo/src/JavaWrapper\" \"test_wrapping\"\n15: Environment variables:\n15:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n15: Test timeout computed to be: 1500\n15: Error: A JNI error has occurred, please check your installation and try again\n15: Exception in thread \"main\" java.lang.UnsupportedClassVersionError: test_wrapping has been compiled by a more recent version of the Java Runtime (class file version 55.0), this version of the Java Runtime only recognizes class file versions up to 52.0\n15: \tat java.lang.ClassLoader.defineClass1(Native Method)\n15: \tat java.lang.ClassLoader.defineClass(ClassLoader.java:763)\n15: \tat java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)\n15: \tat java.net.URLClassLoader.defineClass(URLClassLoader.java:468)\n15: \tat java.net.URLClassLoader.access$100(URLClassLoader.java:74)\n15: \tat java.net.URLClassLoader$1.run(URLClassLoader.java:369)\n15: \tat java.net.URLClassLoader$1.run(URLClassLoader.java:363)\n15: \tat java.security.AccessController.doPrivileged(Native Method)\n15: \tat java.net.URLClassLoader.findClass(URLClassLoader.java:362)\n15: \tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n15: \tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)\n15: \tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n15: \tat sun.launcher.LauncherHelper.checkAndLoadMain(LauncherHelper.java:495)\n15/113 Test  : JavaTests_test_wrapping ........................................***Failed    0.07 sec\ntest 16\nStart  16: PythonTests_test_wrapping16: Test command: /usr/bin/python3.6 \"test_wrapping.py\"\n16: Environment variables:\n16:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n16:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n16:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n16: Test timeout computed to be: 1500\n16/113 Test  : PythonTests_test_wrapping ......................................***Exception: SegFault  0.58 sec\ntest 17\nStart  17: PythonTests_test_argument_parser17: Test command: /usr/bin/python3.6 \"test_argument_parser.py\"\n17: Environment variables:\n17:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n17:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n17:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n17: Test timeout computed to be: 1500\n17/113 Test  : PythonTests_test_argument_parser ...............................***Exception: SegFault  0.24 sec\ntest 18\nStart  18: PythonTests_test_agent_host18: Test command: /usr/bin/python3.6 \"test_agent_host.py\"\n18: Environment variables:\n18:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n18:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n18:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n18: Test timeout computed to be: 1500\n18/113 Test  : PythonTests_test_agent_host ....................................***Exception: SegFault  0.20 sec\ntest 19\nStart  19: PythonTests_test_mission19: Test command: /usr/bin/python3.6 \"test_mission.py\"\n19: Environment variables:\n19:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n19:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n19:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n19: Test timeout computed to be: 1500\n19/113 Test  : PythonTests_test_mission .......................................***Exception: SegFault  0.20 sec\ntest 20\nStart  20: PythonTests_test_parameter_set20: Test command: /usr/bin/python3.6 \"test_parameter_set.py\"\n20: Environment variables:\n20:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n20:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n20:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n20: Test timeout computed to be: 1500\n20/113 Test  : PythonTests_test_parameter_set .................................***Exception: SegFault  0.20 sec\ntest 21\nStart  21: PythonTests_test_malmoutils21: Test command: /usr/bin/python3.6 \"test_malmoutils.py\"\n21: Environment variables:\n21:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n21:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n21:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n21: Test timeout computed to be: 1500\n21/113 Test  : PythonTests_test_malmoutils ....................................***Exception: SegFault  0.20 sec\ntest 22\nStart  22: PreIntegrationTests22: Test command: /usr/bin/python3.6 \"launch_minecraft_in_background.py\"\n22: Environment variables:\n22:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n22: Test timeout computed to be: 1500\n22: Something is listening on port 10000 - will assume Minecraft is running.\n22/113 Test  : PreIntegrationTests ............................................   Passed    0.09 sec\ntest 23\nStart  23: CppIntegrationTests_run_mission_help23: Test command: /home/justin/MalmoPlatform/build/Malmo/samples/Cpp_examples/run_mission \"--help\"\n23: Environment variables:\n23:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n23: Test timeout computed to be: 1500\n23: Malmo version: 0.37.0\n23:\n23: Allowed options:\n23:   -h [ --help ]         show description of allowed options\n23:   --test                run this as an integration test\n23:\n23:\n23/113 Test  : CppIntegrationTests_run_mission_help ...........................   Passed    0.03 sec\ntest 24\nStart  24: CppIntegrationTests_run_mission24: Test command: /home/justin/MalmoPlatform/build/Malmo/samples/Cpp_examples/run_mission \"--test\"\n24: Environment variables:\n24:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n24: Test timeout computed to be: 1500\n24: Waiting for the mission to start...\n24: video,observations,rewards received: 22,10,0\n24: video,observations,rewards received: 30,10,0\n24: video,observations,rewards received: 30,10,0\n24: video,observations,rewards received: 29,10,0\n24: video,observations,rewards received: 30,10,0\n24: video,observations,rewards received: 30,10,0\n24: video,observations,rewards received: 30,10,0\n24: video,observations,rewards received: 31,10,0\n24: video,observations,rewards received: 29,10,0\n24: video,observations,rewards received: 31,10,0\n24: video,observations,rewards received: 30,10,0\n24: video,observations,rewards received: 29,10,0\n24: video,observations,rewards received: 31,10,0\n24: video,observations,rewards received: 30,10,0\n24: video,observations,rewards received: 29,10,0\n24: video,observations,rewards received: 31,10,0\n24: video,observations,rewards received: 30,10,0\n24: video,observations,rewards received: 30,10,0\n24: video,observations,rewards received: 30,10,0\n24: video,observations,rewards received: 30,10,0\n24: video,observations,rewards received: 2,1,0\n24: Mission has stopped.\n24/113 Test  : CppIntegrationTests_run_mission ................................   Passed   11.02 sec\ntest 25\nStart  25: JavaIntegrationTests_JavaExamples_run_mission_help25: Test command: /usr/bin/java \"-cp\" \"/home/justin/MalmoPlatform/build/Malmo/samples/Java_examples/JavaExamples_run_mission.jar:/home/justin/MalmoPlatform/build/Malmo/src/JavaWrapper/MalmoJavaJar.jar\" \"-Djava.library.path=/home/justin/MalmoPlatform/build/Malmo/src/JavaWrapper\" \"JavaExamples_run_mission\" \"--help\"\n25: Environment variables:\n25:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n25: Test timeout computed to be: 1500\n25: Error: A JNI error has occurred, please check your installation and try again\n25: Exception in thread \"main\" java.lang.UnsupportedClassVersionError: JavaExamples_run_mission has been compiled by a more recent version of the Java Runtime (class file version 55.0), this version of the Java Runtime only recognizes class file versions up to 52.0\n25: \tat java.lang.ClassLoader.defineClass1(Native Method)\n25: \tat java.lang.ClassLoader.defineClass(ClassLoader.java:763)\n25: \tat java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)\n25: \tat java.net.URLClassLoader.defineClass(URLClassLoader.java:468)\n25: \tat java.net.URLClassLoader.access$100(URLClassLoader.java:74)\n25: \tat java.net.URLClassLoader$1.run(URLClassLoader.java:369)\n25: \tat java.net.URLClassLoader$1.run(URLClassLoader.java:363)\n25: \tat java.security.AccessController.doPrivileged(Native Method)\n25: \tat java.net.URLClassLoader.findClass(URLClassLoader.java:362)\n25: \tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n25: \tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)\n25: \tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n25: \tat sun.launcher.LauncherHelper.checkAndLoadMain(LauncherHelper.java:495)\n25/113 Test  : JavaIntegrationTests_JavaExamples_run_mission_help .............***Failed    0.10 sec\ntest 26\nStart  26: JavaIntegrationTests_JavaExamples_run_mission26: Test command: /usr/bin/java \"-cp\" \"/home/justin/MalmoPlatform/build/Malmo/samples/Java_examples/JavaExamples_run_mission.jar:/home/justin/MalmoPlatform/build/Malmo/src/JavaWrapper/MalmoJavaJar.jar\" \"-Djava.library.path=/home/justin/MalmoPlatform/build/Malmo/src/JavaWrapper\" \"JavaExamples_run_mission\" \"--test\"\n26: Environment variables:\n26:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n26: Test timeout computed to be: 1500\n26: Error: A JNI error has occurred, please check your installation and try again\n26: Exception in thread \"main\" java.lang.UnsupportedClassVersionError: JavaExamples_run_mission has been compiled by a more recent version of the Java Runtime (class file version 55.0), this version of the Java Runtime only recognizes class file versions up to 52.0\n26: \tat java.lang.ClassLoader.defineClass1(Native Method)\n26: \tat java.lang.ClassLoader.defineClass(ClassLoader.java:763)\n26: \tat java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)\n26: \tat java.net.URLClassLoader.defineClass(URLClassLoader.java:468)\n26: \tat java.net.URLClassLoader.access$100(URLClassLoader.java:74)\n26: \tat java.net.URLClassLoader$1.run(URLClassLoader.java:369)\n26: \tat java.net.URLClassLoader$1.run(URLClassLoader.java:363)\n26: \tat java.security.AccessController.doPrivileged(Native Method)\n26: \tat java.net.URLClassLoader.findClass(URLClassLoader.java:362)\n26: \tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n26: \tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)\n26: \tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n26: \tat sun.launcher.LauncherHelper.checkAndLoadMain(LauncherHelper.java:495)\n26/113 Test  : JavaIntegrationTests_JavaExamples_run_mission ..................***Failed    0.08 sec\ntest 27\nStart  27: PythonIntegrationTests_animation_test_help27: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/animation_test.py\" \"--help\"\n27: Environment variables:\n27:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n27:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n27: Test timeout computed to be: 1500\n27/113 Test  : PythonIntegrationTests_animation_test_help .....................***Exception: SegFault  0.22 sec\ntest 28\nStart  28: PythonIntegrationTests_animation_test28: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/animation_test.py\" \"--test\" \"--recording_dir\" \"animation_test\" \"--record_video\"\n28: Environment variables:\n28:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n28:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n28: Test timeout computed to be: 1500\n28/113 Test  : PythonIntegrationTests_animation_test ..........................***Exception: SegFault  0.19 sec\ntest 29\nStart  29: PythonIntegrationTests_braitenberg_simulation_help29: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/braitenberg_simulation.py\" \"--help\"\n29: Environment variables:\n29:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n29:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n29: Test timeout computed to be: 1500\n29/113 Test  : PythonIntegrationTests_braitenberg_simulation_help .............***Exception: SegFault  0.19 sec\ntest 30\nStart  30: PythonIntegrationTests_braitenberg_simulation30: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/braitenberg_simulation.py\" \"--test\" \"--recording_dir\" \"braitenberg_simulation\" \"--record_video\"\n30: Environment variables:\n30:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n30:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n30: Test timeout computed to be: 1500\n30/113 Test  : PythonIntegrationTests_braitenberg_simulation ..................***Exception: SegFault  0.20 sec\ntest 31\nStart  31: PythonIntegrationTests_build_test_help31: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/build_test.py\" \"--help\"\n31: Environment variables:\n31:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n31:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n31: Test timeout computed to be: 1500\n31: Traceback (most recent call last):\n31:   File \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/build_test.py\", line 42, in \n31:     from past.utils import old_div\n31: ModuleNotFoundError: No module named 'past'\n31/113 Test  : PythonIntegrationTests_build_test_help .........................***Failed    0.10 sec\ntest 32\nStart  32: PythonIntegrationTests_build_test32: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/build_test.py\" \"--test\" \"--recording_dir\" \"build_test\" \"--record_video\"\n32: Environment variables:\n32:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n32:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n32: Test timeout computed to be: 1500\n32: Traceback (most recent call last):\n32:   File \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/build_test.py\", line 42, in \n32:     from past.utils import old_div\n32: ModuleNotFoundError: No module named 'past'\n32/113 Test  : PythonIntegrationTests_build_test ..............................***Failed    0.10 sec\ntest 33\nStart  33: PythonIntegrationTests_chat_reward_help33: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/chat_reward.py\" \"--help\"\n33: Environment variables:\n33:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n33:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n33: Test timeout computed to be: 1500\n33/113 Test  : PythonIntegrationTests_chat_reward_help ........................***Exception: SegFault  0.19 sec\ntest 34\nStart  34: PythonIntegrationTests_chat_reward34: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/chat_reward.py\" \"--test\" \"--recording_dir\" \"chat_reward\" \"--record_video\"\n34: Environment variables:\n34:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n34:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n34: Test timeout computed to be: 1500\n34/113 Test  : PythonIntegrationTests_chat_reward .............................***Exception: SegFault  0.19 sec\ntest 35\nStart  35: PythonIntegrationTests_chunk_test_help35: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/chunk_test.py\" \"--help\"\n35: Environment variables:\n35:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n35:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n35: Test timeout computed to be: 1500\n35: Traceback (most recent call last):\n35:   File \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/chunk_test.py\", line 37, in \n35:     from past.utils import old_div\n35: ModuleNotFoundError: No module named 'past'\n35/113 Test  : PythonIntegrationTests_chunk_test_help .........................***Failed    0.10 sec\ntest 36\nStart  36: PythonIntegrationTests_chunk_test36: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/chunk_test.py\" \"--test\" \"--recording_dir\" \"chunk_test\" \"--record_video\"\n36: Environment variables:\n36:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n36:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n36: Test timeout computed to be: 1500\n36: Traceback (most recent call last):\n36:   File \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/chunk_test.py\", line 37, in \n36:     from past.utils import old_div\n36: ModuleNotFoundError: No module named 'past'\n36/113 Test  : PythonIntegrationTests_chunk_test ..............................***Failed    0.10 sec\ntest 37\nStart  37: PythonIntegrationTests_craft_work_help37: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/craft_work.py\" \"--help\"\n37: Environment variables:\n37:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n37:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n37: Test timeout computed to be: 1500\n37/113 Test  : PythonIntegrationTests_craft_work_help .........................***Exception: SegFault  0.19 sec\ntest 38\nStart  38: PythonIntegrationTests_craft_work38: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/craft_work.py\" \"--test\" \"--recording_dir\" \"craft_work\" \"--record_video\"\n38: Environment variables:\n38:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n38:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n38: Test timeout computed to be: 1500\n38/113 Test  : PythonIntegrationTests_craft_work ..............................***Exception: SegFault  0.19 sec\ntest 39\nStart  39: PythonIntegrationTests_decision_tree_test_help39: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/decision_tree_test.py\" \"--help\"\n39: Environment variables:\n39:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n39:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n39: Test timeout computed to be: 1500\n39: Traceback (most recent call last):\n39:   File \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/decision_tree_test.py\", line 23, in \n39:     from past.utils import old_div\n39: ModuleNotFoundError: No module named 'past'\n39/113 Test  : PythonIntegrationTests_decision_tree_test_help .................***Failed    0.10 sec\ntest 40\nStart  40: PythonIntegrationTests_decision_tree_test40: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/decision_tree_test.py\" \"--test\" \"--recording_dir\" \"decision_tree_test\" \"--record_video\"\n40: Environment variables:\n40:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n40:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n40: Test timeout computed to be: 1500\n40: Traceback (most recent call last):\n40:   File \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/decision_tree_test.py\", line 23, in \n40:     from past.utils import old_div\n40: ModuleNotFoundError: No module named 'past'\n40/113 Test  : PythonIntegrationTests_decision_tree_test ......................***Failed    0.10 sec\ntest 41\nStart  41: PythonIntegrationTests_default_world_test_help41: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/default_world_test.py\" \"--help\"\n41: Environment variables:\n41:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n41:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n41: Test timeout computed to be: 1500\n41/113 Test  : PythonIntegrationTests_default_world_test_help .................***Exception: SegFault  0.19 sec\ntest 42\nStart  42: PythonIntegrationTests_default_world_test42: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/default_world_test.py\" \"--test\" \"--recording_dir\" \"default_world_test\" \"--record_video\"\n42: Environment variables:\n42:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n42:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n42: Test timeout computed to be: 1500\n42/113 Test  : PythonIntegrationTests_default_world_test ......................***Exception: SegFault  0.19 sec\ntest 43\nStart  43: PythonIntegrationTests_depth_map_runner_help43: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/depth_map_runner.py\" \"--help\"\n43: Environment variables:\n43:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n43:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n43: Test timeout computed to be: 1500\n43: Traceback (most recent call last):\n43:   File \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/depth_map_runner.py\", line 23, in \n43:     from past.utils import old_div\n43: ModuleNotFoundError: No module named 'past'\n43/113 Test  : PythonIntegrationTests_depth_map_runner_help ...................***Failed    0.10 sec\ntest 44\nStart  44: PythonIntegrationTests_depth_map_runner44: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/depth_map_runner.py\" \"--test\" \"--recording_dir\" \"depth_map_runner\" \"--record_video\"\n44: Environment variables:\n44:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n44:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n44: Test timeout computed to be: 1500\n44: Traceback (most recent call last):\n44:   File \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/depth_map_runner.py\", line 23, in \n44:     from past.utils import old_div\n44: ModuleNotFoundError: No module named 'past'\n44/113 Test  : PythonIntegrationTests_depth_map_runner ........................***Failed    0.10 sec\ntest 45\nStart  45: PythonIntegrationTests_discrete_3d_test_help45: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/discrete_3d_test.py\" \"--help\"\n45: Environment variables:\n45:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n45:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n45: Test timeout computed to be: 1500\n45: Traceback (most recent call last):\n45:   File \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/discrete_3d_test.py\", line 39, in \n45:     from past.utils import old_div\n45: ModuleNotFoundError: No module named 'past'\n45/113 Test  : PythonIntegrationTests_discrete_3d_test_help ...................***Failed    0.10 sec\ntest 46\nStart  46: PythonIntegrationTests_discrete_3d_test46: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/discrete_3d_test.py\" \"--test\" \"--recording_dir\" \"discrete_3d_test\" \"--record_video\"\n46: Environment variables:\n46:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n46:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n46: Test timeout computed to be: 1500\n46: Traceback (most recent call last):\n46:   File \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/discrete_3d_test.py\", line 39, in \n46:     from past.utils import old_div\n46: ModuleNotFoundError: No module named 'past'\n46/113 Test  : PythonIntegrationTests_discrete_3d_test ........................***Failed    0.10 sec\ntest 47\nStart  47: PythonIntegrationTests_drawing_test_help47: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/drawing_test.py\" \"--help\"\n47: Environment variables:\n47:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n47:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n47: Test timeout computed to be: 1500\n47: Traceback (most recent call last):\n47:   File \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/drawing_test.py\", line 23, in \n47:     from past.utils import old_div\n47: ModuleNotFoundError: No module named 'past'\n47/113 Test  : PythonIntegrationTests_drawing_test_help .......................***Failed    0.10 sec\ntest 48\nStart  48: PythonIntegrationTests_drawing_test48: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/drawing_test.py\" \"--test\" \"--recording_dir\" \"drawing_test\" \"--record_video\"\n48: Environment variables:\n48:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n48:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n48: Test timeout computed to be: 1500\n48: Traceback (most recent call last):\n48:   File \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/drawing_test.py\", line 23, in \n48:     from past.utils import old_div\n48: ModuleNotFoundError: No module named 'past'\n48/113 Test  : PythonIntegrationTests_drawing_test ............................***Failed    0.10 sec\ntest 49\nStart  49: PythonIntegrationTests_file_test_help49: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/file_test.py\" \"--help\"\n49: Environment variables:\n49:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n49:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n49: Test timeout computed to be: 1500\n49/113 Test  : PythonIntegrationTests_file_test_help ..........................***Exception: SegFault  0.19 sec\ntest 50\nStart  50: PythonIntegrationTests_file_test50: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/file_test.py\" \"--test\" \"--recording_dir\" \"file_test\" \"--record_video\"\n50: Environment variables:\n50:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n50:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n50: Test timeout computed to be: 1500\n50/113 Test  : PythonIntegrationTests_file_test ...............................***Exception: SegFault  0.19 sec\ntest 51\nStart  51: PythonIntegrationTests_hit_test_help51: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/hit_test.py\" \"--help\"\n51: Environment variables:\n51:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n51:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n51: Test timeout computed to be: 1500\n51: Traceback (most recent call last):\n51:   File \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/hit_test.py\", line 29, in \n51:     from past.utils import old_div\n51: ModuleNotFoundError: No module named 'past'\n51/113 Test  : PythonIntegrationTests_hit_test_help ...........................***Failed    0.10 sec\ntest 52\nStart  52: PythonIntegrationTests_hit_test52: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/hit_test.py\" \"--test\" \"--recording_dir\" \"hit_test\" \"--record_video\"\n52: Environment variables:\n52:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n52:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n52: Test timeout computed to be: 1500\n52: Traceback (most recent call last):\n52:   File \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/hit_test.py\", line 29, in \n52:     from past.utils import old_div\n52: ModuleNotFoundError: No module named 'past'\n52/113 Test  : PythonIntegrationTests_hit_test ................................***Failed    0.10 sec\ntest 53\nStart  53: PythonIntegrationTests_inventory_test_help53: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/inventory_test.py\" \"--help\"\n53: Environment variables:\n53:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n53:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n53: Test timeout computed to be: 1500\n53: Traceback (most recent call last):\n53:   File \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/inventory_test.py\", line 39, in \n53:     from past.utils import old_div\n53: ModuleNotFoundError: No module named 'past'\n53/113 Test  : PythonIntegrationTests_inventory_test_help .....................***Failed    0.10 sec\ntest 54\nStart  54: PythonIntegrationTests_inventory_test54: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/inventory_test.py\" \"--test\" \"--recording_dir\" \"inventory_test\" \"--record_video\"\n54: Environment variables:\n54:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n54:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n54: Test timeout computed to be: 1500\n54: Traceback (most recent call last):\n54:   File \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/inventory_test.py\", line 39, in \n54:     from past.utils import old_div\n54: ModuleNotFoundError: No module named 'past'\n54/113 Test  : PythonIntegrationTests_inventory_test ..........................***Failed    0.10 sec\ntest 55\nStart  55: PythonIntegrationTests_MazeRunner_help55: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/MazeRunner.py\" \"--help\"\n55: Environment variables:\n55:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n55:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n55: Test timeout computed to be: 1500\n55/113 Test  : PythonIntegrationTests_MazeRunner_help .........................***Exception: SegFault  0.21 sec\ntest 56\nStart  56: PythonIntegrationTests_MazeRunner56: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/MazeRunner.py\" \"--test\" \"--recording_dir\" \"MazeRunner\" \"--record_video\"\n56: Environment variables:\n56:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n56:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n56: Test timeout computed to be: 1500\n56/113 Test  : PythonIntegrationTests_MazeRunner ..............................***Exception: SegFault  0.19 sec\ntest 57\nStart  57: PythonIntegrationTests_mission_quit_command_example_help57: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/mission_quit_command_example.py\" \"--help\"\n57: Environment variables:\n57:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n57:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n57: Test timeout computed to be: 1500\n57/113 Test  : PythonIntegrationTests_mission_quit_command_example_help .......***Exception: SegFault  0.19 sec\ntest 58\nStart  58: PythonIntegrationTests_mission_quit_command_example58: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/mission_quit_command_example.py\" \"--test\" \"--recording_dir\" \"mission_quit_command_example\" \"--record_video\"\n58: Environment variables:\n58:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n58:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n58: Test timeout computed to be: 1500\n58/113 Test  : PythonIntegrationTests_mission_quit_command_example ............***Exception: SegFault  0.19 sec\ntest 59\nStart  59: PythonIntegrationTests_mob_fun_help59: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/mob_fun.py\" \"--help\"\n59: Environment variables:\n59:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n59:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n59: Test timeout computed to be: 1500\n59: Traceback (most recent call last):\n59:   File \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/mob_fun.py\", line 25, in \n59:     from future import standard_library\n59: ModuleNotFoundError: No module named 'future'\n59/113 Test  : PythonIntegrationTests_mob_fun_help ............................***Failed    0.10 sec\ntest 60\nStart  60: PythonIntegrationTests_mob_fun60: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/mob_fun.py\" \"--test\" \"--recording_dir\" \"mob_fun\" \"--record_video\"\n60: Environment variables:\n60:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n60:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n60: Test timeout computed to be: 1500\n60: Traceback (most recent call last):\n60:   File \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/mob_fun.py\", line 25, in \n60:     from future import standard_library\n60: ModuleNotFoundError: No module named 'future'\n60/113 Test  : PythonIntegrationTests_mob_fun .................................***Failed    0.10 sec\ntest 61\nStart  61: PythonIntegrationTests_mouse_steering_test_help61: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/mouse_steering_test.py\" \"--help\"\n61: Environment variables:\n61:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n61:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n61: Test timeout computed to be: 1500\n61/113 Test  : PythonIntegrationTests_mouse_steering_test_help ................***Exception: SegFault  0.19 sec\ntest 62\nStart  62: PythonIntegrationTests_mouse_steering_test62: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/mouse_steering_test.py\" \"--test\" \"--recording_dir\" \"mouse_steering_test\" \"--record_video\"\n62: Environment variables:\n62:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n62:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n62: Test timeout computed to be: 1500\n62/113 Test  : PythonIntegrationTests_mouse_steering_test .....................***Exception: SegFault  0.20 sec\ntest 63\nStart  63: PythonIntegrationTests_moving_target_test_help63: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/moving_target_test.py\" \"--help\"\n63: Environment variables:\n63:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n63:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n63: Test timeout computed to be: 1500\n63/113 Test  : PythonIntegrationTests_moving_target_test_help .................***Exception: SegFault  0.19 sec\ntest 64\nStart  64: PythonIntegrationTests_moving_target_test64: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/moving_target_test.py\" \"--test\" \"--recording_dir\" \"moving_target_test\" \"--record_video\"\n64: Environment variables:\n64:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n64:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n64: Test timeout computed to be: 1500\n64/113 Test  : PythonIntegrationTests_moving_target_test ......................***Exception: SegFault  0.19 sec\ntest 65\nStart  65: PythonIntegrationTests_overclock_test_help65: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/overclock_test.py\" \"--help\"\n65: Environment variables:\n65:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n65:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n65: Test timeout computed to be: 1500\n65: Traceback (most recent call last):\n65:   File \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/overclock_test.py\", line 29, in \n65:     from past.utils import old_div\n65: ModuleNotFoundError: No module named 'past'\n65/113 Test  : PythonIntegrationTests_overclock_test_help .....................***Failed    0.10 sec\ntest 66\nStart  66: PythonIntegrationTests_overclock_test66: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/overclock_test.py\" \"--test\" \"--recording_dir\" \"overclock_test\" \"--record_video\"\n66: Environment variables:\n66:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n66:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n66: Test timeout computed to be: 1500\n66: Traceback (most recent call last):\n66:   File \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/overclock_test.py\", line 29, in \n66:     from past.utils import old_div\n66: ModuleNotFoundError: No module named 'past'\n66/113 Test  : PythonIntegrationTests_overclock_test ..........................***Failed    0.10 sec\ntest 67\nStart  67: PythonIntegrationTests_patchwork_quilt_help67: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/patchwork_quilt.py\" \"--help\"\n67: Environment variables:\n67:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n67:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n67: Test timeout computed to be: 1500\n67: Traceback (most recent call last):\n67:   File \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/patchwork_quilt.py\", line 26, in \n67:     from past.utils import old_div\n67: ModuleNotFoundError: No module named 'past'\n67/113 Test  : PythonIntegrationTests_patchwork_quilt_help ....................***Failed    0.10 sec\ntest 68\nStart  68: PythonIntegrationTests_patchwork_quilt68: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/patchwork_quilt.py\" \"--test\" \"--recording_dir\" \"patchwork_quilt\" \"--record_video\"\n68: Environment variables:\n68:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n68:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n68: Test timeout computed to be: 1500\n68: Traceback (most recent call last):\n68:   File \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/patchwork_quilt.py\", line 26, in \n68:     from past.utils import old_div\n68: ModuleNotFoundError: No module named 'past'\n68/113 Test  : PythonIntegrationTests_patchwork_quilt .........................***Failed    0.10 sec\ntest 69\nStart  69: PythonIntegrationTests_quit_from_reaching_position_test_help69: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/quit_from_reaching_position_test.py\" \"--help\"\n69: Environment variables:\n69:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n69:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n69: Test timeout computed to be: 1500\n69/113 Test  : PythonIntegrationTests_quit_from_reaching_position_test_help ...***Exception: SegFault  0.19 sec\ntest 70\nStart  70: PythonIntegrationTests_quit_from_reaching_position_test70: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/quit_from_reaching_position_test.py\" \"--test\" \"--recording_dir\" \"quit_from_reaching_position_test\" \"--record_video\"\n70: Environment variables:\n70:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n70:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n70: Test timeout computed to be: 1500\n70/113 Test  : PythonIntegrationTests_quit_from_reaching_position_test ........***Exception: SegFault  0.19 sec\ntest 71\nStart  71: PythonIntegrationTests_radar_test_help71: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/radar_test.py\" \"--help\"\n71: Environment variables:\n71:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n71:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n71: Test timeout computed to be: 1500\n71: Traceback (most recent call last):\n71:   File \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/radar_test.py\", line 28, in \n71:     from future import standard_library\n71: ModuleNotFoundError: No module named 'future'\n71/113 Test  : PythonIntegrationTests_radar_test_help .........................***Failed    0.10 sec\ntest 72\nStart  72: PythonIntegrationTests_radar_test72: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/radar_test.py\" \"--test\" \"--recording_dir\" \"radar_test\" \"--record_video\"\n72: Environment variables:\n72:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n72:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n72: Test timeout computed to be: 1500\n72: Traceback (most recent call last):\n72:   File \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/radar_test.py\", line 28, in \n72:     from future import standard_library\n72: ModuleNotFoundError: No module named 'future'\n72/113 Test  : PythonIntegrationTests_radar_test ..............................***Failed    0.10 sec\ntest 73\nStart  73: PythonIntegrationTests_render_speed_test_help73: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/render_speed_test.py\" \"--help\"\n73: Environment variables:\n73:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n73:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n73: Test timeout computed to be: 1500\n73: Traceback (most recent call last):\n73:   File \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/render_speed_test.py\", line 25, in \n73:     from past.utils import old_div\n73: ModuleNotFoundError: No module named 'past'\n73/113 Test  : PythonIntegrationTests_render_speed_test_help ..................***Failed    0.10 sec\ntest 74\nStart  74: PythonIntegrationTests_render_speed_test74: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/render_speed_test.py\" \"--test\" \"--recording_dir\" \"render_speed_test\" \"--record_video\"\n74: Environment variables:\n74:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n74:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n74: Test timeout computed to be: 1500\n74: Traceback (most recent call last):\n74:   File \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/render_speed_test.py\", line 25, in \n74:     from past.utils import old_div\n74: ModuleNotFoundError: No module named 'past'\n74/113 Test  : PythonIntegrationTests_render_speed_test .......................***Failed    0.10 sec\ntest 75\nStart  75: PythonIntegrationTests_reward_for_discarding_items_test_help75: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/reward_for_discarding_items_test.py\" \"--help\"\n75: Environment variables:\n75:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n75:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n75: Test timeout computed to be: 1500\n75/113 Test  : PythonIntegrationTests_reward_for_discarding_items_test_help ...***Exception: SegFault  0.19 sec\ntest 76\nStart  76: PythonIntegrationTests_reward_for_discarding_items_test76: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/reward_for_discarding_items_test.py\" \"--test\" \"--recording_dir\" \"reward_for_discarding_items_test\" \"--record_video\"\n76: Environment variables:\n76:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n76:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n76: Test timeout computed to be: 1500\n76/113 Test  : PythonIntegrationTests_reward_for_discarding_items_test ........***Exception: SegFault  0.19 sec\ntest 77\nStart  77: PythonIntegrationTests_reward_for_items_test_help77: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/reward_for_items_test.py\" \"--help\"\n77: Environment variables:\n77:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n77:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n77: Test timeout computed to be: 1500\n77/113 Test  : PythonIntegrationTests_reward_for_items_test_help ..............***Exception: SegFault  0.19 sec\ntest 78\nStart  78: PythonIntegrationTests_reward_for_items_test78: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/reward_for_items_test.py\" \"--test\" \"--recording_dir\" \"reward_for_items_test\" \"--record_video\"\n78: Environment variables:\n78:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n78:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n78: Test timeout computed to be: 1500\n78/113 Test  : PythonIntegrationTests_reward_for_items_test ...................***Exception: SegFault  0.19 sec\ntest 79\nStart  79: PythonIntegrationTests_reward_for_mission_end_test_help79: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/reward_for_mission_end_test.py\" \"--help\"\n79: Environment variables:\n79:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n79:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n79: Test timeout computed to be: 1500\n79/113 Test  : PythonIntegrationTests_reward_for_mission_end_test_help ........***Exception: SegFault  0.19 sec\ntest 80\nStart  80: PythonIntegrationTests_reward_for_mission_end_test80: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/reward_for_mission_end_test.py\" \"--test\" \"--recording_dir\" \"reward_for_mission_end_test\" \"--record_video\"\n80: Environment variables:\n80:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n80:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n80: Test timeout computed to be: 1500\n80/113 Test  : PythonIntegrationTests_reward_for_mission_end_test .............***Exception: SegFault  0.19 sec\ntest 81\nStart  81: PythonIntegrationTests_robust_frames_help81: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/robust_frames.py\" \"--help\"\n81: Environment variables:\n81:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n81:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n81: Test timeout computed to be: 1500\n81: Traceback (most recent call last):\n81:   File \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/robust_frames.py\", line 29, in \n81:     from future import standard_library\n81: ModuleNotFoundError: No module named 'future'\n81/113 Test  : PythonIntegrationTests_robust_frames_help ......................***Failed    0.10 sec\ntest 82\nStart  82: PythonIntegrationTests_robust_frames82: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/robust_frames.py\" \"--test\" \"--recording_dir\" \"robust_frames\" \"--record_video\"\n82: Environment variables:\n82:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n82:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n82: Test timeout computed to be: 1500\n82: Traceback (most recent call last):\n82:   File \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/robust_frames.py\", line 29, in \n82:     from future import standard_library\n82: ModuleNotFoundError: No module named 'future'\n82/113 Test  : PythonIntegrationTests_robust_frames ...........................***Failed    0.10 sec\ntest 83\nStart  83: PythonIntegrationTests_run_mission_help83: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/run_mission.py\" \"--help\"\n83: Environment variables:\n83:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n83:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n83: Test timeout computed to be: 1500\n83/113 Test  : PythonIntegrationTests_run_mission_help ........................***Exception: SegFault  0.45 sec\ntest 84\nStart  84: PythonIntegrationTests_run_mission84: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/run_mission.py\" \"--test\" \"--recording_dir\" \"run_mission\" \"--record_video\"\n84: Environment variables:\n84:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n84:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n84: Test timeout computed to be: 1500\n84/113 Test  : PythonIntegrationTests_run_mission .............................***Exception: SegFault  0.20 sec\ntest 85\nStart  85: PythonIntegrationTests_tabular_q_learning_help85: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/tabular_q_learning.py\" \"--help\"\n85: Environment variables:\n85:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n85:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n85: Test timeout computed to be: 1500\n85: Traceback (most recent call last):\n85:   File \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/tabular_q_learning.py\", line 27, in \n85:     from future import standard_library\n85: ModuleNotFoundError: No module named 'future'\n85/113 Test  : PythonIntegrationTests_tabular_q_learning_help .................***Failed    0.10 sec\ntest 86\nStart  86: PythonIntegrationTests_tabular_q_learning86: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/tabular_q_learning.py\" \"--test\" \"--recording_dir\" \"tabular_q_learning\" \"--record_video\"\n86: Environment variables:\n86:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n86:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n86: Test timeout computed to be: 1500\n86: Traceback (most recent call last):\n86:   File \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/tabular_q_learning.py\", line 27, in \n86:     from future import standard_library\n86: ModuleNotFoundError: No module named 'future'\n86/113 Test  : PythonIntegrationTests_tabular_q_learning ......................***Failed    0.10 sec\ntest 87\nStart  87: PythonIntegrationTests_teleport_test_help87: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/teleport_test.py\" \"--help\"\n87: Environment variables:\n87:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n87:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n87: Test timeout computed to be: 1500\n87/113 Test  : PythonIntegrationTests_teleport_test_help ......................***Exception: SegFault  0.19 sec\ntest 88\nStart  88: PythonIntegrationTests_teleport_test88: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/teleport_test.py\" \"--test\" \"--recording_dir\" \"teleport_test\" \"--record_video\"\n88: Environment variables:\n88:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n88:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n88: Test timeout computed to be: 1500\n88/113 Test  : PythonIntegrationTests_teleport_test ...........................***Exception: SegFault  0.19 sec\ntest 89\nStart  89: PythonIntegrationTests_to_string_test_help89: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/to_string_test.py\" \"--help\"\n89: Environment variables:\n89:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n89:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n89: Test timeout computed to be: 1500\n89/113 Test  : PythonIntegrationTests_to_string_test_help .....................***Exception: SegFault  0.21 sec\ntest 90\nStart  90: PythonIntegrationTests_to_string_test90: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/to_string_test.py\" \"--test\" \"--recording_dir\" \"to_string_test\" \"--record_video\"\n90: Environment variables:\n90:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n90:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n90: Test timeout computed to be: 1500\n90/113 Test  : PythonIntegrationTests_to_string_test ..........................***Exception: SegFault  0.19 sec\ntest 91\nStart  91: PreMultiAgentIntegrationTests91: Test command: /usr/bin/python3.6 \"launch_minecraft_in_background.py\" \"10001\"\n91: Environment variables:\n91:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n91: Test timeout computed to be: 1500\n91: Something is listening on port 10001 - will assume Minecraft is running.\n91/113 Test  : PreMultiAgentIntegrationTests ..................................   Passed    0.04 sec\ntest 92\nStart  92: PythonIntegrationTests_two_diggers_help92: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/two_diggers.py\" \"--help\"\n92: Environment variables:\n92:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n92:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n92: Test timeout computed to be: 1500\n92/113 Test  : PythonIntegrationTests_two_diggers_help ........................***Exception: SegFault  0.19 sec\ntest 93\nStart  93: PythonIntegrationTests_two_diggers93: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/two_diggers.py\" \"--test\" \"--recording_dir\" \"two_diggers\" \"--record_video\"\n93: Environment variables:\n93:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n93:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n93: Test timeout computed to be: 1500\n93/113 Test  : PythonIntegrationTests_two_diggers .............................***Exception: SegFault  0.19 sec\ntest 94\nStart  94: PythonIntegrationTests_team_reward_test_help94: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/team_reward_test.py\" \"--help\"\n94: Environment variables:\n94:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n94:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n94: Test timeout computed to be: 1500\n94/113 Test  : PythonIntegrationTests_team_reward_test_help ...................***Exception: SegFault  0.19 sec\ntest 95\nStart  95: PythonIntegrationTests_team_reward_test95: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/team_reward_test.py\" \"--test\" \"--recording_dir\" \"team_reward_test\" \"--record_video\"\n95: Environment variables:\n95:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n95:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n95: Test timeout computed to be: 1500\n95/113 Test  : PythonIntegrationTests_team_reward_test ........................***Exception: SegFault  0.19 sec\ntest 96\nStart  96: PythonIntegrationTests_MultiMaze_help96: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/MultiMaze.py\" \"--help\"\n96: Environment variables:\n96:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n96:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n96: Test timeout computed to be: 1500\n96: Traceback (most recent call last):\n96:   File \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/MultiMaze.py\", line 30, in \n96:     from past.utils import old_div\n96: ModuleNotFoundError: No module named 'past'\n96/113 Test  : PythonIntegrationTests_MultiMaze_help ..........................***Failed    0.10 sec\ntest 97\nStart  97: PythonIntegrationTests_MultiMaze97: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/MultiMaze.py\" \"--test\" \"--recording_dir\" \"MultiMaze\" \"--record_video\"\n97: Environment variables:\n97:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n97:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n97: Test timeout computed to be: 1500\n97: Traceback (most recent call last):\n97:   File \"/home/justin/MalmoPlatform/Malmo/samples/Python_examples/MultiMaze.py\", line 30, in \n97:     from past.utils import old_div\n97: ModuleNotFoundError: No module named 'past'\n97/113 Test  : PythonIntegrationTests_MultiMaze ...............................***Failed    0.10 sec\ntest 98\nStart  98: ValidationTests_default_world_198: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/sample_missions/validate.py\" \"/home/justin/MalmoPlatform/sample_missions/default_world_1.xml\"\n98: Environment variables:\n98:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n98:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n98:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n98: Test timeout computed to be: 1500\n98:\n98: Error: Requires the MalmoPython module to be present in the python path or the current directory.\n98:\n98/113 Test  : ValidationTests_default_world_1 ................................***Failed    0.02 sec\ntest 99\nStart  99: ValidationTests_default_flat_199: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/sample_missions/validate.py\" \"/home/justin/MalmoPlatform/sample_missions/default_flat_1.xml\"\n99: Environment variables:\n99:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n99:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n99:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n99: Test timeout computed to be: 1500\n99:\n99: Error: Requires the MalmoPython module to be present in the python path or the current directory.\n99:\n99/113 Test  : ValidationTests_default_flat_1 .................................***Failed    0.02 sec\ntest 100\nStart 100: ValidationTests_tricky_arena_1100: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/sample_missions/validate.py\" \"/home/justin/MalmoPlatform/sample_missions/tricky_arena_1.xml\"\n100: Environment variables:\n100:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n100:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n100:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n100: Test timeout computed to be: 1500\n100:\n100: Error: Requires the MalmoPython module to be present in the python path or the current directory.\n100:\n100/113 Test : ValidationTests_tricky_arena_1 .................................***Failed    0.02 sec\ntest 101\nStart 101: ValidationTests_eating_1101: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/sample_missions/validate.py\" \"/home/justin/MalmoPlatform/sample_missions/eating_1.xml\"\n101: Environment variables:\n101:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n101:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n101:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n101: Test timeout computed to be: 1500\n101:\n101: Error: Requires the MalmoPython module to be present in the python path or the current directory.\n101:\n101/113 Test : ValidationTests_eating_1 .......................................***Failed    0.03 sec\ntest 102\nStart 102: ValidationTests_cliff_walking_1102: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/sample_missions/validate.py\" \"/home/justin/MalmoPlatform/sample_missions/cliff_walking_1.xml\"\n102: Environment variables:\n102:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n102:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n102:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n102: Test timeout computed to be: 1500\n102:\n102: Error: Requires the MalmoPython module to be present in the python path or the current directory.\n102:\n102/113 Test : ValidationTests_cliff_walking_1 ................................***Failed    0.02 sec\ntest 103\nStart 103: ValidationTests_maze_1103: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/sample_missions/validate.py\" \"/home/justin/MalmoPlatform/sample_missions/mazes/maze_1.xml\"\n103: Environment variables:\n103:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n103:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n103:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n103: Test timeout computed to be: 1500\n103:\n103: Error: Requires the MalmoPython module to be present in the python path or the current directory.\n103:\n103/113 Test : ValidationTests_maze_1 .........................................***Failed    0.03 sec\ntest 104\nStart 104: ValidationTests_maze_2104: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/sample_missions/validate.py\" \"/home/justin/MalmoPlatform/sample_missions/mazes/maze_2.xml\"\n104: Environment variables:\n104:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n104:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n104:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n104: Test timeout computed to be: 1500\n104:\n104: Error: Requires the MalmoPython module to be present in the python path or the current directory.\n104:\n104/113 Test : ValidationTests_maze_2 .........................................***Failed    0.02 sec\ntest 105\nStart 105: ValidationTests_basic105: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/sample_missions/validate.py\" \"/home/justin/MalmoPlatform/sample_missions/classroom/basic.xml\"\n105: Environment variables:\n105:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n105:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n105:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n105: Test timeout computed to be: 1500\n105:\n105: Error: Requires the MalmoPython module to be present in the python path or the current directory.\n105:\n105/113 Test : ValidationTests_basic ..........................................***Failed    0.02 sec\ntest 106\nStart 106: ValidationTests_obstacles106: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/sample_missions/validate.py\" \"/home/justin/MalmoPlatform/sample_missions/classroom/obstacles.xml\"\n106: Environment variables:\n106:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n106:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n106:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n106: Test timeout computed to be: 1500\n106:\n106: Error: Requires the MalmoPython module to be present in the python path or the current directory.\n106:\n106/113 Test : ValidationTests_obstacles ......................................***Failed    0.02 sec\ntest 107\nStart 107: ValidationTests_simpleRoomMaze107: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/sample_missions/validate.py\" \"/home/justin/MalmoPlatform/sample_missions/classroom/simpleRoomMaze.xml\"\n107: Environment variables:\n107:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n107:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n107:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n107: Test timeout computed to be: 1500\n107:\n107: Error: Requires the MalmoPython module to be present in the python path or the current directory.\n107:\n107/113 Test : ValidationTests_simpleRoomMaze .................................***Failed    0.02 sec\ntest 108\nStart 108: ValidationTests_attic108: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/sample_missions/validate.py\" \"/home/justin/MalmoPlatform/sample_missions/classroom/attic.xml\"\n108: Environment variables:\n108:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n108:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n108:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n108: Test timeout computed to be: 1500\n108:\n108: Error: Requires the MalmoPython module to be present in the python path or the current directory.\n108:\n108/113 Test : ValidationTests_attic ..........................................***Failed    0.02 sec\ntest 109\nStart 109: ValidationTests_vertical109: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/sample_missions/validate.py\" \"/home/justin/MalmoPlatform/sample_missions/classroom/vertical.xml\"\n109: Environment variables:\n109:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n109:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n109:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n109: Test timeout computed to be: 1500\n109:\n109: Error: Requires the MalmoPython module to be present in the python path or the current directory.\n109:\n109/113 Test : ValidationTests_vertical .......................................***Failed    0.03 sec\ntest 110\nStart 110: ValidationTests_complexity_usage110: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/sample_missions/validate.py\" \"/home/justin/MalmoPlatform/sample_missions/classroom/complexity_usage.xml\"\n110: Environment variables:\n110:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n110:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n110:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n110: Test timeout computed to be: 1500\n110:\n110: Error: Requires the MalmoPython module to be present in the python path or the current directory.\n110:\n110/113 Test : ValidationTests_complexity_usage ...............................***Failed    0.03 sec\ntest 111\nStart 111: ValidationTests_medium111: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/sample_missions/validate.py\" \"/home/justin/MalmoPlatform/sample_missions/classroom/medium.xml\"\n111: Environment variables:\n111:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n111:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n111:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n111: Test timeout computed to be: 1500\n111:\n111: Error: Requires the MalmoPython module to be present in the python path or the current directory.\n111:\n111/113 Test : ValidationTests_medium .........................................***Failed    0.02 sec\ntest 112\nStart 112: ValidationTests_hard112: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/sample_missions/validate.py\" \"/home/justin/MalmoPlatform/sample_missions/classroom/hard.xml\"\n112: Environment variables:\n112:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n112:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n112:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n112: Test timeout computed to be: 1500\n112:\n112: Error: Requires the MalmoPython module to be present in the python path or the current directory.\n112:\n112/113 Test : ValidationTests_hard ...........................................***Failed    0.03 sec\ntest 113\nStart 113: ValidationTests_tutorial_6113: Test command: /usr/bin/python3.6 \"/home/justin/MalmoPlatform/sample_missions/validate.py\" \"/home/justin/MalmoPlatform/sample_missions/../Malmo/samples/Python_examples/tutorial_6.xml\"\n113: Environment variables:\n113:  PYTHONPATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n113:  LD_LIBRARY_PATH=/home/justin/MalmoPlatform/build/Malmo/src/PythonWrapper\n113:  MALMO_XSD_PATH=/home/justin/MalmoPlatform/Schemas\n113: Test timeout computed to be: 1500\n113:\n113: Error: Requires the MalmoPython module to be present in the python path or the current directory.\n113:\n113/113 Test : ValidationTests_tutorial_6 .....................................***Failed    0.02 sec11% tests passed, 101 tests failed out of 113Total Test time (real) = 153.06 secThe following tests FAILED:\n7 - CppTests_test_persistence (Failed)\n8 - CppTests_test_string_server (Child aborted)\n11 - JavaTests_test_agent_host (Failed)\n12 - JavaTests_test_argument_parser (Failed)\n13 - JavaTests_test_mission (Failed)\n14 - JavaTests_test_parameter_set (Failed)\n15 - JavaTests_test_wrapping (Failed)\n16 - PythonTests_test_wrapping (SEGFAULT)\n17 - PythonTests_test_argument_parser (SEGFAULT)\n18 - PythonTests_test_agent_host (SEGFAULT)\n19 - PythonTests_test_mission (SEGFAULT)\n20 - PythonTests_test_parameter_set (SEGFAULT)\n21 - PythonTests_test_malmoutils (SEGFAULT)\n25 - JavaIntegrationTests_JavaExamples_run_mission_help (Failed)\n26 - JavaIntegrationTests_JavaExamples_run_mission (Failed)\n27 - PythonIntegrationTests_animation_test_help (SEGFAULT)\n28 - PythonIntegrationTests_animation_test (SEGFAULT)\n29 - PythonIntegrationTests_braitenberg_simulation_help (SEGFAULT)\n30 - PythonIntegrationTests_braitenberg_simulation (SEGFAULT)\n31 - PythonIntegrationTests_build_test_help (Failed)\n32 - PythonIntegrationTests_build_test (Failed)\n33 - PythonIntegrationTests_chat_reward_help (SEGFAULT)\n34 - PythonIntegrationTests_chat_reward (SEGFAULT)\n35 - PythonIntegrationTests_chunk_test_help (Failed)\n36 - PythonIntegrationTests_chunk_test (Failed)\n37 - PythonIntegrationTests_craft_work_help (SEGFAULT)\n38 - PythonIntegrationTests_craft_work (SEGFAULT)\n39 - PythonIntegrationTests_decision_tree_test_help (Failed)\n40 - PythonIntegrationTests_decision_tree_test (Failed)\n41 - PythonIntegrationTests_default_world_test_help (SEGFAULT)\n42 - PythonIntegrationTests_default_world_test (SEGFAULT)\n43 - PythonIntegrationTests_depth_map_runner_help (Failed)\n44 - PythonIntegrationTests_depth_map_runner (Failed)\n45 - PythonIntegrationTests_discrete_3d_test_help (Failed)\n46 - PythonIntegrationTests_discrete_3d_test (Failed)\n47 - PythonIntegrationTests_drawing_test_help (Failed)\n48 - PythonIntegrationTests_drawing_test (Failed)\n49 - PythonIntegrationTests_file_test_help (SEGFAULT)\n50 - PythonIntegrationTests_file_test (SEGFAULT)\n51 - PythonIntegrationTests_hit_test_help (Failed)\n52 - PythonIntegrationTests_hit_test (Failed)\n53 - PythonIntegrationTests_inventory_test_help (Failed)\n54 - PythonIntegrationTests_inventory_test (Failed)\n55 - PythonIntegrationTests_MazeRunner_help (SEGFAULT)\n56 - PythonIntegrationTests_MazeRunner (SEGFAULT)\n57 - PythonIntegrationTests_mission_quit_command_example_help (SEGFAULT)\n58 - PythonIntegrationTests_mission_quit_command_example (SEGFAULT)\n59 - PythonIntegrationTests_mob_fun_help (Failed)\n60 - PythonIntegrationTests_mob_fun (Failed)\n61 - PythonIntegrationTests_mouse_steering_test_help (SEGFAULT)\n62 - PythonIntegrationTests_mouse_steering_test (SEGFAULT)\n63 - PythonIntegrationTests_moving_target_test_help (SEGFAULT)\n64 - PythonIntegrationTests_moving_target_test (SEGFAULT)\n65 - PythonIntegrationTests_overclock_test_help (Failed)\n66 - PythonIntegrationTests_overclock_test (Failed)\n67 - PythonIntegrationTests_patchwork_quilt_help (Failed)\n68 - PythonIntegrationTests_patchwork_quilt (Failed)\n69 - PythonIntegrationTests_quit_from_reaching_position_test_help (SEGFAULT)\n70 - PythonIntegrationTests_quit_from_reaching_position_test (SEGFAULT)\n71 - PythonIntegrationTests_radar_test_help (Failed)\n72 - PythonIntegrationTests_radar_test (Failed)\n73 - PythonIntegrationTests_render_speed_test_help (Failed)\n74 - PythonIntegrationTests_render_speed_test (Failed)\n75 - PythonIntegrationTests_reward_for_discarding_items_test_help (SEGFAULT)\n76 - PythonIntegrationTests_reward_for_discarding_items_test (SEGFAULT)\n77 - PythonIntegrationTests_reward_for_items_test_help (SEGFAULT)\n78 - PythonIntegrationTests_reward_for_items_test (SEGFAULT)\n79 - PythonIntegrationTests_reward_for_mission_end_test_help (SEGFAULT)\n80 - PythonIntegrationTests_reward_for_mission_end_test (SEGFAULT)\n81 - PythonIntegrationTests_robust_frames_help (Failed)\n82 - PythonIntegrationTests_robust_frames (Failed)\n83 - PythonIntegrationTests_run_mission_help (SEGFAULT)\n84 - PythonIntegrationTests_run_mission (SEGFAULT)\n85 - PythonIntegrationTests_tabular_q_learning_help (Failed)\n86 - PythonIntegrationTests_tabular_q_learning (Failed)\n87 - PythonIntegrationTests_teleport_test_help (SEGFAULT)\n88 - PythonIntegrationTests_teleport_test (SEGFAULT)\n89 - PythonIntegrationTests_to_string_test_help (SEGFAULT)\n90 - PythonIntegrationTests_to_string_test (SEGFAULT)\n92 - PythonIntegrationTests_two_diggers_help (SEGFAULT)\n93 - PythonIntegrationTests_two_diggers (SEGFAULT)\n94 - PythonIntegrationTests_team_reward_test_help (SEGFAULT)\n95 - PythonIntegrationTests_team_reward_test (SEGFAULT)\n96 - PythonIntegrationTests_MultiMaze_help (Failed)\n97 - PythonIntegrationTests_MultiMaze (Failed)\n98 - ValidationTests_default_world_1 (Failed)\n99 - ValidationTests_default_flat_1 (Failed)\n100 - ValidationTests_tricky_arena_1 (Failed)\n101 - ValidationTests_eating_1 (Failed)\n102 - ValidationTests_cliff_walking_1 (Failed)\n103 - ValidationTests_maze_1 (Failed)\n104 - ValidationTests_maze_2 (Failed)\n105 - ValidationTests_basic (Failed)\n106 - ValidationTests_obstacles (Failed)\n107 - ValidationTests_simpleRoomMaze (Failed)\n108 - ValidationTests_attic (Failed)\n109 - ValidationTests_vertical (Failed)\n110 - ValidationTests_complexity_usage (Failed)\n111 - ValidationTests_medium (Failed)\n112 - ValidationTests_hard (Failed)\n113 - ValidationTests_tutorial_6 (Failed)\nErrors while running CTestI am not sure if this output reveals anything useful, but it seems to show a problem with the current PYTHONPATH. If that is the issue, I am wondering what I should set the PYTHONPATH to be.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "DarthMalloc",
            "datetime": "Mar 9, 2020",
            "body": "Could someone please respond to my latest post? I really need to get this resolved.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "DarthMalloc",
            "datetime": "Mar 10, 2020",
            "body": "I have an update from yesterday. I was successful in running the compiled C++ implementation of the run_mission example, but I am still unable to run any of the Python examples. Based on the results of the Ctest command, it looks like the problem has something to do with Python integration. I am comfortable proceeding in C++ if necessary, although Python would be preferable, so I would therefore really appreciate if someone would be willing to guide me in addressing the Python integration problem.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "satyamedh",
            "datetime": "Jun 8, 2020",
            "body": " , Forge provides a development version on Minecraft. Which does not include any multiplayer code. Because If you can do that, there will be no reason to buy the game. Thus I suggest you to build the mod using  and copy it into your Minecraft mods dir. then launch Minecraft 1.11.2 with forge from Minecraft launcher",
            "type": "commented",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/photoprism/photoprism/issues/2103",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "Alestrix",
            "datetime": "Mar 3, 2022",
            "body": "On \"small\" screens (in my case Amazon Silk browser on 4k screen, but apparently rendered for better readability at far distance), the navigation menu on the left side is not fully displayed with no way to scroll down, as there is no scroll bar displayed.I found a similar topic  but this is not the same issue.You can reproduce the behavior on a regular browser if you increase browser zoom to a value that causes the navigation pane to become longer than the screen's height. In this case there is no way to reach the hidden areas of the navigation unless you have a scroll wheel on your mouse, which is not the case for all devices.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Mar 3, 2022",
            "body": "You have no mouse wheel, touch screen, or touch pad available? Firefox would display a scrollbar.We should eventually provide a special UI for TVs. Also other issues with those browsers.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Alestrix",
            "datetime": "Mar 3, 2022",
            "body": "Thanks, I'll see whether I can get Firefox working on that device.PS: yes, no wheel or touch available on that device\nPPS: Is there a GitHub issue for the TV interface? As there's another problem I stumbled across when using Photoprism on the TV which I would add as a comment there, which is: no RETURN key on TV, so after a search term is entered, there is no way to start that search.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Mar 6, 2022",
            "body": "I thought we have an issue for a TV-friendly UI already, but found only these:Turned this issue into an idea that we can put it on our roadmap as soon as we have the resources.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bm55",
            "datetime": "Jun 30, 2022",
            "body": "How about casting to another browser running PhotoPrism similar to how Jellyfin casting works. For example - if you have a laptop or another low powered device with browser connected to TV and PhotoPrism is opened then use your phone to cast and control the browser connected to TV?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Alestrix",
            "datetime": "Mar 3, 2022",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Mar 6, 2022",
            "body": [],
            "type": "changed the title",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Mar 6, 2022",
            "body": [],
            "type": "added",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/photoprism/photoprism/issues/1409",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "rosscullen",
            "datetime": "Jul 4, 2021",
            "body": "Just installed today and really impressed so far. I'm a traditional user with a 'folders and files' style workflow.Would be great to see a back button on the menu bar (I've mocked up an example below)Could also be used in other areas. I got the idea off the Home Assistant project where it works very well on it. Hopefully other users feel similarly and the idea hasn't already been suggested. Thanks and keep up the great work :-)",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Jul 5, 2021",
            "body": "Any reason you don't use the standard browser back button?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "rosscullen",
            "datetime": "Jul 5, 2021",
            "body": "Thats a fair and valid question...\nPersonally, I think over time I have lost trust with the browser back button. eCommerce forms... eBanking... a lot of the time you loose your search results or page takes longer to re-render etc.\n*\nI've noticed on the readme that one of the \"Key Features\" of Photoprism is that the system \"is built as a progressive web app\"... If someone is using it as a PWA, where's the browser back button?I'm no UX expert/researcher but I have generally found with web applications, the navigation is contained within the application area (particularly if you're using a browser in kiosk mode or similar). And it is quicker than dragging your mouse all the way up to the top left hand corner of the screen. By having your own back button, there may also be an opportunity to used a cached version of the previous page... but I don't know enough to understand the 'behind the scenes' of the core similarities/differences.Which also brings up another question... would you consider using breadcrumbs to navigate folders/sub-folders? Similar to $ynology Photos.Lastly, when you open a photo, would you consider centering the buttons that currently are in the top right (and a back button like $ynology Photos).Appreciate you taking the time to consider my suggestions, really impressed what you have achieved to date... well done",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "graciousgrey",
            "datetime": "Jul 6, 2021",
            "body": "That's a valid point. Using touch gestures could be an option as well.We already have breadcrumbs in Originals (see  ) That's the only section with subfolders.We plan to build our own optimized photo viewer: .",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "rosscullen",
            "datetime": "Jul 7, 2021",
            "body": "Thanks for updates 👍🏻",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "graciousgrey",
            "datetime": "Jul 5, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "graciousgrey",
            "datetime": "Nov 2, 2021",
            "body": [],
            "type": "changed the title",
            "related_issue": null
        },
        {
            "user_name": "graciousgrey",
            "datetime": "Nov 2, 2021",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Nov 16, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/photoprism/photoprism/issues/1865",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "joachimtingvold",
            "datetime": "Dec 31, 2021",
            "body": "When searching for people to assign a face, the list could maybe be sorted/prioritized based on different metadata. Right now, the list is long if you have many persons, and it's tedious to write the whole name, or scroll through the list with mouse/keyboard.Not sure if all of these would be sensible in terms of performance. Also not sure of the prioritization of these.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Jan 1, 2022",
            "body": "Tried that, but turned out to be confusing.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "joachimtingvold",
            "datetime": "Jan 1, 2022",
            "body": "Maybe make it configureable/user preference, then? I guess it's somewhat personal taste to some degree. And I guess some of them makes more sense than others.You usually refer to people by given name or surname, not something \"in the middle\". Alas, searching from the start of given name and/or surname would make more sense than the current search.As an example, search for \"foo\" should sort like this (where first part is given name, and last part is surname):... which is currently not the case (regardless of all the other metadata). Not sure if that's just my opinion, though.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "graciousgrey",
            "datetime": "Jan 1, 2022",
            "body": "I agree sorting can be improved but we need to do more research to find a solution that is not confusing.We are currently focusing on multi-user support.Let's keep this issue open to hear more opinions :)",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "srett",
            "datetime": "Jan 1, 2022",
            "body": "DigiKam bumps the last 10 (or so) people you assigned to a marker to the top of the list and prints them in bold, and likewise, when typing part of a name, those same 10 people, if matching, are displayed at the top, again in bold. It's rather primitive but still effective, and probably less confusing than adding a bunch of magic and heuristics.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "joachimtingvold",
            "datetime": "Jan 1, 2022",
            "body": "I have not used DigiKam, but I guess it somewhat depends on the context you are assigning them from? (cluster, album, image, etc).If you are browsing an album, people assigned to other photos in the same album would be most likely to reappear. If you are going through photos already assigned to a person (to verify and/or assign other people in those photos), you can suddenly span albums/events/years/whatnot, where \"last used\" might not make much sense?Maybe I'm overthinking this :D",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "srett",
            "datetime": "Jan 1, 2022",
            "body": "I'd optimize for the common case, which is (assuming you finished your initial import) adding new photos every now and then, which will be mostly from one or a few events, with recurring people.\nBut even in the scenario you describe, you will most likely go through the pictures of that person in chronological order, so if you fix assignments, it's probably the same few people again, e.g. Bob got confused with Bill a couple times at Jane's wedding, then the next time Bob appears in your collection is some trip in the Alps, where he got tagged as John a few times, and so on.\nFrom my experience I can say it works well enough to be convenient and not get in your way.I don't think it's worth it adding 5 different heuristics for suggestions plus a config dialog, or even trying to pick the right one automatically (and getting it wrong sometimes for maximum confusion).",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "joachimtingvold",
            "datetime": "Jan 1, 2022",
            "body": "I don't disagree, but the \"initial import\" can be a big pain depending on the size. I'm migrating to PP from a self-made image system, and I have about 70k+ pictures that are sorted into albums, and probably equally many unsorted. I'm a few days into importing them into PP now. and my wrists are not happy with me at all. Mostly due to the bad/non-optimal workflow of assigning persons to faces/photos (but also some other workflows).I'm not complaining, and I know we're very early in the whole facial recognition implementation, but yeah.I don't necessarily mean that we should implement all 5 heuristics (and there might be other ones that is more suitable, like the one you suggested), but we should at least improve the current search significantly. I have only scratched the surface of my import, and I already have 300+ people (and only about 30-40k of my 120k+ images imported). Maybe I'm an outlier, but that shouldn't be an excuse to improve on things.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "IeuanK",
            "datetime": "May 7, 2022",
            "body": "As per my now-closed issue , I think it would be ideal to sort primarily by AI confidence.\nGiven that this issue has other ideas, it would be neat to make it configurable; have an option to store confidence levels for all people/faces and some options for which factors you want to use when sorting the dropdown?I really hope this gets added at some point because it would make fixing faces a lot less of a pain.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Sohalt",
            "datetime": "Jul 30, 2022",
            "body": "I very much agree that complicated heuristics can be too confusing, but the suggestion in  is very simple and a huge improvement over the current state imho (highest priority for exact match, then prefix match, then prefix of subword (e.g. surname), then any other substring match).\nIf I try to search for \"Maria\", it's extremely annoying to have \"Alma\" show up first when typing \"Ma\".",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "joachimtingvold",
            "datetime": "Dec 31, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": null,
            "datetime": [],
            "body": [],
            "type": "",
            "related_issue": "#1552"
        },
        {
            "user_name": "graciousgrey",
            "datetime": "Jan 1, 2022",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "graciousgrey",
            "datetime": "Jan 1, 2022",
            "body": [],
            "type": "changed the title",
            "related_issue": null
        },
        {
            "user_name": "graciousgrey",
            "datetime": "May 7, 2022",
            "body": [],
            "type": "issue",
            "related_issue": "#2305"
        }
    ]
},
{
    "issue_url": "https://github.com/photoprism/photoprism/issues/1633",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "Pheggas",
            "datetime": "Oct 17, 2021",
            "body": "Hello. So i found this bug/weird behaviour. As user i'd like to copy the photo (usually by right clicking on PC) and send it to 3rd party service like Facebook Messenger to share some of my photos with other people. But when i right click, the photo UI just closes and throws me back to the gallery.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Oct 17, 2021",
            "body": "Works for me. How did you do that? What operating system & browser version?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Oct 25, 2021",
            "body": "We need more information to reproduce this:",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Oct 25, 2021",
            "body": "Works on  using Google Chrome on macOS:",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Pheggas",
            "datetime": "Oct 27, 2021",
            "body": "Good to knowIt may be caused by it's version tho. As i didn't update photoprism in a while, i have version 210523-b1856b9d-Linux-x86_64",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Oct 27, 2021",
            "body": "Wouldn't know why, but testing the same version wouldn't hurt either Can up update the image to see if it's fixed?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Pheggas",
            "datetime": "Oct 27, 2021",
            "body": "No prob. I'll do it as soon as i'll have more time",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Pheggas",
            "datetime": "Nov 13, 2021",
            "body": "Update: So i get into it, re-pulled image and re-build it. Now i have latest  image and it still does the same thing. Even if i switch browsers. Basically all the points i write above applies to the latest version.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Nov 13, 2021",
            "body": "Strange, still working for me. Any special input devices or drivers in place that might change the event that is fired? From what I remember having read the code years ago, it won't fire if a mobile device is detected to avoid issues with touch gestures.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Nov 13, 2021",
            "body": "Think it's because either iOS or Android use contextmenu to signal \"long touch\". Click is fired for a \"short touch\". The click duration may also play a role on desktop computers, it's worth testing at least. I know we have long click implemented in our search result views (list, mosaic, cards).",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Pheggas",
            "datetime": "Nov 13, 2021",
            "body": "Yeah. I mean, on my main PC. I tried same thing on older PC with no additional input devices attached. Same thing.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Pheggas",
            "datetime": "Nov 13, 2021",
            "body": "Might be. Definitely worth a try of deleting that chunk of code for the test build.What i actually found out is, this doesn't happen on the demo site of PhotoPrism. Or, that I thought. Then I realized this issue only happens on 16:9 aspect ratio photos in landscape mode. On the other hand, in portrait mode with 9:16 aspect ratio, right click only zooms in the photo which is the expected result i think.So the next step would be upload test photo on demo site of PhotoPrism with variables that I described above and see what happen.\nIn case it wouldn't show this issue, I would upload one of my photos from my personal gallery where I'm 100% sure it have this issue.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Nov 14, 2021",
            "body": "Could it depend on the original or thumbnail pixel size? Context menu may be somehow coupled with the zoom function. Would be great if you can check the PhotoSwipe issue tracker for related problems Does your server use default thumb settings or did you change anything?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Pheggas",
            "datetime": "Nov 14, 2021",
            "body": "According to my settings, I'm pretty sure those are default ones.\n",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Pheggas",
            "datetime": "Nov 15, 2021",
            "body": "I was able to replicate the issue inside your demo instance of Photoprism. In , you can see two photos. One of which is from my personal gallery and the second one (with the lake thing), is from net. Both of these are 16:9 aspect ratio images and each have different resolutin.This fact can approve my theory.If the aspect ratio equals 16:9, you  face this issue.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "graciousgrey",
            "datetime": "Oct 18, 2021",
            "body": [],
            "type": "added",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Oct 25, 2021",
            "body": [],
            "type": "changed the title",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Nov 13, 2021",
            "body": [],
            "type": "added",
            "related_issue": null
        },
        {
            "user_name": "Pheggas",
            "datetime": "Nov 15, 2021",
            "body": [],
            "type": "changed the title",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/photoprism/photoprism/issues/1307",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "graciousgrey",
            "datetime": "May 20, 2021",
            "body": "At the moment we use photoswipe as photo viewer. As there are some limitations we plan to implement one on our own.The new photo viewer should solve the following issues:",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "jucor",
            "datetime": "Jun 16, 2021",
            "body": "Is there any worth to \"just\" build an interface on top of Photoswipe rather than rewriting the whole viewer?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Jun 20, 2021",
            "body": "Well, it's architecture is not really extensible. It would all be ugly workarounds. Already did that in large parts, but need to make a cut somewhere.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "jucor",
            "datetime": "Jun 20, 2021",
            "body": "",
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "tribut",
            "datetime": "Aug 12, 2021",
            "body": "When this gets implemented, I would really appreciate some sidebar/overlay for media information. Having to go to the edit view just to look up the file name or assigned tags is cumbersome.Screenshots from librephotos and lychee, to make it clear what I'm looking for:\n",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "RandomHacks-Git",
            "datetime": "Aug 14, 2021",
            "body": "I was going to open an issue but I guess the solution would be implemented as part of this new photo viewer.\nAfter briefly testing photoprism I'm currently using another solution for the sole reason that there is no easy way to skip to the next video (or go back to the previous) inside the lightbox, always having to exit the lightbox and open the next video is quite cumbersome and not very intuitive.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "graciousgrey",
            "datetime": "Aug 15, 2021",
            "body": " Yes, that is one of the main reasons why we need to build our own photo viewer :)",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "aravindhsampath",
            "datetime": "Aug 20, 2021",
            "body": "I am here from the context of  work. It would be wonderful if the new photo viewer considers to implement an UI wherein the photo shows tags/labels associated with it visually like how Facebook photos with people. It may be triggered upon mouse hover in the area, or a button on the top that says\"labels\" or \"tags\" may be clicked to show this info.When manual tagging of people gets implemented in Photoprism, it would be very useful to see \"who all appear in this photo\". Perhaps, also adding the ability to manually tag people right there while viewing the photo.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "issuehunt-app",
            "datetime": "Sep 26, 2021",
            "body": " has funded $10.00 to this issue.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "issuehunt-app",
            "datetime": "Oct 5, 2021",
            "body": "An anonymous user has funded $20.00 to this issue.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "issuehunt-app",
            "datetime": "Oct 19, 2021",
            "body": " has funded $10.00 to this issue.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "IssueHuntBot",
            "datetime": "Dec 27, 2021",
            "body": "An anonymous user has funded $50.00 to this issue.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Dec 28, 2021",
            "body": "Please don't add funds to IssueHunt anymore! While we like IssueHunt and are grateful for the donations we've received so far, it hasn't proven to be a sustainable funding option for us as we spend much of our time maintaining existing features and providing support.If we don't have enough resources to provide support and bugfixes, we can't start working on new features.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "theseraphim",
            "datetime": "Jan 2, 2022",
            "body": "Deep zoom on touchscreens is ok but theres a limit to how far it will zoom before it gets... \"bouncy\" not sure if this is related to dynamic preview size or static preview size (i did raise an issue with having static image size too high causing thumbnail duplication) or some other feature, but id like to be able to zoom to at least 400% of full resolution.I wonder if a small interim fix would be a toggle for \"full resolution\" where instead of loading the fit_xxxx resolution it just forces the original to load within photoswipe?should be possible if you use pwsp.currItem.src (which i think is what is powering the download button) but that might just require the image be opened in a new tab and use the browsers built in image viewer... im not sure if thats better or not.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "joachimtingvold",
            "datetime": "Jan 4, 2022",
            "body": "One other aspect, which I'm not sure is directly related to the current constraints with photo viewer, would be to scroll down to current picture when exiting full sized view.As an example; if you search for something, click on the first picture, and start viewing in full sized view. You look at 147 photos. When exiting full sized view, it'd be nice if you got back to the thumbnail overview being scrolled down to show the 147th photo (so you have the context).Usecase would for example be if you wanted to add certain photos to an album, you would search, browse until you find the correct context, exit viewer, and select the photos before/after, and add to album.Not sure if this warrants it's own issue, as it's most likely not strictly related to the restrictions of the current photo viewer?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "GlassedSilver",
            "datetime": "Apr 9, 2022",
            "body": "Is a revamp of how Live Photos (and similar media kinds by the other OEMs) are presented on the table with this rework as well?Having to click a button to play the Live Photo, for it to load a video player frame and it not being the exact same size as the photo is cumbersome and not very elegant.You'll ask me how to implement it then, and I say: the UX/UI can be referenced in Apple Photos.The UI of it for this media kind is spot on. (not to anyone's surprise I guess, but any deviation from it really feels odd)",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "graciousgrey",
            "datetime": "May 20, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": null,
            "datetime": [],
            "body": [],
            "type": "issue",
            "related_issue": "#508"
        },
        {
            "user_name": "graciousgrey",
            "datetime": "Jun 16, 2021",
            "body": [],
            "type": "issue",
            "related_issue": "#1379"
        },
        {
            "user_name": "graciousgrey",
            "datetime": "Jul 6, 2021",
            "body": [],
            "type": "issue",
            "related_issue": "#1409"
        },
        {
            "user_name": "graciousgrey",
            "datetime": "Aug 19, 2021",
            "body": [],
            "type": "issue",
            "related_issue": "#22"
        },
        {
            "user_name": "graciousgrey",
            "datetime": "Sep 24, 2021",
            "body": [],
            "type": "issue",
            "related_issue": "#1548"
        },
        {
            "user_name": "graciousgrey",
            "datetime": "Sep 26, 2021",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "issuehunt-app",
            "datetime": "Sep 26, 2021",
            "body": [],
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "aravindhsampath",
            "datetime": "Sep 30, 2021",
            "body": [],
            "type": "issue",
            "related_issue": "#1573"
        },
        {
            "user_name": "graciousgrey",
            "datetime": "Oct 2, 2021",
            "body": [],
            "type": "issue",
            "related_issue": "#1581"
        },
        {
            "user_name": "graciousgrey",
            "datetime": "Oct 18, 2021",
            "body": [],
            "type": "issue",
            "related_issue": "#1498"
        },
        {
            "user_name": "lastzero",
            "datetime": "Oct 30, 2021",
            "body": [],
            "type": "issue",
            "related_issue": "#1687"
        },
        {
            "user_name": "lastzero",
            "datetime": "Nov 1, 2021",
            "body": [],
            "type": "removed  the",
            "related_issue": null
        },
        {
            "user_name": null,
            "datetime": [],
            "body": [],
            "type": "",
            "related_issue": "#1050"
        },
        {
            "user_name": "graciousgrey",
            "datetime": "Nov 3, 2021",
            "body": [],
            "type": "issue",
            "related_issue": "#247"
        },
        {
            "user_name": "lastzero",
            "datetime": "Nov 16, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "isleshocky77",
            "datetime": "Jan 4, 2022",
            "body": [],
            "type": "issue",
            "related_issue": "#373"
        },
        {
            "user_name": "graciousgrey",
            "datetime": "Feb 7, 2022",
            "body": [],
            "type": "issue",
            "related_issue": "#2016"
        },
        {
            "user_name": "lastzero",
            "datetime": "Mar 31, 2022",
            "body": [],
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Mar 31, 2022",
            "body": [],
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Apr 5, 2022",
            "body": [],
            "type": "issue",
            "related_issue": "#2223"
        },
        {
            "user_name": "graciousgrey",
            "datetime": "May 21, 2022",
            "body": [],
            "type": "issue",
            "related_issue": "#2325"
        },
        {
            "user_name": null,
            "datetime": [],
            "body": [],
            "type": "",
            "related_issue": "#2292"
        },
        {
            "user_name": "graciousgrey",
            "datetime": "Jul 22, 2022",
            "body": [],
            "type": "issue",
            "related_issue": "#2539"
        },
        {
            "user_name": "ark-",
            "datetime": "Aug 2, 2022",
            "body": [],
            "type": "issue",
            "related_issue": "#2571"
        }
    ]
},
{
    "issue_url": "https://github.com/photoprism/photoprism/issues/1241",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "electricpollution",
            "datetime": "Apr 28, 2021",
            "body": "Video thumbnails are currently created from the first frame hardcoded with the code  Any video that has a black first frame or anything not meaningful is not useful for previews.Suggest defaulting to the first frame or having a parameter to customize how many seconds  into the video a preview is created.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "graciousgrey",
            "datetime": "Apr 28, 2021",
            "body": "Related discussion: ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "issuehunt-app",
            "datetime": "Apr 28, 2021",
            "body": " has funded $5.00 to this issue.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "G2G2G2G",
            "datetime": "Jun 3, 2021",
            "body": "Get video full length:\nGet video black bars and remove them. Useful if someone has.. black bars encoded into the video. (python running a bash script 10 times and averaging it, so in Go you'd just do the same thing):This \"croplist\" should work directly into ffmpeg as  (including the quotes)\nNote my 00:\" + times + \":00 uses a random int 3-59 (cuz I use this for stripping out black bars in legal videos I acquire) but for you guys, you'd need to use the time you get in the previous FFPROBE command (first one I posted)\nYou can also run this for a set amount of time:\n\nHowever it does not work well for dark movies / videos. Some scenes are very dark and some are bright. SO I found randomly skipping around the video and looking at a frame is far better.\nI've also been doing this for over a decade so it is well tested.Last all that is needed is to pick a random time from 0 to the end of the original \"duration\" of the video.Looks like what  guy linked they were already looking at a thumbnailer program though. That is a good project it's used in almost all of the linux file managers. I know he said he was trying to not use C++ stuff though so my above implementations you can cut out black bars + get full duration + pick a random timestamp to make a thumbnail out of while only calling FFMPEG. you can replace AWK with something in Go to parse the output instead.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "G2G2G2G",
            "datetime": "Jun 3, 2021",
            "body": "Actually ignore that crap above you can extract ACTION frames (frames that have pixel movement, thus not black!) purely in ffmpeg\nThis is all you need for every video:\nthe magic is here:  this is generous here, a video file that does not have a lot of pixel shifts is going to get a thumbnail here. However the thumbnail may be in the beginning of the video and not a very good thumbnail.\nIf you want a great thumbnail, maybe make this a setting so people can say \"yes I want better thumbnails\" or whatever.\nBut you check less generously and if it fails, have a fallback to a more generous check, like this:or something like that, this is what I'd personally do. However that is the only command you need. You can copy paste the above command and replace your thumbnail right now and it'll already work better!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Jun 3, 2021",
            "body": " Any idea what the performance impact might be, if any?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "G2G2G2G",
            "datetime": "Jun 3, 2021",
            "body": " how fast is it now? I tested on a \"hollywood movie\" the 0.1 and 0.2 are almost instant\nAll of my videos are h264 as well so it's very fast decode. and it is ryzen 3700X processor.\nVideo is 1280x720 resolution too so pretty fast.From my test I think yours (for me) would be around \"902.35 millis\" and vs the 0.2 which is \"1.02 secs\" I think that's well worth it.\n(assuming millis in the linux time command is milliseconds so 902 is almost 1 second, so they basically take the same time)For me, personally, 0.8 is worth it taking 4 seconds to process the frame it finds is only like 20 seconds into the video.. So if you have like a long video and it never finds one with a lot of pixels changing then it's gonna take a LONG time since it'd go through the whole video and fail.. and then try a lower number.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "G2G2G2G",
            "datetime": "Jun 3, 2021",
            "body": "Technically there's no guarantee that even a 0.1 threshold would work if your video is extremely dark / black almost the entire thing. Somewhere I have videos of us exploring a cave that are terrible videos, if I can find them I'll test it but I guess we need a fallback to just grab the first frame as you do now, in the very worst case?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Jun 4, 2021",
            "body": "Bottom line is that a fallback must be implemented and tested, so it's a bit more complicated than just replacing the current ffmpeg command?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "G2G2G2G",
            "datetime": "Jun 7, 2021",
            "body": "Since someone can upload a video that is just all 1 color and never changes, yes. If we guaranteed people would upload actual videos then we can guarantee 0.1 would get a thumbnail. But we can't guarantee what people upload.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "G2G2G2G",
            "datetime": "Aug 8, 2021",
            "body": "What needs to be done to add this?   I feel bad for  and   lolI can write this in like 15 minutes. Where is a video thumb created which function?  I cannot find itI've tested scene,0.8 on thousands of random videos on imgur.com and none failed. My fear is a lightning video like:  will only work on 0.6:\n\nHowever terrible videos (like the one I uploaded that is entirely white the entire duration) won't find any movement.. obviouslyVideos like this also don't really trigger any thumbnails due to how slow they move\n\nsome do, some don't. It's based on if a bar jumps in 1 frame or not. Sometimes on ones like the \"international exports\" video, when the USSR split into russia etc, russia exported a ton of extra crap to other countries driving their bar from non existent to in the top 5 for 5 frames of the video, which triggers  to detect it, but normally nothing will get any thumbnail thus needing a \"first frame\" fallback (which is easy to do, but just an example of why it's needed)",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Jarvid",
            "datetime": "Feb 4, 2022",
            "body": "Hello,my 2c as I just stumbled accross the black thumbnail (black screen in 1st second) problem: of the thumbnail  is hardly worth the effort.\nEvery setting will work one some, but fail on other videos.Either the thumbnail is custom, where the user can select a specific frame of the video in the GUI or upload a specific picture,\nor\nsimple create a collage thumbnail.Did it with a 2x2 layout to have big enough pictures even on a mobile.\nTook the duration(video playback time) from the Mediafile metadata to get 4 frames evenly distributed on the source videos.\nOnly 4 lines in covert.go.\nBut Indexing is slower now and scales with the playback time of the video. Took 25 seconds for a 60 minutes video with 2giga bytes file size while the original approach was only 1 second.I'm happy with the result though. Unless you happen to have a lot of collage pictures in your library, this change makes videos also more distinguishable from pictures aside from the little arrow icon.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Feb 4, 2022",
            "body": "We need the full, first frame so it can be used as still image for . Otherwise, the UI would have to load the entire video just to display the first frame. Note that Live Photos will only play when you hover over them with the mouse, for example in search results.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Jarvid",
            "datetime": "Feb 5, 2022",
            "body": "Excuse my way to write the same content in a new reply again, but I as orignally answered via E-Mail github does not allow to use markdown in reply.I see, is this still limited to videos up to 3 seconds or intended to be used for all kind of videos in the Future?-edit-\nOk, isLive() is always false im my 2 seconds hvc test example, even tough it is correctly typed as live by photoprism.\nIs this data populated later?\nBut aside from this thing:\nI don't see any network traffic difference indicating it is loading the entire video for the first frame.\nIt behaves just as in an unmodified photoprism instance. Well with the current difference, the thumbnail is a collage and once you mouseover the clip starts just normal.\nI've attached a video to show the current way it looks.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Feb 5, 2022",
            "body": "The type is determined automatically based on the duration (and possibly other properties like the codec, see public source code), but it is possible to change it manually. So to avoid unnecessary complexity, it would be best to always have the same behavior - at least until we can pay an armada of developers to implement bells and whistles.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "graciousgrey",
            "datetime": "Apr 28, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "graciousgrey",
            "datetime": "Apr 28, 2021",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "issuehunt-app",
            "datetime": "Apr 28, 2021",
            "body": [],
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "Observe-1",
            "datetime": "May 3, 2021",
            "body": [],
            "type": "issue",
            "related_issue": "#1260"
        },
        {
            "user_name": "graciousgrey",
            "datetime": "Aug 4, 2021",
            "body": [],
            "type": "issue",
            "related_issue": "#648"
        },
        {
            "user_name": "lastzero",
            "datetime": "Nov 1, 2021",
            "body": [],
            "type": "removed  the",
            "related_issue": null
        },
        {
            "user_name": "graciousgrey",
            "datetime": "Nov 2, 2021",
            "body": [],
            "type": "changed the title",
            "related_issue": null
        },
        {
            "user_name": "graciousgrey",
            "datetime": "Nov 2, 2021",
            "body": [],
            "type": "changed the title",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Jul 7, 2022",
            "body": [],
            "type": "added  the",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/photoprism/photoprism/issues/152",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "ghost",
            "datetime": "Dec 7, 2019",
            "body": "I think a timeline view or a timeline scrollbar, like in Google Photos or Synology Moment, would be a cool feature to have.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dennorske",
            "datetime": "Dec 11, 2019",
            "body": "I agree, this also sounds like what  wants. I support it ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Dec 14, 2019",
            "body": "I personally don't find the timeline scrollbar in Google Photos helpful in practice. We thought more about a punch card view and automatic clustering by date & location.Can you post some screenshots of Synology Moment?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "0liu",
            "datetime": "Dec 16, 2019",
            "body": "I think Synology Moment tried to imtate Apple Photos moments function. Essentially it uses the combination of time and location to group photos into \"moments\", instead of time only as in a timeline.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dennorske",
            "datetime": "Dec 17, 2019",
            "body": "Moments sound cool!\nBut considering the current self hosting market, there's not many services supporting a timeline feature. One of the main reasons is that I want it to easily scroll through pictures sorted by date. I have been looking for over 2 weeks and can't seem to find something useful except for maybe plex and the currently abandoned ownphotos project.\nElse I would survive with a standard gallery/year/month folder structure, like many others.I am more than happy to donate to this feature specifically, if it hasn't been considered added to the project. I do think it will cover a big gap in the projects out there.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Dec 17, 2019",
            "body": " I guess it will take a few donations to really pay a developer to do this, but we listen to community feedback and have this on our list once the basics are done :)If we do a \"pro\" version with additional features, our sponsors will certainly get a free license!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "0liu",
            "datetime": "Dec 18, 2019",
            "body": "As far as I know  has implemented timeline and place view separately, but not moments.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dennorske",
            "datetime": "Dec 28, 2019",
            "body": "Could it be similar to what Nextcloud maps have? There's an app in the store called maps, and it allows you to save locations, as well as visualise GPS tagged photos. It scans through and shows up like this:\nThe nice thing is, when you zoom out, the pictures groups up. If they are taken in a small area, and you click the icon with a number under, it spreads out all the thumbnails around and you can have a glimpse at them:Reason I am showing it, is because it looks very fluent and nice. Will this be similar to what is wanted above? There is also a time-period slider on the bottom where you can define from-to dates, and the map will show only the relevant pictures.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Dec 29, 2019",
            "body": " Thank you very much for the screenshots! We spent the last couple of days (Merry Christmas!) preparing our database for efficient clustering (country/year/month) and location search using S2 cell IDs (more efficient than lat/long). See also .Next, we need to provide our own location service to actually be able to index many photos in acceptable time. When this is done, we can finally focus on the UI, certainly room for improvement. One of our ideas is to show a path on the map where you've been and then you can travel along.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Jan 23, 2020",
            "body": "Looks like you get this feature in our  first!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "leopoldsedev",
            "datetime": "Jan 26, 2020",
            "body": "Here's some more inspiration for the UI. It is taken from plex. I think it's nice how photos are separated by day and dynamically tiled based on the image size. The scrollbar on the right is overlayed by the years and the smaller ticks indicate a high density of photos there. Overall it's nice to scroll through memories like this.\n",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Jan 26, 2020",
            "body": "Google Photos is similar, personally never found this very useful or pleasing to my eye TBH. Lots of space wasted when you only have one or two photos per day.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dennorske",
            "datetime": "Feb 2, 2020",
            "body": "If not a timeline, it could be a scrollbar that shows month + year close to it when you scroll?\nSome sort of seeking like that is very handy, at least if you're an ancient google photos user like me :)\nIt is extremely handy to do. But I would not say this is the most important feature, it is more a nice-to-have if  is implemented.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Feb 2, 2020",
            "body": "Maybe I can't properly use it because my mouse is too fast Let's focus on the essentials to get a stable release, there will be enough time to experiment afterwards.Clustering by year, month and country is easy with our current database schema. We'll do sharing next as this has higher impact on our architecture. Worked a lot on events and validation recently for a smooth user experience.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dennorske",
            "datetime": "Feb 2, 2020",
            "body": "That is great, thank you for all the efforts in the project!\nI am excited to see the sharing come along, that is clearly something I am missing. Good luck",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "mpodshivalin",
            "datetime": "Jun 12, 2020",
            "body": "\nI'm off-topic, but I've seen a lot of mentions of a possible Pro version. Are there any plans on how it will be licensed? E.g. a free-as-a-beer but proprietary license is not something I'd potentially want",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Jun 13, 2020",
            "body": "Fact is, we want to be as free and open as possible and think this provides real value to our users, like when you look at how we develop together with our community.On the other hand, we've been working full-time for about ~2,5 years now and there are still a lot of requests waiting to be implemented. GitHub sponsors doesn't even cover the monthly costs of our servers. So the idea is to release a special version with additional features for our sponsors, contributors and eventually paying customers. See \"Funding\" in our docs. Obviously you shouldn't be allowed to take this and sell it on your own. Suggestions welcome.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "mpodshivalin",
            "datetime": "Jun 14, 2020",
            "body": "\nOf course selling/getting funding for free software is a difficult issue.\nI've checked the Funding page and the first thing I see is \"This project is about freedom and privacy but not necessarily about free beer.\". So, it has to be free software, or else there won't be much of a difference with other proprietary projects.According to the funding page, there won't be Enterprise customers (as opposed to Nextcloud for example). So the project should be funded by regular users, which value privacy so they won't accept the proprietary solution. And by \"Regular users\" I mean not a super tech-savvy users (it's not a big market), but real regular people. And the most important thing for regular people is convenience.Make the source code available for both versions with the same license, but do not distribute a \"Pro\" version for free. This is how e.g. OpenProject works - both versions are GPL'ed. So yes, it should be possible to obtain the source code for the \"Pro\" version without paying, but it shouldn't make sense because it won't be convenient. And the most important thing for regular people is convenience. So if a user obtained the source code for the \"Pro\" version - he must build everything from source, he won't have upgrades and will have a generally semi-working setup in a long term. For example - iOS user can't have this app even if he has a source code, unless he has an up-to-date Mac, general knowledge on how to install apps to and iPhone and he must have a developer account (which won't solve all of the problems). This is very inconvenient and it's better and easier to buy an app, even if it's GPL'ed. This is my opinion :) And it's just one example - servers can be more convenient, too.And, actually, getting back to the topic, from my experience, regular people, when they say they need a \"Cloud\", mainly mean photos, and they certainly mean Timeline. This view is the default view in Apple+Google photos, and it is mainly used because people (including me) don't have much time to organize their photos, they don't want to add photos to albums unless it was an event, something significant, like a trip. And they don't want to filter photos by year, month, etc. they don't want to think. The Timeline interface, though seems simple, lets people look for their photos in a convenient way, with the ability to go to a specific date and grouping by date is letting them find events quickly without organizing anything",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Jun 15, 2020",
            "body": "Shouldn't be difficult. I'm part of the free software community since the 90s and it was clear from early on, that free doesn't mean free beer. I see it as an additional feature that provides value to our users. Unlike back in the 90s, software as a service is very popular today, so the GPL only provides limited protection to us and other startups that invest a lot of time and money into their products.It's not clear to me why the right to commercially distribute every line of code we release should be important to private end-users.If there were more sponsors, we could release everything under a MIT or BSD style license. As a matter of fact, we only have very few sponsors and no other funding whatsoever. So we need to find a different solution unless you want us to stop working on this.For now, you have the new Calendar view plus the year and month search filter in our main view. You can also sort by date (added, newest first, oldest first), relevance, similarity and file name. Plus we automatically create moments based on country and year for you. It feels like this is enough for a first release and of course we're using your feedback to continuously improve our product.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Jun 15, 2020",
            "body": " Pro doesn't mean you won't be able to get or modify the source code. Take a look at how GitLab handles dual-licensing, they also distribute the code.Everyone can use our software under the terms of the AGPL from now on: This is far from being proprietary. Those who need additional rights or advanced features like multi-user support MAY pay for it at some point in the future. We pay for development and take all the risk. Let us know if you get a better deal somewhere :)",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "issuehunt-app",
            "datetime": "Jun 24, 2021",
            "body": " has funded $75.00 to this issue.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "jimboolio",
            "datetime": "Jun 24, 2021",
            "body": "To my understanding this may fix the slow scrolling issue mentioned in issue . I am running photoprism on 10 core server with 60gb ram and storage is from high performance san over smb (on linux) and the scrolling is painfully slow even on local network. I have 200 000 photos on my photoprism instance which I moved from Goolge photos and I miss the ability to quicly scroll all of my photos at once as I used to do there.I tried Nextcloud too, but it is just unusably slow/crashes with my library. Photoprism can handle my photos without crashing (great job photoprism devs!!!), I just cannot view/scroll them very quicly because after scrolling too far on the grid view, my client device heats up and slows down. I see the potential in this project and if the ux was a bit faster on my probably quite unique and heavy use case this could soon become my main photo management software. Even if the timeline feture cannot solve my weird use case I would be happy to see the timeline feature.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Jun 30, 2021",
            "body": "Yep, we'll get to this. The current photo search wasn't designed to scroll through your entire library - instead it may show higher resolution thumbs and more metadata than Google Photos, which only provides very limited metadata with search results, basically just the preview. So there's pros and cons. Working hard to grow our team so that we get more done in less time.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Jul 24, 2021",
            "body": "We are working on facial recognition right now, and also need a short break after working nonstop for more than 3 years. This has nothing to do with backend coder thinking.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "neonsoftware",
            "datetime": "Jul 28, 2021",
            "body": " thanks for updating on current items on the table. Have an outstanding holiday 👍🏼",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "issuehunt-app",
            "datetime": "Sep 16, 2021",
            "body": " has funded $5.00 to this issue.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "issuehunt-app",
            "datetime": "Sep 26, 2021",
            "body": "An anonymous user has funded $15.00 to this issue.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "issuehunt-app",
            "datetime": "Sep 29, 2021",
            "body": "An anonymous user has funded $50.00 to this issue.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "issuehunt-app",
            "datetime": "Oct 10, 2021",
            "body": " has funded $2.00 to this issue.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "IssueHuntBot",
            "datetime": "Dec 23, 2021",
            "body": "An anonymous user has funded $30.00 to this issue.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "IssueHuntBot",
            "datetime": "Dec 23, 2021",
            "body": "An anonymous user has cancelled funding for this issue. (Cancelled amount: $30.00) ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "IssueHuntBot",
            "datetime": "Dec 23, 2021",
            "body": "An anonymous user has funded $10.00 to this issue.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "IssueHuntBot",
            "datetime": "Dec 23, 2021",
            "body": "An anonymous user has cancelled funding for this issue. (Cancelled amount: $10.00) ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Dec 23, 2021",
            "body": "Please don't add funds to IssueHunt anymore! While we like IssueHunt and are grateful for the donations we've received so far, it hasn't proven to be a sustainable funding option for us as we spend much of our time maintaining existing features and providing support.If we don't have enough resources to provide support and bugfixes, we can't start working on new features.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Dec 23, 2021",
            "body": "See  for sponsorship options ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "tolicodes",
            "datetime": "Dec 23, 2021",
            "body": "Actually....I would be open doing some work on this in the near future (need it for a project).  Maybe if someone on the team is wiling to pair with me to get started.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Dec 23, 2021",
            "body": "We already know how to implement it, but must focus on multi user 100% in January and also should look into upgrading Vuetify first. Help with providing support and answering questions is much appreciated.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "tolicodes",
            "datetime": "Dec 23, 2021",
            "body": "",
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Dec 24, 2021",
            "body": "We need a proper API for it first, which is what native app developers are waiting for as well. It's not complicated, we just have to limit , as our current donations don't fund a large team where everyone can focus on something else.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "laterwet",
            "datetime": "Jan 17, 2022",
            "body": "Currently, photoprism is using vuetify 1.5 (released 3 years ago). Looking at their , I see they added  component in version 2.3.Using this component would solve multiple of the listed issues, such as:Someone already upgraded in this PR: ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Jan 17, 2022",
            "body": "I wish we had a team of TypeScript developers, but no. Anyway, we will focus on the missing timeline server API first... the JS part is no magic, it just needs to be done... we develop , meaning before we implement a UI, we work on the API.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Jan 17, 2022",
            "body": "Take a look at , this is (by far) not the only issue on our ToDo list. Otherwise, it would have been done long ago. We can't work on everything at the same time, especially not with our .",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "graciousgrey",
            "datetime": "Jun 29, 2022",
            "body": "No timeline view yet, but the  comes with a much faster scrolling experience ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Dec 8, 2019",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Dec 23, 2019",
            "body": [],
            "type": "issue",
            "related_issue": "#21"
        },
        {
            "user_name": "lastzero",
            "datetime": "Dec 30, 2019",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Dec 30, 2019",
            "body": [],
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Jan 22, 2020",
            "body": [],
            "type": "issue",
            "related_issue": "#214"
        },
        {
            "user_name": "lastzero",
            "datetime": "Jan 23, 2020",
            "body": [],
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Jun 15, 2020",
            "body": [],
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Jun 16, 2020",
            "body": [],
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Jun 23, 2020",
            "body": [],
            "type": "added",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Jun 23, 2020",
            "body": [],
            "type": "self-assigned this",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Nov 1, 2021",
            "body": [],
            "type": "removed  the",
            "related_issue": null
        },
        {
            "user_name": "graciousgrey",
            "datetime": "Nov 3, 2021",
            "body": [],
            "type": "issue",
            "related_issue": "#786"
        },
        {
            "user_name": "lastzero",
            "datetime": "Nov 16, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "graciousgrey",
            "datetime": "Apr 14, 2022",
            "body": [],
            "type": "issue",
            "related_issue": "#2253"
        },
        {
            "user_name": "lastzero",
            "datetime": "Apr 16, 2022",
            "body": [],
            "type": "issue",
            "related_issue": "#2258"
        },
        {
            "user_name": "lastzero",
            "datetime": "Jun 17, 2022",
            "body": [],
            "type": "pull",
            "related_issue": "#2292"
        },
        {
            "user_name": "lastzero",
            "datetime": "Jun 17, 2022",
            "body": [],
            "type": "",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/photoprism/photoprism/issues/1187",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "red-avtovo",
            "datetime": "Apr 11, 2021",
            "body": "Thank you very much for the project! I really enjoy using it.I would like to notice, that it would be useful to group photos on a small scale which are very close to each other or let to open cluster view (similar as a moments view) and show the subset of photos from the place, clicked on. It is not very easy to navigate through the subset of the photos or share a group of them from a specific place\n",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "shawnbarton",
            "datetime": "Apr 13, 2021",
            "body": "I came here to make this exact suggestion. This is an important feature to me since without it the \"Places\" feature doesn't have any real use in a large library. Keep up the great work.Edit: Attached is a more extreme example (low image quality intentional). In this example \"places\" still shows individual bubbles for thousands of images at a \"street-level\" zoom. As described above, I would like to, at some (maybe configurable) zoom level, be able to see an overview of all the images in that place.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Apr 13, 2021",
            "body": "Thank you very much! It's true that we need to optimize this further. As you might have noticed, the maps already cluster automatically - but only up to a certain zoom level as you otherwise might not be able to see individual photos. It's more work to handle situations as this, e.g. by showing a \"stack\" that then opens in the photo viewer like stacks in regular search results.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "magnuznilzzon",
            "datetime": "May 3, 2021",
            "body": "I suspect it is pretty common to have the situation that  has, especially people with families will have a ton of pictures centered on their home. I know I do, that is how I found this thread.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "el-tiuri",
            "datetime": "May 24, 2021",
            "body": "Great idea! I like the way it’s implemented in iOS’ Photos app, and this would be pretty similar. The way it works on iOS is that it dynamically creates stacks of photos that are close together relative to the zoom level, and if you tap on a stack you get a grid of all the photos in that stack.I especially like this because it enables you to easily see all the photos you took in a particular place (regardless of scale - could be a city, could be a continent) regardless of when you took it.I think limiting the automatic clustering functionality to low zoom levels would be a bit limiting compared to the use it could have, and I don’t really see the benefit of it compared to enabling it on all zoom levels.Let me know if you want me to share some screenshots of the iOS photos app, in case that’d be helpful.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ohthehugemanatee",
            "datetime": "Jul 11, 2021",
            "body": "I have the same issue. We in fact already have the dynamic stacks. Just when you click/tap on a circle with a number of photos, that should take you immediately to a pre-filled search results page. That would be plenty.  Users can zoom in closer with the plus/minus keys and get more precise, smaller stacks.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "fivestones",
            "datetime": "Dec 23, 2021",
            "body": "I agree with . Right now the circles with the number inside just zooms in when clicked. Instead, clicking on these circles should open a search results page with all those photos shown. Zooming in on the map is easily done other ways and doesn't need to be done by clicking on the circles that have numbers inside.Without the ability to view a search result for a group of photos in a particular location, the maps view is not very useful. For example, it would be really great to be looking at a photo, and easily see all my other photos from the same location or that were taken nearby as a search result. Right now I can go to the location of a photo on the map, but can't just see other photos in the same location without zooming all the way in, and then the other photos are only visible as little circles until I click on each one individually. Another example use would be to just show all the photos taken in, for example, Africa. Or the Grand Canyon. Or Paris. Or my home street. Again, I can find these photos if I look on the map, but only by zooming all the way in to see individual photos and then clicking on each one. If I have a small circle over Africa that says \"27\", I should be able to just click it and see all those 27 photos taken in Africa in a search result.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Dec 23, 2021",
            "body": "To see the photos in regular search results, you can also type the name of the location in the regular search field, for example \"Africa\". Changing the view type between map and cards / list view causes a lot of load in the front and backend. For this reason, you typically don't want to jump back and forth all the time.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "fivestones",
            "datetime": "Jan 13, 2022",
            "body": "Being able to search for a location and see photos taken there is great. Thanks! I didn't know about that.But as for the map view, what's the point if you can't click on a location and see all the photos in that location? I do this all the time on my iPhone--I'm looking for a particular photo, don't know quite when it was but I know where I was. Go to the map view in the photos app, zoom in until I'm only seeing photos in the area I know the photo was taken, tap on that indicator for a bunch of photos, and there I have all those photos to scroll through, just from that location. It's great, I can do it on a location as big as a continent or as small as my house, and it's very quick--takes make 10 seconds to find a specific photo this way.It makes sense that a map view in a photos app would work this way, and then whatever load in the front and backend that it causes could be worked on.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "graciousgrey",
            "datetime": "Jan 13, 2022",
            "body": " We will find a nice solution when we find time to work on this :)",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "alber70g",
            "datetime": "Feb 28, 2022",
            "body": "I have an idea on how to do this:We could split the circle in a upper and bottom half.\nUpper half: shows a  that the user can tap/click and it'll zoom (current behaviour)\nLower half: shows the number of pictures in that area that the user can tap/click that takes the user to a album view of those pictures",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ttimasdf",
            "datetime": "Jul 29, 2022",
            "body": "As for zooming, on desktop we can use mouse scrolls, on mobile device we can use two-finger gestures. Clicking on the circle could be used to browse all the photo inside the whole group. It's rather intuitive.Here's a screen record from Huawei Gallery app, may be a good reference i think?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "fivestones",
            "datetime": "Aug 1, 2022",
            "body": "I agree, there is no need for any clicking/tapping on the numbers to be a zoom option. We can just zoom with two fingers or mouse scroll.\nI'd love to see it look like in the above Huawei Gallery app.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Aug 1, 2022",
            "body": "Huawei uses local images in a native app. We use thumbnails with a responsive Web UI that must be fast and work on all browsers and devices. So it's a tiny bit more complicated.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "fivestones",
            "datetime": "Aug 3, 2022",
            "body": "I suppose it is. But to change from the current, not very useful behavior (zooming in when clicking on a number) to a very useful behavior (showing a search result of all the photos in that area when clicking on the number) should be a super easy change to make. The photos in that area have already been found in the database, which is how we know how many there are. We just need the link to go to a display of all of those particular photos.If we want to zoom, we can already do that without clicking on the numbers.To show a photo, just pick the first one out of all those represented by a number, and show it there. Already when you zoom in until only a single photo is on a particular place on the map, that photo is shown. So it shouldn't be hard to show that same number to represent a bunch of photos in a more zoomed out view.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "heikomat",
            "datetime": "Aug 3, 2022",
            "body": "No promises, but maybe I'll try creating a POC for this feature on the weekend",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "heikomat",
            "datetime": "Aug 6, 2022",
            "body": "Had a couple hours today. This is the current progress:Still a lot to do (its rough around the edges, has no tests etc), but it proves that it's doable.See ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "svengreb",
            "datetime": "Aug 7, 2022",
            "body": " That already looks great for a POC, well done!\nI'd like to throw in a small improvement suggestion: Instead of showing only numbers it would be nice to use a photo of this cluster instead as \"background\". This way it would be easier to quickly find what you are looking for instead of having to click on each cluster in an area when you are not quite sure if it was really taken at this specific location.\nThe number could be shown either as overlay or maybe we can introduce a new variant implementation of the cluster circle component that can have a small \"badge\" outside of the circle that contains the number. The second option would be great to prevent contrast issues of the number when the \"background\" photo has the same color like the font.To allow users to change this behavior we can make this customizable through new setting keys, e.g. to make it possible to select a specific criteria which image will be used as \"background\" (latest photo, most viewed etc.) and, of course, disable the feature to only show numbers instead like already possible in your POC.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ttimasdf",
            "datetime": "Aug 8, 2022",
            "body": " This idea has already been considered by project developer. So, no hurry ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "heikomat",
            "datetime": "Aug 8, 2022",
            "body": "All photo IDs of a cluster are known when the cluster is rendered.Showing  photo of a cluster is not a problem I think. Showing a photo based on some criteria would be more difficult.The map already renders custom elements for single images.\nRendering a different custom element, for example with a counter attached in a little bubble, should be no problem as far as I can tell.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "heikomat",
            "datetime": "Aug 10, 2022",
            "body": "I hope no one waiting for this feature is in a hurry.\nI'd really like to spend another night or two developing this, but time is tight in the coming days/weeks.\nWith some luck I'll have some free time at the end of next week",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Istria1704",
            "datetime": "Sep 3, 2022",
            "body": "I found this thread just before I almost opened a new one about the same thing. Very nice it is being worked on!I also agree that there should be a way to \"show all photos in cluster\".\nIf the zooming function is simple replaced by it, I'd be fine with that. But maybe something like double-tapping is possible to keep both functions? That could work universally on both desktop and mobile, no?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "heikomat",
            "datetime": "Sep 7, 2022",
            "body": "I'm slowly but surely making progress whenever i find some free time.\nIn it's current stateI tried making the dialog fullscreen on screens with  of width, but that somehow breaks closing it?\nFor now, having it not-fullscreen isn't to bad, even on mobile devices.a known issue is, that opening a cluster currently resets the search if a search-term was entered.\nOther than that, and a lot of testing and a little cleaning up, the only missing thing afaik is implementing better custom-elements to be rendered on the map (something like maybe the first 4 images in a cluster with an outside bubble displaying the image count)",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "heikomat",
            "datetime": "Sep 17, 2022",
            "body": "current progress. What do you think about the squared rectangles instead of circles (to see more of the images), and borders and counter bubbles?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "svengreb",
            "datetime": "Sep 17, 2022",
            "body": "The count badge/bubble is nice and definitely better that just a one-colored circle without an image preview!\nShowing multiple image previews is also a nice idea, but it should be opt-in since the images are really small and maybe a single image might be preferred. Adding this as an option to the settings would be really great.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Sep 17, 2022",
            "body": "The new thumbnails on the map look great! As for the overlay, I haven't had enough time to think about it and didn't want to start a discussion based on unfinished work. An alternative could be to display the images at the bottom with horizontal scrolling, similar to Google Maps and other services. Of course, not so many images would be visible there at the same time and it would require developing yet another view.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "heikomat",
            "datetime": "Sep 27, 2022",
            "body": "i'll try to fix the \"opening a cluster resets the search\" tomorrow or in two days (will have some free time then).\n do you consider that Bug a show-stopper?More important though: Are there any missing must-haves for that feature i should work on before you consider merging it?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "graciousgrey",
            "datetime": "Sep 28, 2022",
            "body": " The bug itself would not be a blocker.\nBut since we just changed 10 000 lines of code, we want to test these changes thoroughly before merging more changes.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "graciousgrey",
            "datetime": "Apr 12, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "graciousgrey",
            "datetime": "Apr 12, 2021",
            "body": [],
            "type": "added this to",
            "related_issue": null
        },
        {
            "user_name": "lrq3000",
            "datetime": "Sep 17, 2021",
            "body": [],
            "type": "issue",
            "related_issue": "#1533"
        },
        {
            "user_name": "graciousgrey",
            "datetime": "Nov 11, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "heikomat",
            "datetime": "Aug 6, 2022",
            "body": [],
            "type": "pull",
            "related_issue": "#2596"
        },
        {
            "user_name": "heikomat",
            "datetime": "Aug 27, 2022",
            "body": [],
            "type": "issue",
            "related_issue": "#2653"
        },
        {
            "user_name": "lastzero",
            "datetime": "Sep 17, 2022",
            "body": [],
            "type": "changed the title",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Sep 17, 2022",
            "body": [],
            "type": "moved this from",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Sep 17, 2022",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "lastzero",
            "datetime": "Sep 17, 2022",
            "body": [],
            "type": "added  the",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/googlearchive/vrview/issues/288",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "cwilso",
            "datetime": "Dec 11, 2017",
            "body": "OSX, Chrome 62, clicking and dragging with mouse does not move view around as it should.",
            "type": "commented",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/googlearchive/vrview/issues/230",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "graymouser",
            "datetime": "Jul 14, 2017",
            "body": "Similar to  , trying to implement a 'click to add hotspot' interface and getting mouse yaw/pitch on click would be super helpful, whether via modified getPosition or a separate function.Does anyone know a three.js command sequence that would work this out from worldRenderer.hotspotRenderer.pointer or similar? Have been fiddling with it but so far no luck, any help much appreciated.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "WojciechJasinski",
            "datetime": "Oct 8, 2017",
            "body": "As far as I can see onGetPosition returns somethig called camera rotation. The problem is that when I new hotspot whit Yaw and Pitch values returned by this method I get new hotspot rendered in very wrong position (90 degrees to the left).\nFurthermore loading pano I suspect that camera looks at Vector3(0, 0, 0) but in fact it looks at point 90 degrees to the right.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "WojciechJasinski",
            "datetime": "Oct 8, 2017",
            "body": "I've also tried to send position using  on mouse up but still no effect:",
            "type": "commented",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/googlearchive/vrview/issues/306",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "michelePap",
            "datetime": "Mar 11, 2018",
            "body": "Visiting any webpage with a google vr frame with chrome on android, moving the smartphone the scene does not change visual as usual. Things remain the same in the cardboard view.\nWith firefox and samsung browser there are no problem",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ddorwin",
            "datetime": "Mar 12, 2018",
            "body": "Which version of Chrome exactly? There was a bug in Chrome 65 () that should be fixed soon. See also the discussion in , including changes in Chrome 66. Updating the polyfill should handle the latter fine, but an upcoming Chrome update is required to fix the Chrome 65 issue. /cc ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "michelePap",
            "datetime": "Mar 13, 2018",
            "body": "On chrome stable version 65.0.3325.109",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "neilloispy",
            "datetime": "Mar 13, 2018",
            "body": "Yes this is the same issue which came up with Android Chrome version 62.0.3202.84 last year and was fixed in subsequent versions.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ddorwin",
            "datetime": "Mar 16, 2018",
            "body": "A new version of the polyfill containing a workaround for the Chrome 65 issue has been released: ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "jsantell",
            "datetime": "Mar 16, 2018",
            "body": "Looks like vrview is using 0.9.x, and uses WebVRConfig in unexpected ways; need to confirm if the YAW_ONLY option actually works (it's set after polyfill is brought in so looks like it wouldn't do anything), and how necessary mouse and keyboard controls (although it looks like it's using a different click/drag mechanism?)",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dkudrin",
            "datetime": "Mar 17, 2018",
            "body": " polyfill doesn't helps. Have yot tried it?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "jsantell",
            "datetime": "Mar 19, 2018",
            "body": " do you have a test page using the latest polyfill release? what doesn't work?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ademarre",
            "datetime": "May 14, 2018",
            "body": [],
            "type": "issue",
            "related_issue": "#317"
        }
    ]
},
{
    "issue_url": "https://github.com/googlearchive/vrview/issues/317",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "davidh64",
            "datetime": "May 14, 2018",
            "body": "The latest  seems to include fixes for  introduced by newer versions of Chrome, but webvr-polyfill v0.10.0 removed MouseKeyboardVRDisplay which provided 3DOF controls for desktop when no native displays are connected. Is anyone actively working on updating to the newer version of the polyfill? It seems that this would resolve , but would require a replacement for the mouse and keyboard controls on desktop that were previously provided by the polyfill.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ademarre",
            "datetime": "May 14, 2018",
            "body": "In addition to , this should also fix .I assume the replacement for  would also resolve , , and .",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "davidshttintin",
            "datetime": "Aug 25, 2018",
            "body": "how do u update to the latest version of webvr-polyfill? do u replace codes in vrview.js?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "transpirman",
            "datetime": "Sep 23, 2018",
            "body": "it seems that by changing this unique line in embed.(min.)js, it works on newer chrome mobile as well :\nif(this.isIOS||this.isFirefoxAndroid){ this.gyroscope.multiplyScalar(Math.PI/180); }\nremove the if statement to keep only the \"this.gyroscope.multiplyScalar(Math.PI/180); \"",
            "type": "commented",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/googlearchive/vrview/issues/289",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "uberstudio",
            "datetime": "Dec 14, 2017",
            "body": "Confirmed on Edge, Firefox 55+ on Windows 10,\nI've seen more reports of this issue popping up lately.\nThis can also be recreated in Chrome easily by enabling the WebVR experimental flag, so this is definitely coming to Chrome as well.I've noticed requiring the legacy polyfill and enabling the deprecated API has been suggested as a fix in several forums, but I believe this is only a temporary hack.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ademarre",
            "datetime": "Dec 14, 2017",
            "body": "This is the same issue reported in , which was not resolved but is currently closed.It's probably the same as  as well.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lincolnfrog",
            "datetime": "Dec 14, 2017",
            "body": "We closed it because builds on windows are flawed but if you use the embed that we are hosting here:   it should work. Is that not true?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ademarre",
            "datetime": "Dec 14, 2017",
            "body": " I'm not able to test it right now, but I don't think so;  is not a build issue.As I understand it, the problem is that the native WebVR implementations don't provide mouse and keyboard devices in  the way the polyfill does. As far as I know, the solution discussed in these two comments has not been implemented: by ssh-esoteric\n by ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "jsantell",
            "datetime": "Dec 15, 2017",
            "body": " your understanding sounds correct to me -- on native implementations, those displays will be provided instead. If you don't have a Vive/Oculus or something hooked up, you won't be able to view it. If we used that flag in the polyfill mentioned in the above comment, then that would add the MouseKeyboardVRDisplay in this scenario",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "jsantell",
            "datetime": "Dec 15, 2017",
            "body": "Reopening , related to Edge (now with native WebVR) not windows builds",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "uberstudio",
            "datetime": "Dec 18, 2017",
            "body": "I tried using this build: But it's a totally different package than the official VRView library, looks like this one doesn't include Three.js, three-vrcontrols, possibly more (I didn't check, I'd rather have a complete build)",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ademarre",
            "datetime": "May 14, 2018",
            "body": [],
            "type": "issue",
            "related_issue": "#317"
        }
    ]
},
{
    "issue_url": "https://github.com/googlearchive/vrview/issues/255",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "Olexyy",
            "datetime": "Sep 29, 2017",
            "body": "I've implemented mouse data ( but for normal centering i had to add 100px for 'y' and 200px for 'x'). So now, on 'hover' hotspot, div can de put to that place, describing details of it. On blur it vanishes. Does it make sense to commit to master?",
            "type": "commented",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/googlearchive/vrview/issues/203",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "theunreal",
            "datetime": "Jun 25, 2017",
            "body": "Currently it seem like the getPosition() method returns  .This is not really useful, a better way to implement it is to return the yaw and pitch position of a mouse click in the viewer inside the  event.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "graymouser",
            "datetime": "Jul 14, 2017",
            "body": [],
            "type": "issue",
            "related_issue": "#230"
        }
    ]
},
{
    "issue_url": "https://github.com/googlearchive/vrview/issues/274",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "computerjazz",
            "datetime": "Nov 13, 2017",
            "body": "Steps to reproduce: update chrome on android device and go to \nExample does not respond to phone orientation changes.Hoping that upcoming Chromium release fixes the issue: ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "jsantell",
            "datetime": "Nov 13, 2017",
            "body": "Is this Chrome 62.0? Related: ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "jsantell",
            "datetime": "Nov 13, 2017",
            "body": "And is this specifically for webview?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "computerjazz",
            "datetime": "Nov 13, 2017",
            "body": "It is definitely an issue for webview, but I also see the issue when navigating to the above link in android chrome 62.0.3202.84.When I open up the remote device Chrome developer tools for that link I see:Here's what I see -- image does not move with phone movement:\nI have been able to successfully view some 360 content in chrome, so I can't pinpoint the exact issue.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "aerialglasgow",
            "datetime": "Nov 14, 2017",
            "body": "",
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "ademarre",
            "datetime": "Nov 16, 2017",
            "body": "I see the same issues on Android after updating to Chrome 62. It is only a problem when running VR View through a cross-domain iframe, and it is solved by adding  Feature Policy attribute to the .In addition to the accelerometer, these issues present as well:Perhaps coincidentally, Firefox on Android is broken with the same symptoms, but  does not resolve it.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "aerialglasgow",
            "datetime": "Nov 17, 2017",
            "body": "",
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "ademarre",
            "datetime": "Nov 17, 2017",
            "body": ", I don't know about that line number, but I was putting it in  after this line:\nNonetheless, you are correct that it does not solve the problem. I was mistaken and had a false positive when I tested it. Although I am confident that it is only an issue with cross-domain iframes.Since the  Feature Policy doesn't fix it for Chrome, I want to revise my previous statement to say that The  change is probably still good though, because of this: ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lincolnfrog",
            "datetime": "Nov 18, 2017",
            "body": " do you mind putting up a PR with this change?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "adamweld",
            "datetime": "Nov 30, 2017",
            "body": "This issue is still present for me even after adding allow='vr' to the iframe.For example view my site in Chrome on Android:\nThe viewpoint appears locked to the ground. Tapping and dragging to change yaw still works. Here's a code snippet:Note I've also tried using a self hosted version of VRView with the following src line:But in that case the image fails to load.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ademarre",
            "datetime": "Dec 14, 2017",
            "body": "It seems to be fixed with Chrome 64. Verified with Chrome Dev 64.0.3282.12 on Android 8.1.0.Firefox on Android is still unresolved as of the latest nightly 59.0a1 (2017-12-13).",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "neilloispy",
            "datetime": "Mar 13, 2018",
            "body": "Just to let you know exactly the same issue has appeared again in latest release of Chrome 65.0.3325.109, however not an issue in other browsers, using sample view here:\n",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "jsantell",
            "datetime": "Mar 13, 2018",
            "body": "Does this also occur in Chrome 65 in the webview?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "neilloispy",
            "datetime": "Mar 14, 2018",
            "body": "",
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "thomclae33",
            "datetime": "Mar 16, 2018",
            "body": "Accelerometer tracking seems indeed broken on Chrome mobile",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "jsantell",
            "datetime": "Mar 16, 2018",
            "body": "There are a few regressions in Chrome m65 detailed in the , vrview needs to be updated with the latest polyfill to mitigate these changes, although there still could be low frequency of devicemotion events, which there's not much we can do until m66",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "McGern",
            "datetime": "Mar 22, 2018",
            "body": "Can confirm it was working for me this morning using an aframe demo (don't know what version of Chrome sorry). I have set updates to manual on my phone. When I updated to 65.0.3325.109 the gyroscope is not working anymore. Using a oneplus one.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "tksharpless",
            "datetime": "Apr 17, 2018",
            "body": "On my Samsung Galaxy S6, several recent versions of Chrome, Chrome Dev and Chrome Beta show incorrect gyro behavior at multiple VR/360 websites. Either the gyro response is wildly unstable & hypersensitive, or it works very slowly and only on the vertical axis. The current Samsung Internet app is usable, though both jumpy & sluggish.Rolling back the factory installed Chrome app to the original version, which is several years old, restored correct gyro behavior. I was also able able to install version 63.0.3239.71 of Chrome Beta, which works right. So this is definitely a case of \"better is the assasin of good\".I  hope there is a fix real soon, as this is a major problem for  the VR industry.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "tinywolf3",
            "datetime": "May 8, 2018",
            "body": "I tested with .\nMobile Chrome(v66) and Opera Mini(v33) have the problem.\nMobile Firefox(v60) and Samsung Internet(v6.4) are fine.The other 360 web viewer, , is fine in all browsers.I hope fix this soon.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "steindelek",
            "datetime": "May 10, 2018",
            "body": "To fix  issue in latest Chrome or webview, just force vrview to calculate the rotation the same way as for Firefox and IOS. In embed.js in FusionPoseSensor.prototype.updateDeviceMotion function take this.gyroscope.multiplyScalar(Math.PI / 180) out of \"isIOS or isFirefoxAndroid\" condition.\nHope that helps :)",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "jsantell",
            "datetime": "May 10, 2018",
            "body": "Chrome m65 has deviceorientation platform issues that the polyfill cannot work around. In Chrome m66, the deviceorientation events are now calculated similarly to iOS/Firefox -- the latest webvr-polyfill version addresses this, which this library needs to update to",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ademarre",
            "datetime": "May 10, 2018",
            "body": " is anyone actively working on updating this library to the new polyfill?I understand there will be some work involved to provide new keyboard/mouse controls since  was removed from the new polyfill. I'm not sure of the best way to solve that in VRView.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "tinywolf3",
            "datetime": "May 14, 2018",
            "body": "  Thank you for your help.\nI change the function, isFirefoxAndroid to isAndroid.\n\nNow, all browsers are OK.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Donosor",
            "datetime": "May 23, 2018",
            "body": " Also on Huawei?\nCan you help me please? if I modify mi code don't work nothing. I see the white screen on all browser!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "kadupenido",
            "datetime": "May 24, 2018",
            "body": "  Thank you. I made the changes and it worked out here.\nI tested on android 7.1 and chrome 66 and it worked fine",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "jedaan",
            "datetime": "Jul 11, 2018",
            "body": "\ni tested on android 7.0 and chrome 67 and it ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lincolnfrog",
            "datetime": "Nov 20, 2017",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "ademarre",
            "datetime": "Nov 20, 2017",
            "body": [],
            "type": "pull",
            "related_issue": "#277"
        },
        {
            "user_name": "ademarre-ca",
            "datetime": "Nov 22, 2017",
            "body": [],
            "type": "pull",
            "related_issue": "#278"
        },
        {
            "user_name": "davidh64",
            "datetime": "May 14, 2018",
            "body": [],
            "type": "issue",
            "related_issue": "#317"
        }
    ]
},
{
    "issue_url": "https://github.com/googlearchive/vrview/issues/150",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "markwoodward23",
            "datetime": "Apr 27, 2017",
            "body": "I'm creating a slide based website based on Dragdealer that uses the arrow keys or dragging horizontally to navigate between slides. As soon as the Vrview loads on one of the slides, it hijacks the keyboard and mouse movements so I can't change slide anymore. I've tried commenting out the event listeners in embed.js, which stops the commands, but instead of allowing me to use the normal dragging and or arrow keys, it doesn't do anything.Is it possible to change the arrows keys or remove the key binds?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "tommytee",
            "datetime": "May 8, 2017",
            "body": "You might want to take this question to stack exchange... (since its not really a vrview issue)The keyboard events happen in the WebVR Polyfill.\ncommenting out line 38 should work. Or commenting out that code directly in embed.js\n(which you may have already tried)",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "tommytee",
            "datetime": "May 11, 2017",
            "body": "I apologize for suggesting stack exchange / stack overflow.  I recently tried to use stack overflow and discovered that it doesn't work very well.\nI created a google group for questions and discussion.\n",
            "type": "commented",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/googlearchive/vrview/issues/78",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "pszafer",
            "datetime": "Nov 16, 2016",
            "body": "Hello,\nI wanted to use your library to put panorama/360 photos on my website, but first thing I see, that with my touchscreen laptop I cannot move sample photo on your website Is it a bug or vrview library is not touch friendly on PC devices?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "paulstone",
            "datetime": "Nov 21, 2016",
            "body": "Hi I had this problem today too on a kiosk we've installed. Did you fix the issue/find a workaround? From what I could tell, it wasn't working because the touchscreen doesn't have (or Chrome wasn't recognising) the click-and-drag event.Thanks,\nPaul.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "pszafer",
            "datetime": "Nov 22, 2016",
            "body": "No success so far.\nAccording to this file  line 54:I imagine that they implemented touchevents into library.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "paulstone",
            "datetime": "Nov 22, 2016",
            "body": "Hi,I have ended up using the A-frame library instead for the kiosk I'm working on (). It works when testing it in Chrome simulating a touch PC. Just waiting to update it on the actual kiosk though to REALLY test it works though.This is basically what I have replicated on our app: On desktop/mobile you can pan around in all directions. However on touch desktop it appears to allow you to pan around left/right but NOT up/down.  Luckily in our case, there is nothing interesting to see on the floor or the ceiling so this is acceptable for us :)Hopefully this fallback/feature can/will be implemented in vrview.Thanks,\nPaul.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "paulstone",
            "datetime": "Nov 22, 2016",
            "body": "Just an update from me for completeness. The Aframe library worked on the actual touchscreen PC kiosk in that it allows us to pan left-right fully. No panning up or down, but that was ok for our purposes (nothing interesting to see up or down, thankfully).",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "borismus",
            "datetime": "Nov 22, 2016",
            "body": "The if (!Util.isMobile()) { check is incorrect. Instead, touch events\nshould event.preventDefault() to stop the mouse event from being emitted.On Tue, Nov 22, 2016 at 6:48 AM Paul Stone  wrote:",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "pszafer",
            "datetime": "Dec 6, 2016",
            "body": "Do you have plans to correct it in nearest future?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "RolandMac",
            "datetime": "Mar 12, 2017",
            "body": " Do you mind providing a bit more detail as to how to correct this issue.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "phoenix5999",
            "datetime": "Mar 15, 2017",
            "body": "Seem like it still not work until now.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "tgunz",
            "datetime": "Jun 14, 2017",
            "body": "While A-Frame is great, it's also complete overkill for those of us looking to incorporate this kind of feature into a kiosk. I'd love to help figure out how to enable touchscreen capabilities with anyone who's got the time.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lincolnfrog",
            "datetime": "Jun 20, 2017",
            "body": [],
            "type": "added  the",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/sarxos/webcam-capture/issues/704",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "edckt",
            "datetime": "Mar 26, 2019",
            "body": "I can open the webcam when first the Java file. But after doing the first mouseClicked, the second trigger of captureImage shows 'device error' on the WebcamPanel.",
            "type": "commented",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/just-ai/aimybox-android-assistant/issues/53",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "mellahysf",
            "datetime": "Aug 26, 2020",
            "body": "Hi,When i run the app demo in my device, i send my first speech (\"what time is it\"), but no reply !!\nit gives me the error below (in andoird studio) :com.justai.aimybox.core.ApiRequestTimeoutException: Request timeout: AimyboxRequest(query=what time is it, apiKey=Ldf0j7WZi3KwNah2aNeXVIACz0lb9qMH, unitId=8d456677-94d9-4a9a-afd4-fecb599b4545, data={}). Server didn't respond within 10000 ms.\nat com.justai.aimybox.api.DialogApi$send$3.invokeSuspend(DialogApi.kt:69)\nat kotlin.coroutines.jvm.internal.BaseContinuationImpl.resumeWith(ContinuationImpl.kt:33)\nat kotlinx.coroutines.ResumeModeKt.resumeUninterceptedWithExceptionMode(ResumeMode.kt:56)\nat kotlinx.coroutines.TimeoutCoroutine.afterCompletionInternal(Timeout.kt:98)\nat kotlinx.coroutines.JobSupport.completeStateFinalization(JobSupport.kt:310)\nat kotlinx.coroutines.JobSupport.tryFinalizeFinishingState(JobSupport.kt:236)\nat kotlinx.coroutines.JobSupport.tryMakeCompletingSlowPath(JobSupport.kt:849)\nat kotlinx.coroutines.JobSupport.tryMakeCompleting(JobSupport.kt:811)\nat kotlinx.coroutines.JobSupport.makeCompletingOnce$kotlinx_coroutines_core(JobSupport.kt:787)\nat kotlinx.coroutines.AbstractCoroutine.resumeWith(AbstractCoroutine.kt:111)\nat kotlin.coroutines.jvm.internal.BaseContinuationImpl.resumeWith(ContinuationImpl.kt:46)\nat kotlinx.coroutines.DispatchedTask.run(Dispatched.kt:334)\nat kotlinx.coroutines.scheduling.CoroutineScheduler.runSafely(CoroutineScheduler.kt:594)\nat kotlinx.coroutines.scheduling.CoroutineScheduler.access$runSafely(CoroutineScheduler.kt:60)\nat kotlinx.coroutines.scheduling.CoroutineScheduler$Worker.run(CoroutineScheduler.kt:740)\nD/OkHttp: <-- HTTP FAILED: java.net.SocketTimeoutException: failed to connect to api.aimybox.com/63.34.12.130 (port 443) from /10.0.8.1 (port 40158) after 10000ms",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "morfeusys",
            "datetime": "Aug 26, 2020",
            "body": "There is a timeout of the server side. Please ensure your project is alive once you've done the training (in the case you're using aimybox console)",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "mellahysf",
            "datetime": "Aug 27, 2020",
            "body": "I try the project in action in aimybox console () and it works.\nit works also in postman (by accessing  with a POST request).\nBut when I try to test it in my device (with android studio), it still gives me the same error above !! :(",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "mellahysf",
            "datetime": "Aug 27, 2020",
            "body": "I found the problem.\nit was some configurations to do in the device to allow the app to use network and mic.\nNow It works both in my device and in the emulator :D\nthank you.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "mellahysf",
            "datetime": "Aug 27, 2020",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/just-ai/aimybox-android-assistant/issues/64",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "sriramsv",
            "datetime": "Oct 3, 2021",
            "body": "I'm currently working on modifying this demo app to make it a Tasker plugin. I can send the messages the app hears now to Tasker, but I don't see any way to get the message back to the app and update the message in the UI fragment.I'm not very familiar with kotlin, so any help is appreciated!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "sriramsv",
            "datetime": "Oct 4, 2021",
            "body": "I want to achieve this flow where in the response coming from the assistant could either be initiated by an event or the request-response flow is not being called synchronously by the DialogAPI.\n  ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "sriramsv",
            "datetime": "Oct 7, 2021",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/googlearchive/vrview/issues/192",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "rsacksteder",
            "datetime": "Jun 20, 2017",
            "body": "VR view is broken in the following version of Microsoft Edge (which came with the Windows Creator Update):Microsoft Edge 40.15063.0.0\nMicrosoft EdgeHTML 15.15063Before updating, I was unable to reproduce the issue in the following version of Microsoft Edge:Microsoft Edge 38.14393.1066.0\nMicrosoft EdgeHTML 14.14393To reproduce this issue:Interestingly I noticed that the viewer at  works okay, even with the affected version of Edge. I believe the reason for this is that an older version of VR view is being used on that page.After noticing this, I used git bisect and found that commit  (\"Move to latest polyfill, but so far using the provided distortion correction\") appears to have introduced this issue in combination with whatever changes were made recently to Microsoft Edge. Prior to that commit, the viewer appears to work even in the affected version of Edge. But any versions of the viewer from that commit and newer are broken. I suspect that the mentioned commit made a change to the Edge polyfill that is not playing nicely with the latest release version of Edge.There don't appear to be any console errors to go off of and I set up a test with everything on the same origin, which didn't appear to resolve the issue, so it doesn't appear to be a cross-origin issue either.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ademarre",
            "datetime": "Jun 20, 2017",
            "body": "The panorama loads but viewport interaction with the mouse does not work.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lincolnfrog",
            "datetime": "Jun 20, 2017",
            "body": "",
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "ademarre",
            "datetime": "Aug 11, 2017",
            "body": "In Firefox 55, VR View is breaking identically to Edge 15. Interestingly, Edge 15 and Firefox 55 both introduced WebVR support. VR View works correctly when  is turned off in Firefox's advanced config.In both browsers, the older version of VR View at this URL works correctly: ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ademarre",
            "datetime": "Sep 14, 2017",
            "body": "It also breaks on Chrome if you enable WebVR in .Verified with Chrome  on Windows 8.1.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "jsantell",
            "datetime": "Sep 14, 2017",
            "body": "I think this is fixed by upgrading the webvr-polyfill to 0.9.38 that includes  that doesn't engage the polyfill when we have full native support ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lincolnfrog",
            "datetime": "Sep 15, 2017",
            "body": "Upgraded to webvr-polyfill 0.9.38",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "sportflier",
            "datetime": "Sep 19, 2017",
            "body": "On FF 32-bit 55.0.3 with webvr-polyfill 0.9.38, doesn't work.\nJavaScript errors in build/embed.js: display is undefined (var display = this.controls.getVRDisplay();)",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "jsantell",
            "datetime": "Sep 19, 2017",
            "body": " on desktop or mobile? Works for me on FF 55 (both with and without  on) ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ssh-esoteric",
            "datetime": "Sep 20, 2017",
            "body": "I think I found the root of this issue:Is it possible for VRView (or the polyfill) to register an instance of MouseKeyboardVRDisplay with the browser so that it's natively returned from getVRDisplays()? (Possibly by emitting a vrdisplayconnect event? - I'm not too familiar with the WebVR spec)A temporary workaround is to forcibly enable the polyfill:",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "jsantell",
            "datetime": "Sep 20, 2017",
            "body": "In that case, there's an option  that will need to be added -- reopening // ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "sportflier",
            "datetime": "Sep 20, 2017",
            "body": " I've seen the issue on desktop (Windows), but haven't tried yet on mobile or investigated setting .",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "benhamelin",
            "datetime": "Oct 12, 2017",
            "body": "Just cloned and built this morning, on Windows 10 (thanks to  ) .I was getting errors in both FF and Edge from the embed.js script. I compared it to  and found them to be different, so used the copy from this URL and that solved the issue. Can't tell when the build was published.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lincolnfrog",
            "datetime": "Oct 12, 2017",
            "body": "We just added some information to the README advising windows users to download the builds from the github pages link you posted. I am closing this for now.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "btb",
            "datetime": "Feb 27, 2018",
            "body": "Still broken for me, on both Firefox 58.0.2 (64-bit) and Microsoft Edge 41.16299.248.0, EdgeHTML 16.16299Forcibly enabling polyfill does make it work.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "walkthelot",
            "datetime": "Apr 18, 2018",
            "body": "Any luck on this? This is crazy. :(",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "gctommy",
            "datetime": "May 4, 2018",
            "body": "Still doesn't load on the latest Firefox.But if anyone's looking for an alternative, A-Frame works great on both the latest Chrome and Firefox (not tested on Edge): ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "mdbarr73",
            "datetime": "Oct 11, 2018",
            "body": "Firefox is still broken on version 62.0.3, image loads but pan does not work.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lincolnfrog",
            "datetime": "Jun 20, 2017",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "gol4er2219",
            "datetime": "Aug 29, 2017",
            "body": [],
            "type": "issue",
            "related_issue": "#246"
        },
        {
            "user_name": "lincolnfrog",
            "datetime": "Sep 15, 2017",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        },
        {
            "user_name": "jsantell",
            "datetime": "Sep 20, 2017",
            "body": [],
            "type": "reopened this",
            "related_issue": null
        },
        {
            "user_name": "lincolnfrog",
            "datetime": "Oct 12, 2017",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        },
        {
            "user_name": "ademarre",
            "datetime": "Dec 14, 2017",
            "body": [],
            "type": "issue",
            "related_issue": "#289"
        },
        {
            "user_name": "jsantell",
            "datetime": "Dec 15, 2017",
            "body": [],
            "type": "reopened this",
            "related_issue": null
        },
        {
            "user_name": "ademarre",
            "datetime": "May 14, 2018",
            "body": [],
            "type": "issue",
            "related_issue": "#317"
        }
    ]
},
{
    "issue_url": "https://github.com/sarxos/webcam-capture/issues/601",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "reginavaleria96",
            "datetime": "Dec 18, 2017",
            "body": "Is it possible to access and take picture from a phone connected through  using this project?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "sarxos",
            "datetime": "Dec 18, 2017",
            "body": "Hi ,It seems you can, but I don't know the exact URL to be used with . This is the claim from their web page:When you already know what is the URL to access MJPEG stream from the camera you can take a look at the IP camera examples of Webcam Capture to learn more on how to integrate it into your solution:Please let me know if you have any further questions.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "sarxos",
            "datetime": "Dec 19, 2017",
            "body": ", FYI, I found information on MJPEG here:Check this section: .",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "neilyoung",
            "datetime": "Dec 19, 2017",
            "body": " Just out of curiosity: Would it be possible to  from such a cam?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "sarxos",
            "datetime": "Dec 20, 2017",
            "body": ", yes, but the performance will be much below what you can get with UVC (USB). This is due to:In addition to 2, you can skip this and get RAW bytes, but these won't be RGB, but a JPEG frame, which you will have to convert to RGB to have compatibility with  (thus doing the same what  is doing underneath).",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "neilyoung",
            "datetime": "Dec 20, 2017",
            "body": " Clear and understandable. Thanks for the explanations. Merry Christmas to you and thanks too for all your efforts.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "reginavaleria96",
            "datetime": "Jan 10, 2018",
            "body": "I have included webcam-capture-0.3.12-20171103.095135-4.jar in my library but I'm getting  and \nWhere can I find IpCamDeviceRegistry and IpCamMode?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "sarxos",
            "datetime": "Jan 10, 2018",
            "body": ", use these JARs: ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "sarxos",
            "datetime": "Jan 10, 2018",
            "body": "And remove webcam-capture-0.3.12-20171103.095135-4.jar beforehand. The zip I posted above, already contains newest webcam-capture dependency.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "sarxos",
            "datetime": "Jan 10, 2018",
            "body": ", and one more missing JAR file: ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "reginavaleria96",
            "datetime": "Jan 18, 2018",
            "body": "Thanks for the JARs!\nDo you mind explaining why is it necessary to have\n\n( line 57 onward)?and do webcam.open() and webcam.close() work the same way for IPcam?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "sarxos",
            "datetime": "Jan 18, 2018",
            "body": "Hi ,In regards to your questions:This is the code which is executed when action is performed on a \"Snapshot\" button. When you click this button the  will iterate over all  instances in  list, get image and save it to file with . The file names will be , , , etc (as many as you have webcams). Without this code you would not have ability to save images into files.And in regards to:No. The  and  works in a different for IP cameras when you compare to  webcam.In case of classic webcam (the ) when you invoke  then hardware device is turned on (LED is powered) and USB capacity is allocated to stream image frames. After you invoke  the USB capacity is released and UVC device is turned off. There is a direct connection between UVC being turned on/off and the webcam state (unless something is broken).The  from the other hand is always turned on, unless you turn it off with a manual switch, a power cord or administration panel. In this case when you invoke  a persistent HTTP connection is made which is used to stream MJPEG frames from camera to your computer, but this is done with the IP/TCP instead of USB (as in case of UVC). Then, when you invoke , the webcam is not turned off, but the HTTP connection is closed instead and IP camera device remains active.This is a difference. I hope I was able to describe it in a understandable way.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "sarxos",
            "datetime": "Jan 18, 2018",
            "body": "Just for your information, if you would like to avoid managing JARs manually, I suggest you to take a look at .Maven is a tool to build Java projects and manage JAR dependencies. It may be a little hard to learn at the beginning, but there a dozens of tutorials on the internet. The ZIP bundles I sent you are also a list of files prepared by Maven.The more JARs you have in the project the higher chance you will have to use some dependency manager (Maven, Gradle or Ivy). When Java project grows in time it comes into the point where managing JARs manually is impossible (due to massive amount of incompatible libraries).My Webcam Capture API project is also managed and build with Maven.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "reginavaleria96",
            "datetime": "Jan 18, 2018",
            "body": " Thank you for your explanation, it was clear and understandable. I was confused about the webcam iteration, that was why I had to ask. I hope you don't mind.If I have the default onboard webcam on my laptop and an IP camera connected via droidCam, how do I tell the program to specifically take one picture from my DroidCam camera?And thank you for sharing about Maven, I have heard of it and had considered using it. My mistake was thinking that my small project won't have so many libraries and deciding to manage them manually, but now I know that I was wrong :')",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "sarxos",
            "datetime": "Jan 18, 2018",
            "body": "In regards to:Yes, sorry for this. The code I initially wrote was to support multiple cameras, but finally I left only one IP camera in the code.You have to use composite driver to \"compose\" two drivers into one, example:You set it in the same way as you would do it with a different drivers:You can access cameras by index so the ones from first driver will be first one the list (e.g. index 0), and the ones from second driver will be added later (e.g. index 1, 2, 3, etc).The other option is to use camera names, but this may be tricky on Windows since it may work well on your computer, but different computers may have different camera names. In Linux this is simple because on different computers every all cameras are simply , , etc, and on Windows this can be , , etc. depending on the webcam hardware.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "reginavaleria96",
            "datetime": "Jan 18, 2018",
            "body": "Thanks, that is one helpful explanation! I am going to try it now. I hope you don't mind if I still have more questions in the future.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "sarxos",
            "datetime": "Jan 18, 2018",
            "body": "If you link your carrier with Java then Maven is a tool you have to, at least, be familiar with. It has thousands of plugins and configuration options which may be overwhelming at the beginning because different people on the internet may suggest different solution, but after you understand how it works it will become one of the fundamental tools in your toolbox.When you want to manage you project with Maven it's enough to put  file in the project main directory.The simplest example for your project can be:Instead of providing many JARs I only had to add one dependency in the XML, that is:And when I  into the project and run  I can see what JARs are used:Which will display all JARs required by your project:And e.g. if I want to export all required JARs together with your own application JAR I can do the following:And all JARs will be magically be placed in a  directory:I spent many years working in a terminal environments and I'm used to do things from command line, but the same can be done from a decent IDEs, e.g. Eclipse or IntelliJ.For example when you are using Eclipse IDE for Java EE Developers (basic Eclipse installation does not have Maven plugin installed) you can create Maven project from the mouse menu and manage dependencies with a very nice POM editor.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "sarxos",
            "datetime": "Jan 18, 2018",
            "body": "And one last thing - almost all (probably 99.99%) of all decent Java frameworks and libraries are deployed into Maven Central repository which is used as a source from where all dependencies are downloaded.Jersey, JBoss, Hibernate, JSP, all Apache Commons, SL4J, Logback, Jetty, Netty, Vavr, Akka, and of course Webcam Capture API, all are available from Maven.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "avatar31",
            "datetime": "Jan 29, 2018",
            "body": "Hello Sir,\nI am trying to use  as a Webcam. The program is identifying the device but it not showing the panel. I referred  example. Please help me.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "sarxos",
            "datetime": "Jan 29, 2018",
            "body": "",
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "avatar31",
            "datetime": "Jan 29, 2018",
            "body": "Yes, I am able to view the Image in browser. I didn't make any changes to the code. I just copied the code from example program. Here is the code.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "sarxos",
            "datetime": "Jan 30, 2018",
            "body": "Hi ,If you can view it in browser and you can't in a Java code, means that your code is broken. The URL you provided to IP cam driver:Points to a web page, not MJPEG stream! A static HTML, nothing to stream video feed from. Please take a look at the DridCam web page and ! You will find this information:Therefore, your code should be fixed to use proper URL:I installed DroidCam and easily found it myself by checking what is the image source (just press F12 in Firefox):This is my code:And it works perfectly well:After reading this far please also take a look at the problem I described below.I noticed that you can connect  to the DroidCam. Therefore if you have your DroidCam web page open in a browser you  to view it from code and vice versa - when you have your DroidCam streaming open from the Java code, you won't be able to view it in a browser. This is DroidCam limitation, not the Webcam Capture issue.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "avatar31",
            "datetime": "Jan 31, 2018",
            "body": "Thank You very much Sir. Now it is working",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "sarxos",
            "datetime": "Dec 19, 2017",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "sarxos",
            "datetime": "Jan 30, 2018",
            "body": [],
            "type": "",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/just-ai/aimybox-android-assistant/issues/58",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "krauzee",
            "datetime": "Nov 2, 2020",
            "body": "When I click on mic button my app is crashing with error:\nInflateException: Binary XML file line : Binary XML file line : You must supply a layout_width attribute.\nCaused by: java.lang.UnsupportedOperationException: Bin\nary XML file line : You must supply a layout_width attribute.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "krauzee",
            "datetime": "Nov 2, 2020",
            "body": "Full stacktrace:android.view.InflateException: Binary XML file line : Binary XML file line : You must supply a layout_width attribute.\nCaused by: java.lang.UnsupportedOperationException: Binary XML file line : You must supply a layout_width attribute.\nat android.content.res.TypedArray.getLayoutDimension(TypedArray.java:767)\nat android.view.ViewGroup$LayoutParams.setBaseAttributes(ViewGroup.java:7036)\nat android.view.ViewGroup$MarginLayoutParams.(ViewGroup.java:7218)\nat androidx.recyclerview.widget.RecyclerView$LayoutParams.(RecyclerView.java:11905)\nat androidx.recyclerview.widget.RecyclerView$LayoutManager.generateLayoutParams(RecyclerView.java:8591)\nat androidx.recyclerview.widget.RecyclerView.generateLayoutParams(RecyclerView.java:4611)\nat android.view.LayoutInflater.inflate(LayoutInflater.java:509)\nat android.view.LayoutInflater.inflate(LayoutInflater.java:430)\nat com.justai.aimybox.components.extensions.ViewKt.inflate(View.kt:22)\nat com.justai.aimybox.components.extensions.ViewKt.inflate$default(View.kt:21)\nat com.justai.aimybox.components.adapter.ResponseDelegate.createViewHolder(ResponseDelegate.kt:15)\nat com.justai.aimybox.components.adapter.ResponseDelegate.createViewHolder(ResponseDelegate.kt:11)\nat com.justai.aimybox.components.base.DelegatedAdapter.onCreateViewHolder(DelegatedAdapter.kt:37)\nat com.justai.aimybox.components.base.DelegatedAdapter.onCreateViewHolder(DelegatedAdapter.kt:8)\nat androidx.recyclerview.widget.RecyclerView$Adapter.createViewHolder(RecyclerView.java:7216)\nat androidx.recyclerview.widget.RecyclerView$Recycler.tryGetViewHolderForPositionByDeadline(RecyclerView.java:6347)\nat androidx.recyclerview.widget.RecyclerView$Recycler.getViewForPosition(RecyclerView.java:6231)\nat androidx.recyclerview.widget.RecyclerView$Recycler.getViewForPosition(RecyclerView.java:6227)\nat androidx.recyclerview.widget.LinearLayoutManager$LayoutState.next(LinearLayoutManager.java:2330)\nat androidx.recyclerview.widget.LinearLayoutManager.layoutChunk(LinearLayoutManager.java:1631)\nat androidx.recyclerview.widget.LinearLayoutManager.fill(LinearLayoutManager.java:1591)\nat androidx.recyclerview.widget.LinearLayoutManager.onLayoutChildren(LinearLayoutManager.java:668)\nat androidx.recyclerview.widget.RecyclerView.dispatchLayoutStep2(RecyclerView.java:4230)\nat androidx.recyclerview.widget.RecyclerView.dispatchLayout(RecyclerView.java:3941)\nat androidx.recyclerview.widget.RecyclerView.onLayout(RecyclerView.java:4499)\nat android.view.View.layout(View.java:17666)\nat android.view.ViewGroup.layout(ViewGroup.java:5577)\nat android.widget.FrameLayout.layoutChildren(FrameLayout.java:323)\nat android.widget.FrameLayout.onLayout(FrameLayout.java:261)\nat com.justai.aimybox.components.view.AimyboxButton.onLayout(AimyboxButton.kt:367)\nat android.view.View.layout(View.java:17666)\nat android.view.ViewGroup.layout(ViewGroup.java:5577)\nat android.widget.FrameLayout.layoutChildren(FrameLayout.java:323)\nat android.widget.FrameLayout.onLayout(FrameLayout.java:261)\nat android.view.View.layout(View.java:17666)\nat android.view.ViewGroup.layout(ViewGroup.java:5577)\nat android.widget.FrameLayout.layoutChildren(FrameLayout.java:323)\nat android.widget.FrameLayout.onLayout(FrameLayout.java:261)\nat android.view.View.layout(View.java:17666)\nat android.view.ViewGroup.layout(ViewGroup.java:5577)\nat android.widget.FrameLayout.layoutChildren(FrameLayout.java:323)\nat android.widget.FrameLayout.onLayout(FrameLayout.java:261)\nat android.view.View.layout(View.java:17666)\nat android.view.ViewGroup.layout(ViewGroup.java:5577)\nat android.widget.FrameLayout.layoutChildren(FrameLayout.java:323)\nat android.widget.FrameLayout.onLayout(FrameLayout.java:261)\nat android.view.View.layout(View.java:17666)\nat android.view.ViewGroup.layout(ViewGroup.java:5577)\nat android.widget.LinearLayout.setChildFrame(LinearLayout.java:1741)\n2020-11-02 13:30:09.558 1383-1383/ru.akbarslife.akbars E/AndroidRuntime:     at android.widget.LinearLayout.layoutVertical(LinearLayout.java:1585)\nat android.widget.LinearLayout.onLayout(LinearLayout.java:1494)\nat android.view.View.layout(View.java:17666)\nat android.view.ViewGroup.layout(ViewGroup.java:5577)\nat android.widget.FrameLayout.layoutChildren(FrameLayout.java:323)\nat android.widget.FrameLayout.onLayout(FrameLayout.java:261)\nat android.view.View.layout(View.java:17666)\nat android.view.ViewGroup.layout(ViewGroup.java:5577)\nat android.widget.LinearLayout.setChildFrame(LinearLayout.java:1741)\nat android.widget.LinearLayout.layoutVertical(LinearLayout.java:1585)\nat android.widget.LinearLayout.onLayout(LinearLayout.java:1494)\nat android.view.View.layout(View.java:17666)\nat android.view.ViewGroup.layout(ViewGroup.java:5577)\nat android.widget.FrameLayout.layoutChildren(FrameLayout.java:323)\nat android.widget.FrameLayout.onLayout(FrameLayout.java:261)\nat com.android.internal.policy.DecorView.onLayout(DecorView.java:730)\nat android.view.View.layout(View.java:17666)\nat android.view.ViewGroup.layout(ViewGroup.java:5577)\nat android.view.ViewRootImpl.performLayout(ViewRootImpl.java:2390)\nat android.view.ViewRootImpl.performTraversals(ViewRootImpl.java:2112)\nat android.view.ViewRootImpl.doTraversal(ViewRootImpl.java:1298)\nat android.view.ViewRootImpl$TraversalRunnable.run(ViewRootImpl.java:6437)\nat android.view.Choreographer$CallbackRecord.run(Choreographer.java:876)\nat android.view.Choreographer.doCallbacks(Choreographer.java:688)\nat android.view.Choreographer.doFrame(Choreographer.java:623)\nat android.view.Choreographer$FrameDisplayEventReceiver.run(Choreographer.java:862)\nat android.os.Handler.handleCallback(Handler.java:754)\nat android.os.Handler.dispatchMessage(Handler.java:95)\nat android.os.Looper.loop(Looper.java:163)\nat android.app.ActivityThread.main(ActivityThread.java:6238)\nat java.lang.reflect.Method.invoke(Native Method)\nat com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:933)\nat com.android.internal.os.ZygoteInit.main(ZygoteInit.java:823)my build.gradle:android {\ncompileSdkVersion 29\nbuildToolsVersion \"29.0.3\"}dependencies {//Aimylogic integration\nimplementation(\"com.justai.aimybox:google-platform-speechkit:0.14.0\")\nimplementation(\"com.justai.aimybox:core:0.14.0\")\nimplementation(\"com.justai.aimybox:components:0.1.9\")\n}In the app and activity class, I did everything exactly according to the instructions.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "morfeusys",
            "datetime": "Nov 3, 2020",
            "body": "Please provide your Android version",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "krauzee",
            "datetime": "Nov 3, 2020",
            "body": "MIUI 11.0.2 Android 7.1.2",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Neerav006",
            "datetime": "Nov 4, 2020",
            "body": "Just put these styles in theme.xml file it should work",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "krauzee",
            "datetime": "Nov 19, 2020",
            "body": "I added this to my styles.xml\nbut I still get the error. What am I doing wrong?\n",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Billthebest1",
            "datetime": "Nov 19, 2020",
            "body": "youre in better shape than me im compleatly new to this have android studio and dont have a clue on how to get a assisstant app to work lol ive tryied them all  this one seems the closest to the one i had but google got rid of  it even works with dialogue flo  but i cant get it to work im missing something in the instructions on how to do it and every time i try i end up downloading more and more software it went from android studio to github desktop to some thing that starts with z i cant think of the name atm  i just want a assisstant app like the one i paid for the one by speaktoit that one was perfect it was eficiant ran everything so useful af plus customizable and funny and its like im going to have to take 8 years of college in order to get it back",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "morfeusys",
            "datetime": "Nov 22, 2020",
            "body": " are you sure you've applied this style in your AndroidManifest?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "krauzee",
            "datetime": "Dec 1, 2020",
            "body": "I solved this problem, thanks",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "morfeusys",
            "datetime": "Dec 2, 2020",
            "body": " did my suggest help you or you've found another solution?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "krauzee",
            "datetime": "Dec 2, 2020",
            "body": "your suggestion helped me, thanks!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "krauzee",
            "datetime": "Dec 1, 2020",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/just-ai/aimybox-android-assistant/issues/52",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "mellahysf",
            "datetime": "Aug 24, 2020",
            "body": "Hi,\nI want to run the demo, but both in a device and emulator (in android studio),  when I click on the mic button, it doesn't work !!\nWhen I click on the mic button, it cancels quickly and I can't send the speech.Thank you for your help !Below the trace given to me in the android studio :I/Aimybox(Aimybox-Components): [main] STANDBY\nI/Aimybox(STT): [DefaultDispatcher-worker-4] Begin recognition\nI/Aimybox(Aimybox-Components): [main] LISTENING\nE/Aimybox(STT): [DefaultDispatcher-worker-3] Failed to get recognition result\ncom.justai.aimybox.speechkit.google.platform.GooglePlatformSpeechToTextException: Exception [3]: Audio recording error.\nat com.justai.aimybox.speechkit.google.platform.GooglePlatformSpeechToText$createRecognitionListener$1.onError(GooglePlatformSpeechToText.kt:77)\nat android.speech.SpeechRecognizer$InternalListener$1.handleMessage(SpeechRecognizer.java:450)\nat android.os.Handler.dispatchMessage(Handler.java:107)\nat android.os.Looper.loop(Looper.java:214)\nat android.app.ActivityThread.main(ActivityThread.java:7356)\nat java.lang.reflect.Method.invoke(Native Method)\nat com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:492)\nat com.android.internal.os.ZygoteInit.main(ZygoteInit.java:930)\nE/Aimybox(Aimybox-Components): [main]\ncom.justai.aimybox.speechkit.google.platform.GooglePlatformSpeechToTextException: Exception [3]: Audio recording error.\nat com.justai.aimybox.speechkit.google.platform.GooglePlatformSpeechToText$createRecognitionListener$1.onError(GooglePlatformSpeechToText.kt:77)\nat android.speech.SpeechRecognizer$InternalListener$1.handleMessage(SpeechRecognizer.java:450)\nat android.os.Handler.dispatchMessage(Handler.java:107)\nat android.os.Looper.loop(Looper.java:214)\nat android.app.ActivityThread.main(ActivityThread.java:7356)\nat java.lang.reflect.Method.invoke(Native Method)\nat com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:492)\nat com.android.internal.os.ZygoteInit.main(ZygoteInit.java:930)\nI/Aimybox(Aimybox-Components): [main] STANDBY",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "mellahysf",
            "datetime": "Aug 26, 2020",
            "body": "now It works fine in my device but doesn't in emulator android studio",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "mellahysf",
            "datetime": "Aug 27, 2020",
            "body": "And now it works also in the emulator.\nSome configurations were required at the emulator to allow access to the network and microphone.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "mellahysf",
            "datetime": "Aug 27, 2020",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/just-ai/aimybox-android-assistant/issues/42",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "morfeusys",
            "datetime": "Nov 12, 2019",
            "body": "Aimybox  could be invoked from everywhere of the application. Not only by clicking on the mic button, but also through the voice trigger event or any other trigger (camera, sensors, etc). Thus  should appear once a recognition event is fired.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "morfeusys",
            "datetime": "Dec 28, 2019",
            "body": [],
            "type": "issue",
            "related_issue": null
        },
        {
            "user_name": "morfeusys",
            "datetime": "Dec 28, 2019",
            "body": [],
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "morfeusys",
            "datetime": "Jan 20, 2020",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/just-ai/aimybox-android-assistant/issues/14",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "morfeusys",
            "datetime": "Aug 15, 2019",
            "body": "Make it possible to configure any labels of Aimybox fragment through  for example as well as styles.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "morfeusys",
            "datetime": "Oct 2, 2019",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/just-ai/aimybox-android-assistant/issues/48",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "kvbulusu",
            "datetime": "Mar 11, 2020",
            "body": "I'm new to android and a newbie qn. Along with voice, how can I add a text so users can type too?  In your example/demo code what should I change?  I want to have both voice and text... I'm using rasa nlu stack....",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "morfeusys",
            "datetime": "Mar 11, 2020",
            "body": "You have to implement text input UI on your side and add it to your application. Once the user inputs some text, it should be passed to send() method of Aimybox. All other work will be done under the hood.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "kvbulusu",
            "datetime": "Mar 11, 2020",
            "body": [],
            "type": "changed the title",
            "related_issue": null
        },
        {
            "user_name": "kvbulusu",
            "datetime": "Mar 11, 2020",
            "body": [],
            "type": "changed the title",
            "related_issue": null
        },
        {
            "user_name": "morfeusys",
            "datetime": "Mar 11, 2020",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/just-ai/aimybox-android-assistant/issues/9",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "morfeusys",
            "datetime": "Aug 8, 2019",
            "body": "Now there are some required components with versions from . This requires one more module to start using Aimybox SDK. Is it possible to simplify build.gradle to get rid of additional module?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lambdatamer",
            "datetime": "Aug 12, 2019",
            "body": [],
            "type": "self-assigned this",
            "related_issue": null
        },
        {
            "user_name": "lambdatamer",
            "datetime": "Aug 15, 2019",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/just-ai/aimybox-android-assistant/issues/64",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "sriramsv",
            "datetime": "Oct 3, 2021",
            "body": "I'm currently working on modifying this demo app to make it a Tasker plugin. I can send the messages the app hears now to Tasker, but I don't see any way to get the message back to the app and update the message in the UI fragment.I'm not very familiar with kotlin, so any help is appreciated!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "sriramsv",
            "datetime": "Oct 4, 2021",
            "body": "I want to achieve this flow where in the response coming from the assistant could either be initiated by an event or the request-response flow is not being called synchronously by the DialogAPI.\n  ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "sriramsv",
            "datetime": "Oct 7, 2021",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/just-ai/aimybox-android-assistant/issues/70",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "Di-Zayn",
            "datetime": "May 15, 2022",
            "body": "Hello, I'm running the code in master branch but it failed. Here is the error in logs:\n\nIs it because of the region that I can't use Google's services?(I'm in China)",
            "type": "commented",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/just-ai/aimybox-android-assistant/issues/65",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "chinaandylee",
            "datetime": "Oct 29, 2021",
            "body": "when i run the this app on mobile phone, the memory continues to grow and is not released. I don't know why. Here ask for help.\n",
            "type": "commented",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/just-ai/aimybox-android-assistant/issues/63",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "wahyouwebid",
            "datetime": "Apr 16, 2021",
            "body": "I have used Kaldi to trigger the speech but it doesn't work, I still have to click the button first\n\nplease for the solution, thank you",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "rubycho",
            "datetime": "Apr 16, 2021",
            "body": "Though this comment is not the answer for your question, I suggest you to hide your API KEY on your screenshot.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "wahyouwebid",
            "datetime": "Apr 16, 2021",
            "body": "on the github there is also API KEY, this is proof\n",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "rubycho",
            "datetime": "Apr 16, 2021",
            "body": "Oh it was the key from the repo. I thought it was your own key. Sorry.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "cdhiraj40",
            "datetime": "Mar 18, 2022",
            "body": "hey,  did you find a solution for this?",
            "type": "commented",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/just-ai/aimybox-android-assistant/issues/61",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "Tedcas",
            "datetime": "Feb 11, 2021",
            "body": "Hi,I'm working in a new project where I need a custom voice assistant in my android app. I tried this example  and everything works perfectly, however, if I go from MainActivity to another activity and I try to load the assistant on this new activity, tts, stt and wake word doesn't work, I press the floating button and the assitant does its animation, but thats all, my question is, How can I implement something like the example project but extending the assistant in all the activities?Thank you very much in advance.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bgubanov",
            "datetime": "Feb 12, 2021",
            "body": "Hello!\nAre you initializing the Aimybox object from the Application instance, like in the example?\nCan you send code snippet with the second activity?\nI added second activity to example project, copied code of first activity and everything started correctly on each of activities.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Billthebest1",
            "datetime": "Feb 12, 2021",
            "body": "",
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "Tedcas",
            "datetime": "Feb 14, 2021",
            "body": "Hi, first of all many thanks for your reply ¡, I'm sorry I couldn't reply you earlier, answering your question, yes I'm initializing the Aimybox object from Application instance like the example, here is my code for that I've modified it a little bit to adjust to my project:class AimyboxApplication : Application(), AimyboxProvider {And this is the class I use to create the Assistant in every class of my project:class VoiceAssistant constructor(context: Context, container: Int) : Serializable, ActivitiesFather() {So in Activity 1 I call the following methods on onCreate():And then in the next activity I do the same (I simplified this step, calling those two statements in the father of all the Activities of my project)I'm not sure what I'm doing wrong, I must admit I'm not used to Kotlin (nowadays I'm learning the language) and I could make a misstake there.Again many thanks for your help in advance.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Tedcas",
            "datetime": "Apr 23, 2021",
            "body": "Hi, it's been a while since my last posr, after doing some tests I've realized that the problem only happens when I use KaldiVoiceTrigger with the TTS, STT and DialogApi together, if I disable the KaldiVoiceTrigger system, all works perfectly. I've try updating all the dependencies to the last version, but nothing change.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "cdhiraj40",
            "datetime": "Jul 5, 2022",
            "body": "does KaldiVoiceTrigger work perfectly for you folks?  \nFor me, it just triggers every time I say anything! Let me know thanks.",
            "type": "commented",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/just-ai/aimybox-android-assistant/issues/59",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "krauzee",
            "datetime": "Dec 1, 2020",
            "body": "I wanna custom ui. I wanna see messages from user on right and I ovveride \"gravity\" attribute, but its not works:(\nAny help is appreciated.\n1",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bgubanov",
            "datetime": "Dec 2, 2020",
            "body": "Hello, please try using android:layout_gravity instead of android:gravity",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "krauzee",
            "datetime": "Dec 2, 2020",
            "body": "Hello! I tried using \"android:layout_gravity\" but it also doesn't work:(",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "bgubanov",
            "datetime": "Dec 2, 2020",
            "body": "Have you overrided android:gravity attribute of parent layout? If yes, try to delete it. I tried your case with your params on default layout and it worked",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "krauzee",
            "datetime": "Dec 2, 2020",
            "body": "do you mean by parent_layout is \"aimybox_container\"? Can you show me your code please?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "krauzee",
            "datetime": "Dec 3, 2020",
            "body": "Please, try to set attr \"layout_width\" to wrap_content, after this attr gravity and layout_gravity was no work",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "morfeusys",
            "datetime": "Dec 3, 2020",
            "body": " we have published a new version of components. Please try to use  and then update your styles like:",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "krauzee",
            "datetime": "Dec 3, 2020",
            "body": "Gradle can't download components-0.1.10\nEndless loading occurs:(so already 20 minutes\n",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "morfeusys",
            "datetime": "Dec 3, 2020",
            "body": "You can check that it's available via jcenter normally.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "morfeusys",
            "datetime": "Dec 3, 2020",
            "body": [],
            "type": "pull",
            "related_issue": "#60"
        },
        {
            "user_name": "just-ai",
            "datetime": "Dec 4, 2020",
            "body": [],
            "type": "deleted a comment from",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/just-ai/aimybox-android-assistant/issues/55",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "mellahysf",
            "datetime": "Sep 4, 2020",
            "body": "Hi,I made a chatbot with english language and i integrated it with aimybox and its works.\nNow i want to use the same chatbot but with french language (maybe with using translator API !! but how to do that ?)Thanks for help !",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "morfeusys",
            "datetime": "Sep 9, 2020",
            "body": "Aimybox console supports only English and Russian languages for now. You could create another chatbot using any other supported tools like Dialogflow or Rasa and connect your Aimybox based application directly to it using an appropriate library from Aimybox repostory.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "mellahysf",
            "datetime": "Sep 9, 2020",
            "body": "Thanks  for your reply.\nYes im created 2 chatbots in Rasa; One in english and another in french language. But how to distinguish between them in the aimAbox based application? In term of speech to text and text to speech methods, we specify only one local language !!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "morfeusys",
            "datetime": "Sep 9, 2020",
            "body": " you can create two separate Rasa webhooks and determine language on the application starting and initialise Aimybox with an appropriate webhook URL.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "mellahysf",
            "datetime": "Sep 22, 2020",
            "body": " can you tell me please how can I add 2 buttons in running Aimybox, and according to the clicked button call an appropriate URL (treatment should be in the method createAimybox of class AimyboxApplication of file AimyboxApplication.kt) ?",
            "type": "commented",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/just-ai/aimybox-android-assistant/issues/54",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "mellahysf",
            "datetime": "Sep 4, 2020",
            "body": "Hi,I'm looking for Arabic speech recognition.\nGooglePlatformTextToSpeech(context, Locale.ENGLISH) does not support arabic text to speech.Thanks",
            "type": "commented",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/just-ai/aimybox-android-assistant/issues/47",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "lewisccx",
            "datetime": "Jan 31, 2020",
            "body": "Hi When I click the button link from dialogflow API, it auto dismiss itself instead of opening the link in browser, how do I solve that?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Neerav006",
            "datetime": "Nov 4, 2020",
            "body": "Same issue here",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "morfeusys",
            "datetime": "Jan 31, 2020",
            "body": [],
            "type": "transferred this issue from just-ai/aimybox-android-sdk",
            "related_issue": null
        },
        {
            "user_name": "morfeusys",
            "datetime": "Jan 31, 2020",
            "body": [],
            "type": "changed the title",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/just-ai/aimybox-android-assistant/issues/46",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "babat00nday",
            "datetime": "Dec 28, 2019",
            "body": "The demo app works fine when I push to my android device. However, when I try to test on my Android Studio device, the speech recognition functionality does not work. It cancels as soon as I click on the microphone button.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "achernin",
            "datetime": "Jul 14, 2020",
            "body": [],
            "type": "pull",
            "related_issue": "#49"
        }
    ]
},
{
    "issue_url": "https://github.com/just-ai/aimybox-android-assistant/issues/37",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "lambdatamer",
            "datetime": "Oct 14, 2019",
            "body": "Some modules (like Snowboy VT & Google Cloud) requires access to external storage. We need to find a way to check/request the mic and storage permissions before VT start.",
            "type": "commented",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/just-ai/aimybox-android-assistant/issues/36",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "morfeusys",
            "datetime": "Oct 2, 2019",
            "body": "Need to have a way to add custom widgets that could be rendered by the Aimybox's fragment.\nWould be great to have a single place where the user can add their map of  ->  (or something like that) during the  initialisation.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "chinaandylee",
            "datetime": "Oct 29, 2021",
            "body": "The same needs are in front of me. Is there any update?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "morfeusys",
            "datetime": "Oct 2, 2019",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "morfeusys",
            "datetime": "Oct 2, 2019",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "morfeusys",
            "datetime": "Jan 21, 2020",
            "body": [],
            "type": "unassigned",
            "related_issue": null
        },
        {
            "user_name": "just-ai",
            "datetime": "Sep 4, 2020",
            "body": [],
            "type": "deleted a comment from",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/allenai/allennlp/issues/5700",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "tianliuxin",
            "datetime": "Aug 11, 2022",
            "body": "allennlp.common.params.Params only implentment , I think implenmenting  will be better.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "github-actions",
            "datetime": "Aug 25, 2022",
            "body": "This issue is being closed due to lack of activity. If you think it still needs to be addressed, please comment on this thread ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "tianliuxin",
            "datetime": "Aug 11, 2022",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "github-actions",
            "datetime": "Aug 25, 2022",
            "body": [],
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "github-actions",
            "datetime": "Aug 25, 2022",
            "body": [],
            "type": "",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/allenai/allennlp/issues/5637",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "eraldoluis",
            "datetime": "May 21, 2022",
            "body": "\n metric () returns a dictionary with three keys: ,  and . Under each key, a list comprises the corresponding values for each class/label. This is problematic for some logging plugins (TensorBoard and Weight&Bias, for instance) because these plugins assume that each metric key comprises one unique value. In fact, W&B can work with lists, but it is usually less convenient (it is harder to choose a specific metric to plot, for instance).Another problem is that you need to choose between having the individual values for each class or the average, but not both. If you choose to have the average, the per-class values are not returned.\nI have implemented a class called  that solve this by returning a dictionary with keys:where  is the index (or the label) of the class and  is the (optional) requested average (micro, macro or weighted). You can even request more than one average.This implementation just overrides the (...) and get_metric(...) methods. The (...) method is the same because it provides all the necessary counts. It is just the output of get_metric(...) that is not convenient in some cases.\nNone.\nThis problem occurred to me when I was implementing a solution for issue ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "eraldoluis",
            "datetime": "May 21, 2022",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "eraldoluis",
            "datetime": "May 21, 2022",
            "body": [],
            "type": "pull",
            "related_issue": "#5638"
        },
        {
            "user_name": "dirkgr",
            "datetime": "Jun 2, 2022",
            "body": [],
            "type": "pull",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/allenai/allennlp/issues/5620",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "jacoby149",
            "datetime": "Apr 13, 2022",
            "body": "\nI would like to fine tune the following model : \nI would like to fine tune it on squad data.\nHowever there is no documentation that explains how to fine tune allen ai models from huggingface.\nI think there is an opportunity here to make allenNLP much more easy to use and convenient.\nI would like a documentation page that has clear instructions on how to fine tune any of the allenAI hugging face models.\nI tried using the allenAI command line, but I struggle without a documentation example.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "AkshitaB",
            "datetime": "Apr 18, 2022",
            "body": " Thank you for the request. Here's our config for training the transformer qa model: This will finetune the roberta-large model for the task. If you wish to start with the trained transformer_qa model itself, you can modify the config as follows:We are no longer focused on adding new features to the allennlp library/docs, but will be happy to review contributions and/or provide further assistance in debugging.Also checkout the allennlp guide here: ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "github-actions",
            "datetime": "Apr 27, 2022",
            "body": "This issue is being closed due to lack of activity. If you think it still needs to be addressed, please comment on this thread ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "jacoby149",
            "datetime": "Apr 13, 2022",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "github-actions",
            "datetime": "Apr 27, 2022",
            "body": [],
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "github-actions",
            "datetime": "Apr 27, 2022",
            "body": [],
            "type": "",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/allenai/allennlp/issues/5597",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "tarohi24",
            "datetime": "Mar 13, 2022",
            "body": "Hello, is called inside  () . If I understand correctly, the method does some sanity checks by comparing a pair of token ids that should be different from each other.The current implementation compares  or , but both of the pairs don't work for some Japanese pre-trained tokenizers. For example, the vocabulary of the  contains none of  because it only accepts full-width characters.So I'd like to pass a custom pair to  by adding a parameter to . I'm ready to make a PR, but I opened this issue to make sure that it's a good approach.Thanks,",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Mar 22, 2022",
            "body": "Hi , yes please go ahead with that PR and feel free to tag me for a review when you open it ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "tarohi24",
            "datetime": "Mar 26, 2022",
            "body": "Sure I'll do that soon!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "tarohi24",
            "datetime": "Mar 31, 2022",
            "body": "HI  , I made a PR for this. It looks like I cannot assign a reviewer for some reasons. Could you check that? Thank you!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "tarohi24",
            "datetime": "Mar 13, 2022",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Mar 22, 2022",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "tarohi24",
            "datetime": "Mar 26, 2022",
            "body": [],
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "tarohi24",
            "datetime": "Mar 26, 2022",
            "body": [],
            "type": "pull",
            "related_issue": "#5608"
        },
        {
            "user_name": "dirkgr",
            "datetime": "Apr 8, 2022",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/allenai/allennlp/issues/5614",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "vikigenius",
            "datetime": "Apr 5, 2022",
            "body": "Currently looking at the discussion here  and the code It seems like you have to manually wrap each individual unit of partition.Looking at the tutorial for fairscale: \nThere is an  function that automatically wraps each submodule for you. This is incredibly convenient if you would just like to wrap a huge pretrained transformer embedder yourself.Is there a possibility of providing an option to auto_wrap modules?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Apr 6, 2022",
            "body": "We could definitely add support for that. I'm happy to review a PR.In the meantime you could just  the whole module. There might not be much of a performance difference between -ing it and -ing it.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "vikigenius",
            "datetime": "Apr 6, 2022",
            "body": "Sure, I will work on a PR.I am curious behind your statement that there is not much of a difference between wrap and auto-wrap. Can you elaborate?From my understanding when you wrap a whole module, it will overlap the all gather step only in the final step and all the parameters needed by the whole module should be present in each GPU.However, if you use auto_wrap you will be wrapping each layer/submodule and only the parameters for a particular layer need to be in the GPU at any given time. This seems like it will be slower but a lot more memory efficient ?Am I missing something here, or is my understanding wrong?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Apr 6, 2022",
            "body": "I think you're correct. But the FairScale docs actually say that this will \"improve training speed by overlapping the all-gather step across the forward pass.\" I'm not entirely sure what that means / how sharding individual layers would speed things up. But it does make sense that it would save a lot of memory.So, ignore my previous comment.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "github-actions",
            "datetime": "Apr 25, 2022",
            "body": " this is just a friendly ping to make sure you haven't forgotten about this issue ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "github-actions",
            "datetime": "May 9, 2022",
            "body": " this is just a friendly ping to make sure you haven't forgotten about this issue ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "github-actions",
            "datetime": "May 24, 2022",
            "body": " this is just a friendly ping to make sure you haven't forgotten about this issue ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "github-actions",
            "datetime": "Jun 8, 2022",
            "body": " this is just a friendly ping to make sure you haven't forgotten about this issue ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "github-actions",
            "datetime": "Jun 22, 2022",
            "body": " this is just a friendly ping to make sure you haven't forgotten about this issue ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "github-actions",
            "datetime": "Jul 6, 2022",
            "body": " this is just a friendly ping to make sure you haven't forgotten about this issue ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "github-actions",
            "datetime": "Jul 21, 2022",
            "body": " this is just a friendly ping to make sure you haven't forgotten about this issue ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "github-actions",
            "datetime": "Aug 1, 2022",
            "body": "This issue is being closed due to lack of activity. If you think it still needs to be addressed, please comment on this thread ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "vikigenius",
            "datetime": "Apr 5, 2022",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Apr 8, 2022",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Jul 21, 2022",
            "body": [],
            "type": "removed their assignment",
            "related_issue": null
        },
        {
            "user_name": "github-actions",
            "datetime": "Aug 1, 2022",
            "body": [],
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "github-actions",
            "datetime": "Aug 1, 2022",
            "body": [],
            "type": "",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/allenai/allennlp/issues/5358",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "seyeeet",
            "datetime": "Aug 15, 2021",
            "body": "Hello\nI found that examples are missing from the provided documents. would it be apoosible to provide a simple examples for the models so we can use them while using the modules?\nfor example, I am interested in learning NER with , but I am not sure how I can do it and I cannot find any exmples in your website that shows me the size/structure of inputs.\nThanks",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Aug 17, 2021",
            "body": "It takes a little bit of work, but you can start from the demo, and look at the parts from there. We have a NER demo here: It includes instructions of how to run the model, and how to train it. You can also check out how the components work together. The training config for this model is here: You can see that it uses the  reader, which lives at  and is documented at .For the model, it uses , which lives at  and is documented at .Similarly, you can find the code and documentation for the other components.If that is too detailed, I recommend the AllenNLP guide at . It won't talk specifically about NER, but it will introduce many important AllenNLP concepts.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "seyeeet",
            "datetime": "Aug 15, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "seyeeet",
            "datetime": "Aug 15, 2021",
            "body": [],
            "type": "changed the title",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Aug 17, 2021",
            "body": [],
            "type": "self-assigned this",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Aug 17, 2021",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/allenai/allennlp/issues/5521",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "himkt",
            "datetime": "Dec 21, 2021",
            "body": " raises an error that fails to load .\nAfter executing , the problem does not happen anymore.OS:Python version: 3.9.9",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "himkt",
            "datetime": "Dec 21, 2021",
            "body": "I found the error doesn't occurs when running  and .\nSorry for raising the fixed problem. It's enough to wait the next release of AllenNLP.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "himkt",
            "datetime": "Dec 21, 2021",
            "body": "After removing , the error occurs again and I re-opened the issue.\nPlease close if you think here is not good place to discuss.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "idiomaticrefactoring",
            "datetime": "Dec 22, 2021",
            "body": "I also find the problem when I run test suite.\npython3.7 -m pytest -v tests/core/policies/test_unexpected_intent_policy.py",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Dec 23, 2021",
            "body": "See also .  should fix our CI and Docker image issues. But I'm not sure what else we can do about this other than downgrading the necessary dependencies.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "github-actions",
            "datetime": "Jan 4, 2022",
            "body": "This issue is being closed due to lack of activity. If you think it still needs to be addressed, please comment on this thread ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "himkt",
            "datetime": "Dec 21, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "himkt",
            "datetime": "Dec 21, 2021",
            "body": [],
            "type": "pull",
            "related_issue": "optuna/optuna#3200"
        },
        {
            "user_name": "himkt",
            "datetime": "Dec 21, 2021",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        },
        {
            "user_name": "himkt",
            "datetime": "Dec 21, 2021",
            "body": [],
            "type": "reopened this",
            "related_issue": null
        },
        {
            "user_name": "HideakiImamura",
            "datetime": "Dec 22, 2021",
            "body": [],
            "type": "pull",
            "related_issue": "optuna/optuna-examples#75"
        },
        {
            "user_name": "epwalsh",
            "datetime": "Dec 23, 2021",
            "body": [],
            "type": "pull",
            "related_issue": "#5529"
        },
        {
            "user_name": "epwalsh",
            "datetime": "Dec 23, 2021",
            "body": [],
            "type": "pull",
            "related_issue": "#5529"
        },
        {
            "user_name": "github-actions",
            "datetime": "Jan 4, 2022",
            "body": [],
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "github-actions",
            "datetime": "Jan 4, 2022",
            "body": [],
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Jan 4, 2022",
            "body": [],
            "type": "reopened this",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Jan 4, 2022",
            "body": [],
            "type": "added",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Jan 12, 2022",
            "body": [],
            "type": "changed the title",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Jan 12, 2022",
            "body": [],
            "type": "pull",
            "related_issue": "#5540"
        },
        {
            "user_name": "dirkgr",
            "datetime": "Jan 13, 2022",
            "body": [],
            "type": "pull",
            "related_issue": null
        },
        {
            "user_name": "h-vetinari",
            "datetime": "Feb 5, 2022",
            "body": [],
            "type": "issue",
            "related_issue": "#5559"
        },
        {
            "user_name": "toshihikoyanase",
            "datetime": "Apr 18, 2022",
            "body": [],
            "type": "pull",
            "related_issue": "optuna/optuna#3353"
        }
    ]
},
{
    "issue_url": "https://github.com/allenai/allennlp/issues/5478",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "HarshTrivedi",
            "datetime": "Nov 20, 2021",
            "body": "I’m using T5 model implemented in allennlp, and need to add extra special tokens to its vocabulary.I’ve added extra tokens in the tokenizer in my reader with . But I also need to extend model’s token embeddings. Usually, when the transformer is loaded with , it’s taken care of by itself because of . I can also do it by invoking HF’s  manually, but, T5 object here doesn’t have this method on it. The T5 object  is allennlp's module, so doesn't have HF methods like .My current solution is to manually extend T5 embeddings and lm_head, but it'd be good to have native support for this in allennlp. Assigning you based on the discussion on slack.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "github-actions",
            "datetime": "Dec 6, 2021",
            "body": " this is just a friendly ping to make sure you haven't forgotten about this issue ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "github-actions",
            "datetime": "Dec 20, 2021",
            "body": " this is just a friendly ping to make sure you haven't forgotten about this issue ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "github-actions",
            "datetime": "Jan 3, 2022",
            "body": " this is just a friendly ping to make sure you haven't forgotten about this issue ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Jan 6, 2022",
            "body": "Fixed in .",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "HarshTrivedi",
            "datetime": "Nov 20, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "HarshTrivedi",
            "datetime": "Nov 20, 2021",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Jan 6, 2022",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/allenai/allennlp/issues/5491",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "JohnGiorgi",
            "datetime": "Nov 30, 2021",
            "body": "The paper  (published at ICLR 2021) demonstrated that re-initializing the last few layers of a pretrained transformer before fine-tuning can reduce the variance between re-runs, speed up convergence and improve final task performance, nicely summarized in their figures:\nThe intuition is that some of the final layers may be over-specified to the pretraining objective(s) and therefore the pretrained weights can provide a bad initialization for downstream tasks.Ideally, you could easily specify which layers to re-initialize in a , something like:The  of  would take care of correctly re-initializing the specified layers for the given .You could achieve this right now with the , but this would require:I've drafted a solution that works (but requires more testing). Essentially, we add a new parameter to , , which can be an integer or list of integers. In , we re-initialize as follows:I sanity-checked it by testing that the weights of the specified layers are indeed re-initialized. I also trained a model with re-initialized layers on my own task and got a non-negligible performance boost.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Dec 3, 2021",
            "body": "Hey , I do think this would be a good addition. Feel free to ping me when you start the PR!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "github-actions",
            "datetime": "Dec 15, 2021",
            "body": "This issue is being closed due to lack of activity. If you think it still needs to be addressed, please comment on this thread ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "JohnGiorgi",
            "datetime": "Dec 15, 2021",
            "body": "Oops, still working on  so I think it makes sense to keep this open!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Dec 15, 2021",
            "body": "Unfortunately there's no easy way to check if an issue has an open linked pull request from the GitHub API, which should be a sufficient condition to keep the issue open ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "JohnGiorgi",
            "datetime": "Nov 30, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "JohnGiorgi",
            "datetime": "Dec 10, 2021",
            "body": [],
            "type": "pull",
            "related_issue": "#5505"
        },
        {
            "user_name": "github-actions",
            "datetime": "Dec 15, 2021",
            "body": [],
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "github-actions",
            "datetime": "Dec 15, 2021",
            "body": [],
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Dec 15, 2021",
            "body": [],
            "type": "reopened this",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Dec 15, 2021",
            "body": [],
            "type": "self-assigned this",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Dec 23, 2021",
            "body": [],
            "type": "pull",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/allenai/allennlp/issues/5576",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "zhaowei-wang98",
            "datetime": "Feb 23, 2022",
            "body": "When I try to load a model with the above code, a deluge of log info takes my terminal and disrupts my personal log info.\nCould it be silent?\nNo log info about loading a model appears on my terminal.\nkeep it silent or output only one or two lines to show that the loading process is finished.\nno.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Feb 24, 2022",
            "body": "All of the messages are using the Python logging facilities. You can limit it to only show warning messages from AllenNLP by doing this:If you want to only see warnings from all packages (not just AllenNLP), you can even do this:",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "zhaowei-wang98",
            "datetime": "Feb 23, 2022",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Feb 24, 2022",
            "body": [],
            "type": "self-assigned this",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Feb 25, 2022",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/allenai/allennlp/issues/5355",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "amitkparekh",
            "datetime": "Aug 11, 2021",
            "body": "\nI like removing boilerplate from code and using the training configs as much as possible.The vocab created from instances with  and  do not update the vocab with the model's entire vocab. I understand that this might not be desired behaviour, which is why  exists.But this doesn't help if I want to create a vocab from both instances and the pretrained transformer. Building a multitask model, I've found that I would like this feature.\nAn additional constructor for creating the vocab from both instances and the pretrained transformer. The construction should support multiple model names for various namespaces, which are likely used in multitask models.In my training config, I would like it to just be this (where the keys are the namespace, and values are the model name).Users could  extend the vocabulary during the  of their classes, but this would result in repeated code for each namespace they want to extend.For example, extending a single namespace with one model would result in:but if there were multiple models, you'd probably end up seeing:I tried implementing my solution  and it works as I described above with the additional tokens being added to the vocab from the transformer.I realised I came across this feature because I was trying to do things before the  of module within my model. I now see that the vocab is indexed after the model is initialised, so this is not  necessary. But _ shows that there is some demand.But that brings up a different problem when I need the vocab size during model initialisation but it's not accurate until after the model is fully constructed.I thought about closing but I feel like this has some use if this functionality is desired? Feel free to just close this if it's of no use to anyone!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Aug 17, 2021",
            "body": "I think that would be a fine additional  constructor. Can you make it into a PR, with a small test? I'd be happy to review it.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "amitkparekh",
            "datetime": "Aug 20, 2021",
            "body": " — Just submitted a PR!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "amitkparekh",
            "datetime": "Aug 11, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "amitkparekh",
            "datetime": "Aug 11, 2021",
            "body": [],
            "type": "changed the title",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Aug 17, 2021",
            "body": [],
            "type": "self-assigned this",
            "related_issue": null
        },
        {
            "user_name": "amitkparekh",
            "datetime": "Aug 19, 2021",
            "body": [],
            "type": "pull",
            "related_issue": "#5368"
        },
        {
            "user_name": "dirkgr",
            "datetime": "Aug 24, 2021",
            "body": [],
            "type": "pull",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/allenai/allennlp/issues/5558",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "h-vetinari",
            "datetime": "Feb 5, 2022",
            "body": "In ,  :Since that issue is closed, it's exceedingly easy to overlook this, and so I thought I'd open a new issue.The migration will be kicked off as soon as  is merged, and will then be observable under . It might be a while until all dependencies get published, but I'll try to keep an eye on the PRs that the migrator opens (you can too! yes, you! you can ping me if you find something has stalled, which is always possible in a volunteer-only organisation).",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "h-vetinari",
            "datetime": "Feb 7, 2022",
            "body": "With the merging of , allennlp plus all extras mentioned in the readme are now available for osx-arm in conda-forge - closing.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "h-vetinari",
            "datetime": "Feb 5, 2022",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "h-vetinari",
            "datetime": "Feb 5, 2022",
            "body": [],
            "type": "pull",
            "related_issue": "conda-forge/conda-forge-pinning-feedstock#2485"
        },
        {
            "user_name": "h-vetinari",
            "datetime": "Feb 7, 2022",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/allenai/allennlp/issues/5258",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "codeananda",
            "datetime": "Jun 13, 2021",
            "body": "There is a  install for Linux. Could you please also add one for Mac?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Jun 21, 2021",
            "body": ", do you know what it would take to get this done?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "h-vetinari",
            "datetime": "Jun 21, 2021",
            "body": "Hey allThanks for the ping, I've had a long-standing , but it was then still missing osx-builds for pytorch/torchvision. Those have since arrived, but there are still some errors in the test suite on OSX. Any help fixing those is appreciated. :)",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Jun 21, 2021",
            "body": "Errors in the AllenNLP test suite, or in the torchvision test suite?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "h-vetinari",
            "datetime": "Jun 22, 2021",
            "body": "The AllenNLP test suite. For details, see the  from ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Jun 23, 2021",
            "body": "It looks like the problem is thatI don't know why that is, but as long as that's the case, the AllenNLP tests won't run.It's surprising though, because I'm running it on Mac right now, wit PyTorch installed from Conda, and it all works fine, including the distributed setup. Why doesn't it use this version when it runs the tests?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "github-actions",
            "datetime": "Jul 8, 2021",
            "body": " this is just a friendly ping to make sure you haven't forgotten about this issue ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "github-actions",
            "datetime": "Jul 22, 2021",
            "body": " this is just a friendly ping to make sure you haven't forgotten about this issue ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Aug 2, 2021",
            "body": "Have not forgotten. Am waiting for the resolution on .",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "h-vetinari",
            "datetime": "Aug 2, 2021",
            "body": "Which Mac's are we talking about? The processor architecture changed with the M1, so building for pre-M1 is different. I'm currently looking to get the osx-x86_64 build running (equals pre-M1), but since conda-forge does not have M1 CI, we can only cross-compile, and I would need someone to test-run a candidate artefact before we can merge.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Aug 3, 2021",
            "body": "I am currently not concerned about the M1 Macs. As far as I know, AllenNLP works fine on those with the official PyTorch conda package, so people running that can use that. Of course it would be better if the conda version of PyTorch also worked, but let's get that to work on x86 first before we worry about M1.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "h-vetinari",
            "datetime": "Aug 4, 2021",
            "body": "osx-x86_64 builds are available now. :)",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Aug 4, 2021",
            "body": "Does that mean we can close this issue?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "h-vetinari",
            "datetime": "Aug 4, 2021",
            "body": "We can keep it for the M1 packages if you want.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Aug 4, 2021",
            "body": "Too many open issues. We'll wait until someone requests them. By that point, the fine folks at Apple and Facebook might have solved some of the problems we'd otherwise have already.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Vladimir-Chan",
            "datetime": "Nov 27, 2021",
            "body": " Hi, there is a  install of version 2.6.0. Could you please upgrade it to the stable version 2.8.0? If it is difficult to build a install for mac, could you please build it for linux?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "h-vetinari",
            "datetime": "Nov 30, 2021",
            "body": "There's an effort  to do that, but due to the new dependencies added in 2.7 & 2.8, this is taking longer than expected. Also, if you have an M1, conda-forge is not building allennlp for osx-arm yet, but that could be done in principle.PS. Posting on long-closed issues makes it very likely that your comment gets overlooked.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "h-vetinari",
            "datetime": "Dec 1, 2021",
            "body": "Allennlp 2.8 is now in conda-forge.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Dec 1, 2021",
            "body": "Sweet, thank you!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "RoyLiberman",
            "datetime": "Jan 17, 2022",
            "body": "can you please add support for mac M1 systems on conda-forge?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "codeananda",
            "datetime": "Jun 13, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Jun 18, 2021",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Aug 4, 2021",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        },
        {
            "user_name": null,
            "datetime": [],
            "body": [],
            "type": "",
            "related_issue": "conda-forge/conda-forge-pinning-feedstock#2485"
        }
    ]
},
{
    "issue_url": "https://github.com/allenai/allennlp/issues/5155",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "nelson-liu",
            "datetime": "Apr 26, 2021",
            "body": "Right now, allennlp currently evaluates / saves checkpoints at the end of every epoch. However, it'd be nice if there was some way of evaluating within an epoch.  For example, say an epoch is 10,000 steps, and I want to evaluate / save a checkpoint every 500 steps.This is especially important when fine-tuning pre-trained language models. Often, the optimal checkpoint does not occur at the end of an epoch, and models can quickly overfit. For example, the huggingface default scripts save checkpoints every 500 steps. it'd be nice to have some sort of similar option for allennlp.\nperhaps the checkpointing side of this could be controlled by the checkpointer, similar to how  exists. Perhaps . However, maybe there needs to be analogous argument in the  for evaluation.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nelson-liu",
            "datetime": "Apr 26, 2021",
            "body": "To be concrete: I'm trying to train BERT on the IMDb sentiment dataset (25K examples). It peaks after epoch 2 (and starts overfitting from epoch 3) but i'm sure that there are better checkpoints between the end of epoch 2 and the end of epoch 3. In general, these pre-trained language models aren't trained for very many epochs (e.g., 3-4), so only evaluating and saving 3 or 4 checkpoints seems like you'd leave a lot of performance on the table.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ArjunSubramonian",
            "datetime": "Apr 27, 2021",
            "body": "This would indeed be a great feature to have. I've made it so that Contributions are Welcome. I also labeled it as Easy from a first glance (and the fact that you provide suggestions and a reference above), but let me know if you think this could be a more difficult change.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Apr 28, 2021",
            "body": "In practice I always set  to a suitable number for this exact reason. Is there a reason that approach is sub-optimal for you use-case, ?See also ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nelson-liu",
            "datetime": "Apr 28, 2021",
            "body": "The reason is that i either did not know about it, and/or forgot that this was a thing :) This seems to fit the bill perfectly, thanks  .",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Apr 28, 2021",
            "body": "Great, no problem!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "nelson-liu",
            "datetime": "Apr 26, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "ArjunSubramonian",
            "datetime": "Apr 27, 2021",
            "body": [],
            "type": "added",
            "related_issue": null
        },
        {
            "user_name": "nelson-liu",
            "datetime": "Apr 28, 2021",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/allenai/allennlp/issues/4823",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "tomsherborne",
            "datetime": "Nov 26, 2020",
            "body": "The  activation is currently not a possible option from the set of registered Activations. Since this class just directly called the PyTorch classes - adding this in is a 1 line addition. Motivation is that models like BART/BERT use this activation in many places and elegant consistency of activation function across models that are \"something pretrained\" + \"more weights trained on AllenNLP\" would be nice.\nAdd the following snippet to the end of the  class\nManually hardcoding the activation. This isn't very robust and modules such as FeedForward complain since Gelu isnt a registered activation to insert between layers (as far as I can tell).Thanks - happy to submit a tiny PR for this",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Nov 30, 2020",
            "body": "Hi , yes please go ahead a submit a PR for this. Thanks!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "tomsherborne",
            "datetime": "Nov 26, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": null,
            "datetime": [],
            "body": [],
            "type": "",
            "related_issue": "#4827"
        },
        {
            "user_name": "epwalsh",
            "datetime": "Nov 30, 2020",
            "body": [],
            "type": "pull",
            "related_issue": "#4828"
        },
        {
            "user_name": "epwalsh",
            "datetime": "Dec 2, 2020",
            "body": [],
            "type": "pull",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/allenai/allennlp/issues/4856",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "epwalsh",
            "datetime": "Dec 9, 2020",
            "body": "In particular, it would be great if you do something like this:",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Dec 10, 2020",
            "body": "I think we'd use one LR scheduler that calls into others to make this as flexible as possible.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Dec 9, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Dec 9, 2020",
            "body": [],
            "type": "added this to the",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Dec 18, 2020",
            "body": [],
            "type": "pull",
            "related_issue": "#4871"
        },
        {
            "user_name": "epwalsh",
            "datetime": "Dec 19, 2020",
            "body": [],
            "type": "pull",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/allenai/allennlp/issues/4877",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "schmmd",
            "datetime": "Dec 21, 2020",
            "body": " is going to investigate whether we need this and get back to .",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Dec 22, 2020",
            "body": "The model we want is ResNext-152 trained on Visual Genome. Neither torchvision nor detectron has this, so we'll hold off for now. We might still need detectron if it turns out to be the easiest way to get that model.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "schmmd",
            "datetime": "Dec 21, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "schmmd",
            "datetime": "Dec 21, 2020",
            "body": [],
            "type": "added this to the",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Dec 22, 2020",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/allenai/allennlp/issues/4541",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "PrettyMeng",
            "datetime": "Aug 6, 2020",
            "body": "It seems that in current AllenNLP, the model we save and create cannot interact with apis in transformers. (because we have different keys in model.state_dict()) I think it will be highly helpful if we can convert a trained AllenNLP model to a transformers model. This will provide more flexibility in applications and researchs.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "wj-Mcat",
            "datetime": "Aug 6, 2020",
            "body": "Waiting for this feature.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "matt-gardner",
            "datetime": "Aug 6, 2020",
            "body": "In general, this isn't possible, because, e.g., they don't have coref or SRL models.  We do want to make it easy to do this when it is possible, though.  For instance, you could take the base transformer weights and save them.  This isn't very hard right now, just a few lines in a simple script, but we could document it / make it one line instead.  Can you give more detail on what exactly you want to do?  Which models, and which weights, are you hoping to have be compatible?For more info on a simple script to do what you want, see .",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "PrettyMeng",
            "datetime": "Aug 6, 2020",
            "body": "Thanks for your quick reply! For example, if I want to run some example scripts from transformers on a trained AllenNLP Roberta model, it seems to be troublesome in my case. It would also be great if there is more example scripts in AllenNLP.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "matt-gardner",
            "datetime": "Aug 6, 2020",
            "body": "That's still not enough detail.  What exactly do you want to do?  Which scripts?  \"Roberta\" isn't a single model.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "PrettyMeng",
            "datetime": "Aug 6, 2020",
            "body": "For example, I have finetuned Roberta to train a text classifier. Based on this, I want to run language modeling on this trained model, using this . It would be great if we can directly apply an AllenNLP model to scripts like this.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "AkshitaB",
            "datetime": "Aug 7, 2020",
            "body": "Closing as a duplicate of ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "PrettyMeng",
            "datetime": "Aug 6, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "AkshitaB",
            "datetime": "Aug 7, 2020",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/allenai/allennlp/issues/4513",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "Rajwrita",
            "datetime": "Jul 26, 2020",
            "body": "A sticky navbar would probably be helpful to access the various pages on the website with ease.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Jul 27, 2020",
            "body": "Hi , I agree, I think that would be nice. I'm not sure if that's an easy change, maybe  would know?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "jonborchardt",
            "datetime": "Jul 27, 2020",
            "body": "the demo has a sticky top bar...\nwhat exactly are you wanting to see?\ncan you provide a screen shot of existing and let me know what you would like estimated?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Jul 27, 2020",
            "body": " sorry, I think  was talking about  and I saw you had some commits recently, so I thought you might be the best person to ping",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "jonborchardt",
            "datetime": "Jul 27, 2020",
            "body": "",
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Jul 27, 2020",
            "body": "Oh, awesome. Thanks Jon!Closing this then.  let me know if you were talking about something other than allennlp.org and I can re-open.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Rajwrita",
            "datetime": "Jul 26, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Jul 27, 2020",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/allenai/allennlp/issues/4528",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "PrettyMeng",
            "datetime": "Aug 3, 2020",
            "body": "For the cluster that I'm using, it does not allow specifying cuda device in my code. I think it's pretty common in many different clusters. I have not found how to do it for current allennlp library. Does there exist one that I have not noticed or can you add a feature like this? For example, by setting some config parameters, we can use model.cuda() instead of model.to(device). Thanks in advance!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Aug 3, 2020",
            "body": "Hey @PrettyPrettyMeng, we changed the behavior of the  command recently to automatically detect and use a GPU when it can if you don't explicitly set the \"cuda_device\" parameter in the trainer. Have you tried that?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "PrettyMeng",
            "datetime": "Aug 4, 2020",
            "body": "That's great! Thanks. Maybe I'm using some older version and it automatically use CPU when I don't explicitly set the \"cuda_device\" parameter in the trainer.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "PrettyMeng",
            "datetime": "Aug 3, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "PrettyMeng",
            "datetime": "Aug 4, 2020",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/allenai/allennlp/issues/5228",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "offendo",
            "datetime": "May 27, 2021",
            "body": "Hello! Thanks for the fantastic work on this project.In the  class, the  flag for DDP is set to , which causes the following warning when running distributed code.(Issue  and PR  are related)The warning states it can adversely affect performance, but I'm not clear on how much exactly. Simply traversing the graph sounds like a minimal compute expenditure, yeah?If that's the case, maybe we can disable the warning? If it's not controllable by the end user anyway (since it's not a parameter to ), is it useful to print out?On the other hand, if it is significantly detrimental to performance, maybe it should be a parameter. Although, the constructor signature is already rather imposing...Thanks for your time!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "May 27, 2021",
            "body": "I think I just want to turn that parameter off completely. It's not reliable with multitask models, it prints a warning, and it's weird that we get this check only in the distributed setting. If we want to provide this functionality, I'd rather do it in a . , , any concerns?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "May 28, 2021",
            "body": " says he has this fixed in his work on T5.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "May 28, 2021",
            "body": "Update: There is no PR yet for Pete's work, but we'll link the issue when there is one.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "offendo",
            "datetime": "May 29, 2021",
            "body": "Thanks, appreciate it!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "github-actions",
            "datetime": "Jun 14, 2021",
            "body": " this is just a friendly ping to make sure you haven't forgotten about this issue ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "github-actions",
            "datetime": "Jun 28, 2021",
            "body": " this is just a friendly ping to make sure you haven't forgotten about this issue ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Jun 28, 2021",
            "body": "Have not forgotten.  is still working on his PR.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "github-actions",
            "datetime": "Jul 13, 2021",
            "body": " this is just a friendly ping to make sure you haven't forgotten about this issue ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "offendo",
            "datetime": "May 27, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "May 27, 2021",
            "body": [],
            "type": "self-assigned this",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Jul 13, 2021",
            "body": [],
            "type": "pull",
            "related_issue": "#5242"
        },
        {
            "user_name": "epwalsh",
            "datetime": "Jul 19, 2021",
            "body": [],
            "type": "pull",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/allenai/allennlp/issues/4486",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "dirkgr",
            "datetime": "Jul 16, 2020",
            "body": "",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "github-actions",
            "datetime": "Mar 3, 2021",
            "body": "This issue is being closed due to lack of activity. If you think it still needs to be addressed, please comment on this thread ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Mar 3, 2021",
            "body": "We're still interested in this, and some of these are part of our , but we don't have active work going on with these datasets that isn't being tracked elsewhere already.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Jul 16, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Jul 16, 2020",
            "body": [],
            "type": "added this to the",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Nov 9, 2020",
            "body": [],
            "type": "modified the milestones:",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Feb 22, 2021",
            "body": [],
            "type": "changed the title",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Feb 22, 2021",
            "body": [],
            "type": "removed this from the",
            "related_issue": null
        },
        {
            "user_name": "github-actions",
            "datetime": "Mar 3, 2021",
            "body": [],
            "type": "",
            "related_issue": null
        },
        {
            "user_name": "github-actions",
            "datetime": "Mar 3, 2021",
            "body": [],
            "type": "",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/allenai/allennlp/issues/4362",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "mateuszpieniak",
            "datetime": "Jun 16, 2020",
            "body": "\nI noticed that BERT-like architecture is usually fully fine-tuned, but very shortly (1-2 epochs) with some warm-up (to avoid catastrophic forgetting) - for example in . I believe that such a resolution is not enough for good validation score estimation i.e. you don't really know the curve's shape. I could lower down learning rate and increase the number of epochs, but it will take a lot of time to train.A slightly different example of calculating the validation score more frequently is , which was implemented in Caffe (no epoch concept). In the paper, the LR test was performed on the whole validation set after N batches.\nProvide an additional argument to  that denotes the frequency of validation evaluation.\nDecrease the learning rate and increase the number of epochs.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Jun 16, 2020",
            "body": "I was actually just thinking about this as well. We already  have a setting for this: .But this isn't perfect because if  is less than the total number of batches in the dataset, then you're not guaranteed to see every unique instance:\nThat said, I don't think it would too hard to tweak it to ensure that every instance is seen (provided you're running for enough epochs). The  would just have to keep some internal state about where to pick up again next time  is called.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "mateuszpieniak",
            "datetime": "Jun 17, 2020",
            "body": " Super cool! In my case, I don't need such guarantees. I am not sure though whether  scheduler reads the proper number of batches, but I guess I will find out tomorrow.Btw, out of curiosity, do you think it can be considered a regularization? In theory the bigger the dataset, the better generalization properties. On the other hand sampling data from the training, dataset restricts you from fitting perfectly into your training dataset. This can be considered a regularization technique, but the \"effective dataset size\" is smaller due to sampling.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Jun 17, 2020",
            "body": "Hmm yea I suppose you could think of it that way. Kind of like dropout, except applied to training instances instead of individual weights.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Jun 19, 2020",
            "body": " is the right answer here. If that does not guarantee that you'll see all instances, we have to fix it. Is that the case?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "mateuszpieniak",
            "datetime": "Jun 19, 2020",
            "body": " Yes, that's the case. I am satisfied with the current implementation of  for my purpose, but I think that such a guarantee should be more intuitive for a user.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Jun 22, 2020",
            "body": "Ok, sounds like this one can be closed, but I've open up a separate issue to address the behavior with : .",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "mateuszpieniak",
            "datetime": "Jun 16, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Jun 22, 2020",
            "body": [],
            "type": "issue",
            "related_issue": "#4393"
        },
        {
            "user_name": "epwalsh",
            "datetime": "Jun 22, 2020",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Apr 28, 2021",
            "body": [],
            "type": "issue",
            "related_issue": "#5155"
        }
    ]
},
{
    "issue_url": "https://github.com/allenai/allennlp/issues/4405",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "liyucheng09",
            "datetime": "Jun 26, 2020",
            "body": "",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "matt-gardner",
            "datetime": "Jun 26, 2020",
            "body": "I  all you need to do is .  Then you can use the predictor in your script however you want.  Does that work for you?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "liyucheng09",
            "datetime": "Jun 27, 2020",
            "body": "Thanks for your immediate replay. I successfully build a predictor by your codes:But when I use the predictor by  there is an NotInplementedError, this is because the predictor is a default Predictor and the predict function is not defined yet.Then I use the  Predictor which has the defined  function:But it return a default Predictor also and the there is no  function obviously.So I still have no idea that how to use the archiev file to initialize a custom Predictor and use it to predict.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "matt-gardner",
            "datetime": "Jun 29, 2020",
            "body": "If you look at , you'll see that there's a  argument to .  The predictor name for  is .But I'm a bit confused about your second line of code - that looks to me like it should return an instance of , not .  Are you sure it's returning just a ?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "github-actions",
            "datetime": "Aug 18, 2020",
            "body": " this is just a friendly ping to make sure you haven't forgotten about this issue ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "liyucheng09",
            "datetime": "Jun 26, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "matt-gardner",
            "datetime": "Jun 26, 2020",
            "body": [],
            "type": "added",
            "related_issue": null
        },
        {
            "user_name": "matt-gardner",
            "datetime": "Jun 26, 2020",
            "body": [],
            "type": "self-assigned this",
            "related_issue": null
        },
        {
            "user_name": "matt-gardner",
            "datetime": "Aug 18, 2020",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/allenai/allennlp/issues/4304",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "dirkgr",
            "datetime": "May 30, 2020",
            "body": "People using the library () are ending up with lots of model directories that are full of checkpoints, wasting many TB of space. We could have an  command that finds these and deletes them, leaving only the final model.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "matt-gardner",
            "datetime": "May 30, 2020",
            "body": "Finding arbitrary directories that were used seems really challenging.  We could walk a directory looking for weights files, but how do we know which ones to keep...?An alternative solution is to just change the number of serialized models that we keep around, which we did already: ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ZhaofengWu",
            "datetime": "May 30, 2020",
            "body": "+1 to Matt's comment. I was having the same problem in 0.9 but with this change this shouldn't be a problem anymore.Regardless, if we want to do this, it might be better to come up with a name other than  to avoid confusion with model pruning.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "matt-gardner",
            "datetime": "Jun 5, 2020",
            "body": "In issue review we thought we should just close this.  Please reopen  if you want to discuss further.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "May 30, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "May 30, 2020",
            "body": [],
            "type": "added this to the",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "May 30, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "matt-gardner",
            "datetime": "Jun 5, 2020",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/allenai/allennlp/issues/5488",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "unikcc",
            "datetime": "Nov 30, 2021",
            "body": "\nI' a newbie for AllenNLP but I've fall in love with it to handle my own NLP task.\nBut each time I start a new project, I have to copy the previous code of other AllenNLP project since I can't remember the file architecture.\nThen there will me much old code that is redundant for the new project and I have to delete so much lines that are task-specific.\nSo I need a tool or just a command(e.g. ) to init a golden template project of AllenNLP, which contains some basic moduel for runing a AllenNLP code, like model,  configuration, data processor and demo data folder, etc.\nI think this feature will make researcher much cheerful to work with AllenNLP.\nAdd a command to init a simplest AllenNLP project, just like spring-boot-start for java web developer.\nOr provide a demo code project of AllenNLP and I can easily access for it.\nNo",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Dec 3, 2021",
            "body": "Hi , we have a template repo for this purpose: . You could also make your own template repo if that one is not exactly what you're looking for.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "lgessler",
            "datetime": "Dec 6, 2021",
            "body": "I'd just like to add that I agree with  that this kind of a thing is a great boon for beginners. CLI templater tools ( and  are the ones I'm most familiar with), when done well, can get a user straight into the \"real code\" they want to write without requiring them to handle small but cognitively non-negligible things like, for example, renaming packages or deleting files they don't intend to use. (Templaters avoid those two problems by parameterizing package name and parameterizing modules so you can choose whether you want CI, tests, flake8/black/tox support, JSON-, Jsonnet-, or code-based execution, etc.)Maybe it turns out this problem is better handled as a 3rd party lib than as an AllenNLP-owned functionality, but regardless I think this would be an awesome addition to the AllenNLP ecosystem. Perhaps I and anyone else who's interested could work towards implementing something like this?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Dec 6, 2021",
            "body": "I think that's true. At least it would be easier to get up and running and faster to develop since you wouldn't have to wait for feedback from us to merge PRs. I'm happy to provide feedback / advice if you want it though.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "unikcc",
            "datetime": "Nov 30, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Dec 10, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/allenai/allennlp/issues/5450",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "HOZHENWAI",
            "datetime": "Oct 27, 2021",
            "body": "\nOn the current version of 2.7.0 of allennlp and versions 4.11.3 of transformers, layoutlmv2 is not supported :Error occurs since they added an argument  as second argument of the fast layoutlm_v2 tokenizer which breaks the reverse engineer of the special tokens of allennlp pretrained_transformer_tokenizer.\nIdeally, naming the arguments in  of pretrained_transformer_tokenizer should do the work but I'm afraid of repercussions on other tokenizer that have different argument name (those not based of Bert maybe?)\nMoreover since layoutlm_v2 added a few input to the model (images and boxes), modifications should be made to _unfold_long_sequences, _fold_long_sequences and forward of the pretrained_transformer_embedder and pretrained_transformer_mismatched_embedder to account for additional inputs.If it's okay with you, I'd like to work in it.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Oct 29, 2021",
            "body": "Hi , yes this would be a good fix to have. Feel free to open a PR when you're ready.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "HOZHENWAI",
            "datetime": "Oct 27, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Oct 29, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/allenai/allennlp/issues/4422",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "dirkgr",
            "datetime": "Jun 30, 2020",
            "body": "We’ll write a  that takes a  as one of its  arguments. This way we define the different datasets we want to read. Much like the , this reader’s  method takes a , so that we can pass the right path to the right inner reader. Accordingly, the  keys in the config need to be dictionaries.’s  method will return a .  will act like  (chaining the inner datasets into one large one), with two differences:We’ll write a  that takes a  as a  argument that defines the different data loaders for each task. It also takes a  that determines which task gets batched next. The  method batches instances from the next task and returns them as a .When it does this, it makes one change to the  that come from the inner data loaders: The instances will have a “task” field identifying the task, so the batch with those instances will contain a  with the task in it. Since we know that one batch always comes from a single task, we replace that field with a single  containing the task name.Note that this design makes it possible to define different batch sizes and shuffling options per task.Multitask schedulers are the only type of object that is genuinely new. As usual, we should have a base class with a a few implementations:We’ll write a  base class. Derivations of this class hold some parameters within themselves (the “backbone”), and also support one or more “heads”, which perform the actual tasks. Every head is a  in its own right, i.e., it returns a loss from the  method.The ’s  method must take a  that describes the task-specific heads, each with a name. Optionally, it should take a , containing scaling factors for the loss for each task.The  method should take the following arguments:The heads return a  of results, including a loss. The  renames all of the results such that they are prefixed by the head name. For example, if the  head returns a tensor under the name , the  returns a tensor under the name . In addition, it computes a loss based on the loss from the head, and the loss weight for the task.Similarly, the ’s  call will call  on all of the heads, and prefix the results with the head’s names.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "matt-gardner",
            "datetime": "Jun 30, 2020",
            "body": "My first pass at how I would design something for this:You have a  or a , which goes from inputs to an encoded representation that's ready to have various task heads applied.  (Though, really, the  already does what the  would do, so we may not need anything new there, just for text+images.)  Then you have a  that takes as  arguments a  and a list of prediction heads.   is a bit tricky, you probably have to have it accept  and make assumptions about the names of things that it gets.  But assuming you can work that out, you then have the model apply whatever heads are required based on the inputs it receives, compute a joint loss, and that's it.  You can configure this pretty easily to add another head just by adding another prediction head to the list, and an appropriate dataset inside a multi-task dataset reader.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "jiasenlu",
            "datetime": "Jul 1, 2020",
            "body": "I think what  suggested about model forward pass makes sense. For multi-task dataloader, we can borrow the existing code from M3Transofrmers. What we need is to call  before each iteration, and it will output the batched data for different tasks.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Aug 17, 2020",
            "body": "I updated this issue's description to be basically a spec, ready to implement. , does it address your concerns?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Aug 17, 2020",
            "body": "I put the description of Stop&Go into , since we can do that separately from this.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "wlhgtc",
            "datetime": "Aug 18, 2020",
            "body": "Yes.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "schmmd",
            "datetime": "Nov 16, 2020",
            "body": "  is going to check if there's anything left to do.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "mateuszpieniak",
            "datetime": "Nov 5, 2021",
            "body": "How can we distribute a single instance to two or more heads?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "jbrry",
            "datetime": "Nov 5, 2021",
            "body": " A quick workaround I ended up doing was introducing a boolean value  for the  model, where if specified, skips some of the dataset reader to task-head mapping logic.It's not properly tested but served me for my needs. You can see some of the control flow .",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Nov 18, 2021",
            "body": "To support this properly I would write another version of  that supports this.  is not that big a class anyways. But if you have a workaround, that's good too.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Jun 30, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Jun 30, 2020",
            "body": [],
            "type": "added this to the",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Jun 30, 2020",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "wlhgtc",
            "datetime": "Aug 12, 2020",
            "body": [],
            "type": "issue",
            "related_issue": "#4551"
        },
        {
            "user_name": "dirkgr",
            "datetime": "Aug 17, 2020",
            "body": [],
            "type": "issue",
            "related_issue": "#4566"
        },
        {
            "user_name": "matt-gardner",
            "datetime": "Aug 26, 2020",
            "body": [],
            "type": "pull",
            "related_issue": "#4601"
        },
        {
            "user_name": "schmmd",
            "datetime": "Nov 16, 2020",
            "body": [],
            "type": "unassigned",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Nov 23, 2020",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/allenai/allennlp/issues/4351",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "JohnGiorgi",
            "datetime": "Jun 11, 2020",
            "body": "As per , I think it would be very useful if there were instructions for uploading the weights of a transformer-based language model trained with AllenNLP to .A mechanism (if it doesn't already exist) and instructions for uploading the weights of a pretrained language model trained with AllenNLP to .N/A.I first asked if this was possible  and  asked me to open a feature request here.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "schmmd",
            "datetime": "Jun 11, 2020",
            "body": " is this something you did with one of your models?  Apologies if I'm misremembering.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ZhaofengWu",
            "datetime": "Jun 11, 2020",
            "body": "I uploaded and only uploaded SpanBERT (, ). It's not generated by AllenNLP and was already packaged in a way that huggingface recognizes, so it's probably not super relevant here.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "schmmd",
            "datetime": "Jun 12, 2020",
            "body": " if you have a huggingface model in memory is that sufficient?  If so, we can give you some pointers on how to do that.  If not, we need to figure something bigger out.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "JohnGiorgi",
            "datetime": "Jun 15, 2020",
            "body": " Do you mean did I train a huggingface model with allennlp? If so then yes, all my trainable weights are in a ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "matt-gardner",
            "datetime": "Jun 15, 2020",
            "body": "The question is, if you can get the in-memory  from , is that sufficient to follow their instructions to upload weights, or is something else needed?  I haven't done this before, but it looks like there's a  method that you can call on the in-memory , which you can pull out of our  object.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "JohnGiorgi",
            "datetime": "Jun 15, 2020",
            "body": "Oh sorry, I understand now. Yes that seems obvious in hindsight, I guess it is just a matter of figuring out where/when to call  but I am sure I can figure that out. Thanks for the guidance!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "JohnGiorgi",
            "datetime": "Jun 24, 2020",
            "body": "Okay, for anyone who lands on this issue, I have figured out how to do this with an  object:Of course, this implementation relied on knowing that for my model,  exists and that is is a .I confirmed that a model saved this way can be uploaded (and downloaded from) .",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Aug 12, 2020",
            "body": " thanks for that example.And for everyone in this thread, where do you think would be the best place to document this? A couple of ideas (not necessarily mutually exclusive):",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "JohnGiorgi",
            "datetime": "Aug 12, 2020",
            "body": " No problem, there's just a couple of issues I ran into:My updated example looked like:There also appears to be something strange happening if you call this on a distributed model. I never really got to the bottom of it, but when I ran this code on a CPU, uploading/downloading to  worked fine. When I actually went to train my model with AllenNLP in a distributed setup and run this code, uploading works but downloading throws a weird error. This callback might need to make a copy of the model/tokenizer on the CPU before calling  to avoid this.In the end, I actually found it was easier to write a script that loads a predictor and from there calls  (see ).",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Aug 12, 2020",
            "body": "Thanks , that's helpful!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "matt-gardner",
            "datetime": "Aug 12, 2020",
            "body": "Put a section in the guide instead of this?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Aug 12, 2020",
            "body": " either way is fine with me, I just wasn't sure if this would be within the scope of the guide.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Aug 13, 2020",
            "body": "After talking with  and  we decided that it would beneficial (and very little extra work) to publish mini tutorials like these on both Medium and the guide.We want the guide to be the centralized source of truth for AllenNLP documentation, but cross-posting on Medium would make these tutorials easier to find and could ultimately help drive traffic to the guide as well.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Aug 14, 2020",
            "body": "Medium post on this here: .I'll hold off on closing this issue until I've added it to the guide as well so I don't forget.Thanks  for bringing this up!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "JohnGiorgi",
            "datetime": "Jun 11, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "matt-gardner",
            "datetime": "Aug 6, 2020",
            "body": [],
            "type": "issue",
            "related_issue": "#4541"
        },
        {
            "user_name": "AkshitaB",
            "datetime": "Aug 7, 2020",
            "body": [],
            "type": "added this to the",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Aug 12, 2020",
            "body": [],
            "type": "self-assigned this",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Aug 18, 2020",
            "body": [],
            "type": "pull",
            "related_issue": "allenai/allennlp-guide#139"
        },
        {
            "user_name": "epwalsh",
            "datetime": "Aug 18, 2020",
            "body": [],
            "type": "pull",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/allenai/allennlp/issues/5409",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "martin-kirilov",
            "datetime": "Sep 14, 2021",
            "body": "Spacy 3 introduced new transformer-based models that can be run on GPU. I think it's a good idea to add support for these types of language models in AllenNLP, since now it doesn't work out-of-the-box.My suggestion is to add an option to specify whether to load the model on CPU or GPU, and also use it accordingly.\nThis would require changes to both allennlp and allennlp-models, as in some models (e.g. SRL), there should be made some changes to the .",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Sep 20, 2021",
            "body": "Hey , this sounds like a good feature to have. Feel free to submit a PR if you get a chance.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "github-actions",
            "datetime": "Oct 5, 2021",
            "body": " this is just a friendly ping to make sure you haven't forgotten about this issue ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "martin-kirilov",
            "datetime": "Sep 14, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "AkshitaB",
            "datetime": "Sep 17, 2021",
            "body": [],
            "type": "assigned",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Sep 20, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Oct 7, 2021",
            "body": [],
            "type": "removed their assignment",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/allenai/allennlp/issues/5237",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "danieldeutsch",
            "datetime": "Jun 2, 2021",
            "body": "\nI typically used compressed datasets (e.g. gzipped) to save disk space. This works fine with AllenNLP during training because I can write my dataset reader to load the compressed data. However, the  command opens the file and reads lines for the . This fails when it tries to load data from my compressed files.\nEither automatically detect the file is compressed or add a flag to  that indicates that the file is compressed. One method that I have used to detect if a file is gzipped is , although it isn't 100% accurate. I have an implementation . Otherwise a flag like  to mark how the file is compressed should be sufficient. Passing the type of compression would allow support for gzip, bz2, or any other method.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ArjunSubramonian",
            "datetime": "Jun 3, 2021",
            "body": "I think this feature is a great idea! The latter design (passing a flag) seems better to me.I am adding  here to get his input as well.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Jun 3, 2021",
            "body": "Yeup, this seems reasonable. I think we should try to automatically detect the compression type, but also have the flag so that users can override it when the automatic detection fails.You may find this helper function useful: ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Dbhasin1",
            "datetime": "Jun 29, 2021",
            "body": "Hi, I'd like to try working on this. I'm relatively a noobie so are there any pointers I should keep in mind before raising a pull request?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Jun 29, 2021",
            "body": "Hi , check out ",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "spranjal25",
            "datetime": "Oct 14, 2021",
            "body": "Hi ! is this issue still not resolved? I'm looking for issues to start contributing to AllenNLP, can I take this up if not resolved already?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Oct 25, 2021",
            "body": "Hi , we haven't heard from  for a while on their PR, so it's probably okay for you take over at this point.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Dbhasin1",
            "datetime": "Oct 25, 2021",
            "body": "hey, sorry I'd been engaged elsewhere for a while. I'd like to give it one more shot!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "aterzgar",
            "datetime": "Jul 21, 2022",
            "body": "is the issue still open ?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "Akshat977",
            "datetime": "Sep 10, 2022",
            "body": "Hi  ,  ,\nThis issue seems to be a good initiation of my journey towards contribution to FOSS projects.\nCan you please assign this to me?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Sep 12, 2022",
            "body": "Hi , feel free to open a PR when you're ready",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "danieldeutsch",
            "datetime": "Jun 2, 2021",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "ArjunSubramonian",
            "datetime": "Jun 3, 2021",
            "body": [],
            "type": "added",
            "related_issue": null
        },
        {
            "user_name": "Dbhasin1",
            "datetime": "Jul 2, 2021",
            "body": [],
            "type": "pull",
            "related_issue": "#5299"
        }
    ]
},
{
    "issue_url": "https://github.com/allenai/allennlp/issues/4397",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "dhruvdcoder",
            "datetime": "Jun 24, 2020",
            "body": "I wish to use a pre-trained embedding layer in my model with possible vocabulary extension before finetuning. Currently, there is no way to do this using a config file unless I write my own train command. Such a feature would be really useful while finetuning a general Transformer in a  layer for a specific domain.Ideally, this approach should be available with any  with the details about how to extend the vocabulary left to the concrete class. Depending on the embedder, we might also want to pass the extra words to the tokenizer. As far as  goes, the Huggingface APIs offer a way to extend the vocabulary of the tokenizer as well as the model (ref:  ).\nThe easiest way I can think of achieving this would be to add an extra parameter in the constructor of  and  which points to an extra vocab file (which can optionally also contain weights to initialize the extra vocabulary tokens for the embedder).\nI have not really considered an alternative approach. I can come up with it if the proposed approach does not seem reasonable.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Jun 26, 2020",
            "body": "We should try to figure this out when / after we rethink our vocab. See .But in the meantime if there's a quick fix for this, we are open to that.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dhruvdcoder",
            "datetime": "Jun 24, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "Jun 26, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/allenai/allennlp/issues/4295",
    "issue_status": " Open\n",
    "issue_list": [
        {
            "user_name": "xdwang0726",
            "datetime": "May 27, 2020",
            "body": "For now, Embedding only take .txt and .hdf5 for pre-trained embedding format. Would it be possible to add .bin format as .bin is the most commonly used for pre-trained format. Thank you!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "May 27, 2020",
            "body": "It's certainly possible and shouldn't be too difficult. Contributions welcome!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "schmmd",
            "datetime": "May 29, 2020",
            "body": " can you give a clear example of the type of file you are proposing adding support for?  We're not sure what  format is, and it'd be good for us to understand the format before anyone begins implementation on adding support.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "gabeorlanski",
            "datetime": "Feb 15, 2021",
            "body": "I have encountered issues ( in AllenNLP but python in general) where  files would not load in python because they were made on a different os than the one I was using. Mostly it was Windows vs. Linux, but I even had issues in WSL vs. pure Linux. So any implementation may have to deal with this.Also, , I would assume the  he refers to is just pickled data from python's  module. It could be completely wrong, though.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "xdwang0726",
            "datetime": "Feb 21, 2021",
            "body": "For example, the google pretrained word2vec is in .bin file (GoogleNews-vectors-negative300.bin)",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "ghost",
            "datetime": "Mar 30, 2021",
            "body": "\nI see that the .bin you have pointed to  is from \nI remembered trying word2vec from gensim in 2016 I think.I can see that gensim comment to load the bin file indicates that it is in a Word2Vec only C-based format.  and specifically Can you point to any other case of such .bin vectors or/and somewhere where it can be figured out what exactly the bin is formatted as. Is it pickle like  indicated (which with the above word2vec case is not)?One can always write one-time script to convert from word2vec bin to desired hdf5 or/and text.I was thinking of picking this up in the coming week and hence the question.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "dirkgr",
            "datetime": "Apr 5, 2021",
            "body": "I am also interested in getting this done, but without a clear indication of what exactly the format is, I don't see how we can do it.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "May 27, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        },
        {
            "user_name": "epwalsh",
            "datetime": "May 27, 2020",
            "body": [],
            "type": "added  the",
            "related_issue": null
        }
    ]
},
{
    "issue_url": "https://github.com/dmlc/gluon-cv/issues/598",
    "issue_status": " Closed\n",
    "issue_list": [
        {
            "user_name": "yuanCnD",
            "datetime": "Jan 30, 2019",
            "body": "hi,here is training log:\nloading annotations into memory...\nDone (t=16.61s)\ncreating index...\nindex created!\nloading annotations into memory...\nDone (t=0.46s)\ncreating index...\nindex created!\nINFO:root:Namespace(batch_size=64, data_shape=416, dataset='coco', epochs=280, gpus='0,1,2,3,4,5,6,7', label_smooth=True, log_interval=100, lr=0.001, lr_decay=0.1, lr_decay_epoch='220,250', lr_decay_period=0, lr_mode='step', mixup=True, momentum=0.9, network='darknet53', no_mixup_epochs=20, no_random_shape=False, no_wd=True, num_samples=117266, num_workers=32, resume='', save_interval=10, save_prefix='yolo3_darknet53_coco', seed=233, start_epoch=0, syncbn=True, val_interval=1, warmup_epochs=2, warmup_lr=0.0, wd=0.0005)\nINFO:root:Start training from [Epoch 0]\nINFO:root:[Epoch 0][Batch 99], LR: 2.70E-05, Speed: 33.324 samples/sec, ObjLoss=878.333, BoxCenterLoss=17.802, BoxScaleLoss=14.941, ClassLoss=339.257\nINFO:root:[Epoch 0][Batch 199], LR: 5.43E-05, Speed: 27.818 samples/sec, ObjLoss=464.404, BoxCenterLoss=17.508, BoxScaleLoss=13.389, ClassLoss=237.332\nINFO:root:[Epoch 0][Batch 299], LR: 8.16E-05, Speed: 56.125 samples/sec, ObjLoss=321.394, BoxCenterLoss=16.973, BoxScaleLoss=11.971, ClassLoss=174.369\nINFO:root:[Epoch 0][Batch 399], LR: 1.09E-04, Speed: 30.589 samples/sec, ObjLoss=249.321, BoxCenterLoss=16.702, BoxScaleLoss=11.015, ClassLoss=140.578\nINFO:root:[Epoch 0][Batch 499], LR: 1.36E-04, Speed: 38.707 samples/sec, ObjLoss=205.859, BoxCenterLoss=16.567, BoxScaleLoss=10.342, ClassLoss=119.724\nINFO:root:[Epoch 0][Batch 599], LR: 1.63E-04, Speed: 37.456 samples/sec, ObjLoss=176.808, BoxCenterLoss=16.499, BoxScaleLoss=9.844, ClassLoss=105.734\nINFO:root:[Epoch 0][Batch 699], LR: 1.91E-04, Speed: 34.759 samples/sec, ObjLoss=155.749, BoxCenterLoss=16.326, BoxScaleLoss=9.392, ClassLoss=95.448\nINFO:root:[Epoch 0][Batch 799], LR: 2.18E-04, Speed: 34.887 samples/sec, ObjLoss=140.052, BoxCenterLoss=16.265, BoxScaleLoss=9.074, ClassLoss=87.846\nINFO:root:[Epoch 0][Batch 899], LR: 2.45E-04, Speed: 21.149 samples/sec, ObjLoss=127.875, BoxCenterLoss=16.238, BoxScaleLoss=8.806, ClassLoss=81.887\nINFO:root:[Epoch 0][Batch 999], LR: 2.73E-04, Speed: 39.372 samples/sec, ObjLoss=117.959, BoxCenterLoss=16.182, BoxScaleLoss=8.577, ClassLoss=77.059\nINFO:root:[Epoch 0][Batch 1099], LR: 3.00E-04, Speed: 23.731 samples/sec, ObjLoss=109.935, BoxCenterLoss=16.154, BoxScaleLoss=8.364, ClassLoss=73.143\nINFO:root:[Epoch 0][Batch 1199], LR: 3.27E-04, Speed: 32.060 samples/sec, ObjLoss=103.141, BoxCenterLoss=16.092, BoxScaleLoss=8.195, ClassLoss=69.817\nINFO:root:[Epoch 0][Batch 1299], LR: 3.55E-04, Speed: 55.695 samples/sec, ObjLoss=97.359, BoxCenterLoss=16.040, BoxScaleLoss=8.067, ClassLoss=67.010\nINFO:root:[Epoch 0][Batch 1399], LR: 3.82E-04, Speed: 29.831 samples/sec, ObjLoss=92.345, BoxCenterLoss=15.977, BoxScaleLoss=7.947, ClassLoss=64.564\nINFO:root:[Epoch 0][Batch 1499], LR: 4.09E-04, Speed: 47.742 samples/sec, ObjLoss=87.972, BoxCenterLoss=15.919, BoxScaleLoss=7.830, ClassLoss=62.440\nINFO:root:[Epoch 0][Batch 1599], LR: 4.36E-04, Speed: 34.914 samples/sec, ObjLoss=84.214, BoxCenterLoss=15.883, BoxScaleLoss=7.729, ClassLoss=60.608\nINFO:root:[Epoch 0][Batch 1699], LR: 4.64E-04, Speed: 36.860 samples/sec, ObjLoss=80.848, BoxCenterLoss=15.821, BoxScaleLoss=7.624, ClassLoss=58.938\nINFO:root:[Epoch 0][Batch 1799], LR: 4.91E-04, Speed: 46.941 samples/sec, ObjLoss=77.929, BoxCenterLoss=15.795, BoxScaleLoss=7.533, ClassLoss=57.506\nINFO:root:[Epoch 0] Training cost: 4479.540, ObjLoss=77.019, BoxCenterLoss=15.767, BoxScaleLoss=7.509, ClassLoss=57.045\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type \nDONE (t=21.98s).\nAccumulating evaluation results...\nDONE (t=1.79s).\nINFO:root:[Epoch 0] Validation:",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "zhreshold",
            "datetime": "Feb 7, 2019",
            "body": "Are you following the same arguments as in the model zoo script?",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "xupengcoding",
            "datetime": "Mar 28, 2019",
            "body": "I also met this problem. When I was training, the validation mAP is always zero. My script is \"python3 -u train_yolo3.py --network darknet53 --dataset coco --lr 0.0005 --gpus 4,5,6,7 --batch-size 32 -j 32 --log-interval 100 --lr-decay-epoch 220,250 --epochs 280 --syncbn --warmup-epochs 2 --mixup --no-mixup-epochs 20 --label-smooth --no-wd 1>train_yolo_dark53.log\".  , Could you please help me!",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "zhreshold",
            "datetime": "Mar 28, 2019",
            "body": "  try this first to make sure you have all set up correctly:If this still doesn't work, then there might be some dataset problem",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "xupengcoding",
            "datetime": "Mar 29, 2019",
            "body": "I found the ans. The score_thresh in COCODetectionMetric is 0.5, but the predict scores always less than 0.5 in several starting epochs. I think this does not matter, and the issue can be closed.",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "yuzhms",
            "datetime": "Apr 25, 2019",
            "body": "I meet this problem when I use scripts likeLosses seemed ok, dropped about 30x. I check and found the score is all below 0.5 even after training 150 epochs.\nBut, when I turn off label smoothing, mixup and no-wd, It work fine, I can get none zero map after 2 epochs.\nIs this normal?\nWhat should I do if I want to use label smoothing, mixup and no-wd?\n",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "zhreshold",
            "datetime": "Apr 25, 2019",
            "body": "please update to master, there has been a small bug causing smooth to be incorrect",
            "type": "commented",
            "related_issue": null
        },
        {
            "user_name": "zhreshold",
            "datetime": "Mar 29, 2019",
            "body": [],
            "type": "closed this as",
            "related_issue": null
        }
    ]
}
]

